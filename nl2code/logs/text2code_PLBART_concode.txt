C:\Users\sriva\anaconda3\envs\DLAssignment\python.exe C:\Users\sriva\OneDrive\Documents\Lectures\CE7455\Project\CodeBERT\CodeBERT\nl2code\run_nl2code.py --do_train --do_eval --model_type=plbart --model_name_or_path=uclanlp/plbart-en_XX-java --train_filename=data/concode/train.json --dev_filename=data/concode/dev.json --output_dir=model/java/plbart --max_source_length=256 --max_target_length=256 --beam_size=10 --train_batch_size=8 --eval_batch_size=8 --learning_rate=5e-5 --train_steps=50000 --eval_steps=1000
04/01/2022 11:59:12 - INFO - __main__ -   Namespace(model_type='plbart', model_name_or_path='uclanlp/plbart-en_XX-java', output_dir='model/java/plbart', load_model_path=None, train_filename='data/concode/train.json', dev_filename='data/concode/dev.json', test_filename=None, config_name='', tokenizer_name='', max_source_length=256, max_target_length=256, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=1000, train_steps=50000, warmup_steps=0, local_rank=-1, seed=42)
04/01/2022 11:59:12 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
04/01/2022 11:59:32 - INFO - __main__ -   *** Example ***
04/01/2022 11:59:32 - INFO - __main__ -   idx: 0
04/01/2022 11:59:32 - INFO - __main__ -   source_tokens: ['<s>', '▁check', '▁if', '▁details', '▁are', '▁parsed', '▁.', '▁con', 'code', '_', 'field', '_', 'sep', '▁Container', '▁parent', '▁con', 'code', '_', 'elem', '_', 'sep', '▁boolean', '▁is', 'Parsed', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁offset', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁content', 'Start', 'Position', '▁con', 'code', '_', 'elem', '_', 'sep', '▁ByteBuffer', '▁dead', 'Bytes', '▁con', 'code', '_', 'elem', '_', 'sep', '▁boolean', '▁is', 'Read', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁mem', 'Map', 'Size', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Logger', '▁LOG', '▁con', 'code', '_', 'elem', '_', 'sep', '▁byte', '[]', '▁user', 'Type', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁type', '▁con', 'code', '_', 'elem', '_', 'sep', '▁ByteBuffer', '▁content', '▁con', 'code', '_', 'elem', '_', 'sep', '▁FileChannel', '▁file', 'Channel', '▁con', 'code', '_', 'field', '_', 'sep', '▁Container', '▁getParent', '▁con', 'code', '_', 'elem', '_', 'sep', '▁byte', '[]', '▁getUser', 'Type', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁read', 'Content', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁getOffset', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁getContent', 'Size', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁getContent', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁setD', 'ead', 'Bytes', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁parse', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁getHeader', '▁con', 'code', '_', 'elem', '_', 'sep', '▁long', '▁getSize', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁parse', 'Details', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁getType', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁_', 'parse', 'Details', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁getPath', '▁con', 'code', '_', 'elem', '_', 'sep', '▁boolean', '▁verify', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁setParent', '▁con', 'code', '_', 'elem', '_', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   source_ids: 0 553 105 3536 395 4393 9 131 948 33456 1448 33456 11287 6031 975 131 948 33456 7390 33456 11287 629 96 16140 131 948 33456 7390 33456 11287 883 1784 131 948 33456 7390 33456 11287 883 846 1851 2684 131 948 33456 7390 33456 11287 5139 8453 2015 131 948 33456 7390 33456 11287 629 96 2569 131 948 33456 7390 33456 11287 883 1375 832 1054 131 948 33456 7390 33456 11287 6409 2163 131 948 33456 7390 33456 11287 1203 2252 419 406 131 948 33456 7390 33456 11287 212 415 131 948 33456 7390 33456 11287 5139 846 131 948 33456 7390 33456 11287 29660 375 3174 131 948 33456 1448 33456 11287 6031 5124 131 948 33456 7390 33456 11287 1203 2252 5236 406 131 948 33456 7390 33456 11287 274 529 1476 131 948 33456 7390 33456 11287 883 14381 131 948 33456 7390 33456 11287 883 6704 1054 131 948 33456 7390 33456 11287 274 6704 131 948 33456 7390 33456 11287 274 12847 348 2015 131 948 33456 7390 33456 11287 274 1142 131 948 33456 7390 33456 11287 274 9791 131 948 33456 7390 33456 11287 883 9049 131 948 33456 7390 33456 11287 274 1142 4420 131 948 33456 7390 33456 11287 212 3548 131 948 33456 7390 33456 11287 274 92 1787 4420 131 948 33456 7390 33456 11287 212 5721 131 948 33456 7390 33456 11287 629 2608 131 948 33456 7390 33456 11287 274 15599 131 948 33456 7390 33456 2
04/01/2022 11:59:32 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_tokens: ['<s>', '▁boolean', '▁function', '▁(', '▁)', '▁{', '▁return', '▁is', 'Parsed', '▁;', '▁}', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   target_ids: 0 629 393 5 6 66 111 96 16140 43 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   *** Example ***
04/01/2022 11:59:32 - INFO - __main__ -   idx: 1
04/01/2022 11:59:32 - INFO - __main__ -   source_tokens: ['<s>', '▁answer', '▁the', '▁library', '▁file', '▁defining', '▁the', '▁library', '▁containing', '▁the', '▁compilation', '▁unit', '▁to', '▁be', '▁indexed', '▁or', '▁null', '▁if', '▁the', '▁library', '▁is', '▁not', '▁on', '▁disk', '▁con', 'code', '_', 'field', '_', 'sep', '▁Index', 'Store', '▁index', 'Store', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Index', 'Performance', 'Recorder', '▁performance', 'Recorder', '▁con', 'code', '_', 'elem', '_', 'sep', '▁D', 'art', 'Unit', '▁unit', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Compilation', 'Unit', '▁compilation', 'Unit', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Resource', '▁resource', '▁con', 'code', '_', 'elem', '_', 'sep', '▁File', '▁library', 'File', '▁con', 'code', '_', 'field', '_', 'sep', '▁boolean', '▁remove', 'When', 'Resource', 'Removed', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Compilation', 'Unit', '▁get', 'CompilationUnit', '▁con', 'code', '_', 'elem', '_', 'sep', '▁boolean', '▁is', 'Query', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁toString', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁perform', 'Operation', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   source_ids: 0 1572 57 2042 375 9703 57 2042 4437 57 10454 2506 71 229 11699 255 285 105 57 2042 96 188 173 4777 131 948 33456 1448 33456 11287 3060 2426 638 2426 131 948 33456 7390 33456 11287 3060 24708 17759 4591 17759 131 948 33456 7390 33456 11287 243 237 2806 2506 131 948 33456 7390 33456 11287 20106 2806 10454 2806 131 948 33456 7390 33456 11287 3754 1747 131 948 33456 7390 33456 11287 884 2042 664 131 948 33456 1448 33456 11287 629 1050 7863 1927 11858 131 948 33456 7390 33456 11287 20106 2806 86 26450 131 948 33456 7390 33456 11287 629 96 870 131 948 33456 7390 33456 11287 212 1306 131 948 33456 7390 33456 11287 274 2272 2731 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   target_tokens: ['<s>', '▁File', '▁function', '▁(', '▁)', '▁{', '▁return', '▁library', 'File', '▁;', '▁}', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   target_ids: 0 884 393 5 6 66 111 2042 664 43 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   *** Example ***
04/01/2022 11:59:32 - INFO - __main__ -   idx: 2
04/01/2022 11:59:32 - INFO - __main__ -   source_tokens: ['<s>', '▁this', '▁method', '▁deletes', '▁index', '▁files', '▁of', '▁the', '▁@', 'link', 'plain', '▁index', 'commit', '▁for', '▁the', '▁specified', '▁generation', '▁number', '▁.', '▁con', 'code', '_', 'field', '_', 'sep', '▁Logger', '▁log', '▁con', 'code', '_', 'field', '_', 'sep', '▁void', '▁delete', 'Non', 'Snapshot', 'Index', 'Files', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Map', '<', 'String', ',', 'Integer', '>', '▁build', 'Ref', 'Counts', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   source_ids: 0 143 483 20613 638 1139 153 57 377 1994 15072 638 7176 126 57 4017 10347 1019 9 131 948 33456 1448 33456 11287 6409 504 131 948 33456 1448 33456 11287 274 1537 4425 5945 1032 3166 131 948 33456 7390 33456 11287 1466 33500 469 33463 2913 33498 1001 1411 11970 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   target_tokens: ['<s>', '▁void', '▁function', '▁(', '▁Directory', '▁arg', '0', '▁,', '▁Collection', '▁<', '▁Snapshot', 'MetaData', '▁>', '▁arg', '1', '▁,', '▁long', '▁arg', '2', '▁)', '▁{', '▁List', '▁<', '▁Index', 'Commit', '▁>', '▁loc', '0', '▁=', '▁Directory', 'Reader', '▁.', '▁list', 'Comm', 'its', '▁(', '▁arg', '0', '▁)', '▁;', '▁Map', '▁<', '▁String', '▁,', '▁Integer', '▁>', '▁loc', '1', '▁=', '▁build', 'Ref', 'Counts', '▁(', '▁arg', '1', '▁,', '▁loc', '0', '▁)', '▁;', '▁for', '▁(', '▁Index', 'Commit', '▁loc', '2', '▁:', '▁loc', '0', '▁)', '▁{', '▁if', '▁(', '▁loc', '2', '▁.', '▁get', 'Generation', '▁(', '▁)', '▁==', '▁arg', '2', '▁)', '▁{', '▁delete', 'Index', 'Files', '▁(', '▁arg', '0', '▁,', '▁loc', '1', '▁,', '▁loc', '2', '▁)', '▁;', '▁break', '▁;', '▁}', '▁}', '▁}', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   target_ids: 0 274 393 5 9861 795 33480 16 2193 128 11522 5957 202 795 33485 16 883 795 33496 6 66 783 128 3060 6841 202 1271 33480 24 9861 2250 9 410 17210 1147 5 795 33480 6 43 1466 128 212 16 1327 202 1271 33485 24 1001 1411 11970 5 795 33485 16 1271 33480 6 43 126 5 3060 6841 1271 33496 54 1271 33480 6 66 105 5 1271 33496 9 86 14276 5 6 258 795 33496 6 66 1537 1032 3166 5 795 33480 16 1271 33485 16 1271 33496 6 43 1117 43 65 65 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   *** Example ***
04/01/2022 11:59:32 - INFO - __main__ -   idx: 3
04/01/2022 11:59:32 - INFO - __main__ -   source_tokens: ['<s>', '▁do', '▁n', "'", 't', '▁use', '▁this', '▁.', '▁no', '▁,', '▁really', '▁,', '▁do', '▁n', "'", 't', '▁use', '▁this', '▁.', '▁you', '▁already', '▁have', '▁an', '▁authentication', 'token', '▁with', '▁org', '.', 'apache', '.', 'accum', 'ulo', '.', 'core', '.', 'client', '.', 'map', 'reduce', '.', 'lib', '.', 'impl', '.', 'config', 'urator', 'base', '▁#', 'get', 'authentication', 'token', '▁class', '▁,', '▁configuration', '▁.', '▁you', '▁do', '▁n', "'", 't', '▁need', '▁to', '▁construct', '▁it', '▁yourself', '▁.', '▁gets', '▁the', '▁password', '▁from', '▁the', '▁configuration', '▁.', '▁warning', '▁:', '▁the', '▁password', '▁is', '▁stored', '▁in', '▁the', '▁configuration', '▁and', '▁shared', '▁with', '▁all', '▁mapreduce', '▁tasks', '▁;', '▁it', '▁is', '▁base', '64', '▁encoded', '▁to', '▁provide', '▁a', '▁charset', '▁safe', '▁conversion', '▁to', '▁a', '▁string', '▁,', '▁and', '▁is', '▁not', '▁intended', '▁to', '▁be', '▁secure', '▁.', '▁con', 'code', '_', 'field', '_', 'sep', '▁Place', 'Holder', '▁place', 'Holder', '▁con', 'code', '_', 'field', '_', 'sep', '▁String', '▁getPrincipal', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁setLog', 'Level', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Level', '▁getLog', 'Level', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Boolean', '▁is', 'Connector', 'Info', 'Set', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁getToken', 'Class', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁set', 'Z', 'ooKeeper', 'Instance', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁set', 'Mock', 'Instance', '▁con', 'code', '_', 'elem', '_', 'sep', '▁Instance', '▁getInstance', '▁con', 'code', '_', 'elem', '_', 'sep', '▁String', '▁enum', 'To', 'Conf', 'Key', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁set', 'Connector', 'Info', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   source_ids: 0 222 42 33473 33440 374 143 9 809 16 2128 16 222 42 33473 33440 374 143 9 144 1845 295 197 5768 2853 215 1264 33455 3860 33455 29057 14137 33455 2972 33455 2285 33455 1224 7602 33455 1039 33455 6063 33455 1599 14467 912 754 300 17110 2853 291 16 2348 9 144 222 42 33473 33440 519 71 4704 141 6850 9 3133 57 1763 320 57 2348 9 2697 54 57 1763 96 3987 55 57 2348 135 4384 215 515 21139 4523 43 141 96 1314 1299 5158 71 3669 14 4612 4896 7272 71 14 625 16 135 96 188 9142 71 229 7713 9 131 948 33456 1448 33456 11287 12161 3697 2257 3697 131 948 33456 1448 33456 11287 212 27199 131 948 33456 7390 33456 11287 274 25817 2794 131 948 33456 7390 33456 11287 6458 10874 2794 131 948 33456 7390 33456 11287 2961 96 7364 1047 659 131 948 33456 7390 33456 11287 212 11559 679 131 948 33456 7390 33456 11287 274 193 33529 19713 1121 131 948 33456 7390 33456 11287 274 193 3288 1121 131 948 33456 7390 33456 11287 7032 2839 131 948 33456 7390 33456 11287 212 2916 485 3889 609 131 948 33456 7390 33456 11287 274 193 7364 1047 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   target_tokens: ['<s>', '▁byte', '▁[', '▁]', '▁function', '▁(', '▁Class', '▁<', '▁?', '▁>', '▁arg', '0', '▁,', '▁Configuration', '▁arg', '1', '▁)', '▁{', '▁return', '▁Authentication', 'Token', 'Serializer', '▁.', '▁serialize', '▁(', '▁org', '▁.', '▁apache', '▁.', '▁accum', 'ulo', '▁.', '▁core', '▁.', '▁client', '▁.', '▁mapreduce', '▁.', '▁lib', '▁.', '▁impl', '▁.', '▁Config', 'urator', 'Base', '▁.', '▁get', 'Authentication', 'Token', '▁(', '▁arg', '0', '▁,', '▁arg', '1', '▁)', '▁)', '▁;', '▁}', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   target_ids: 0 1203 91 99 393 5 1583 128 593 202 795 33480 16 3838 795 33485 6 66 111 8414 1791 5286 9 5346 5 1264 9 3672 9 8807 14137 9 3420 9 847 9 21139 9 1210 9 5924 9 2480 14467 2363 9 86 6678 1791 5 795 33480 16 795 33485 6 6 43 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   *** Example ***
04/01/2022 11:59:32 - INFO - __main__ -   idx: 4
04/01/2022 11:59:32 - INFO - __main__ -   source_tokens: ['<s>', '▁force', '▁the', '▁event', 'bus', '▁from', '▁am', 'bar', 'ie', 'vent', 'publisher', '▁to', '▁be', '▁serial', 'and', '▁synchronous', '▁.', '▁con', 'code', '_', 'field', '_', 'sep', '▁Place', 'Holder', '▁place', 'Holder', '▁con', 'code', '_', 'field', '_', 'sep', '▁void', '▁register', 'Alert', 'Listeners', '▁con', 'code', '_', 'elem', '_', 'sep', '▁EventBus', '▁synchronize', 'Alert', 'Event', 'Publisher', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁replace', 'Event', 'Bus', '▁con', 'code', '_', 'elem', '_', 'sep', '▁void', '▁register', 'Amb', 'ari', 'Listeners', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   source_ids: 0 3276 57 709 9430 320 505 2091 952 381 32250 71 229 5729 207 14332 9 131 948 33456 1448 33456 11287 12161 3697 2257 3697 131 948 33456 1448 33456 11287 274 1842 9716 7138 131 948 33456 7390 33456 11287 29149 16338 9716 950 13341 131 948 33456 7390 33456 11287 274 1457 950 6891 131 948 33456 7390 33456 11287 274 1842 33242 1390 7138 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
04/01/2022 11:59:32 - INFO - __main__ -   target_tokens: ['<s>', '▁void', '▁function', '▁(', '▁B', 'inder', '▁arg', '0', '▁)', '▁{', '▁EventBus', '▁loc', '0', '▁=', '▁new', '▁EventBus', '▁(', '▁)', '▁;', '▁Amb', 'ari', 'Event', 'Publisher', '▁loc', '1', '▁=', '▁new', '▁Amb', 'ari', 'Event', 'Publisher', '▁(', '▁)', '▁;', '▁replace', 'Event', 'Bus', '▁(', '▁Amb', 'ari', 'Event', 'Publisher', '▁.', '▁class', '▁,', '▁loc', '1', '▁,', '▁loc', '0', '▁)', '▁;', '▁arg', '0', '▁.', '▁bind', '▁(', '▁Amb', 'ari', 'Event', 'Publisher', '▁.', '▁class', '▁)', '▁.', '▁to', 'Instance', '▁(', '▁loc', '1', '▁)', '▁;', '▁}', '</s>']
04/01/2022 11:59:32 - INFO - __main__ -   target_ids: 0 274 393 5 245 4218 795 33480 6 66 29149 1271 33480 24 166 29149 5 6 43 30308 1390 950 13341 1271 33485 24 166 30308 1390 950 13341 5 6 43 1457 950 6891 5 30308 1390 950 13341 9 291 16 1271 33485 16 1271 33480 6 43 795 33480 9 2165 5 30308 1390 950 13341 9 291 6 9 71 1121 5 1271 33485 6 43 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
04/01/2022 11:59:32 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
C:\Users\sriva\anaconda3\envs\DLAssignment\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
04/01/2022 12:01:18 - INFO - __main__ -   ***** Running training *****
04/01/2022 12:01:18 - INFO - __main__ -     Num examples = 100000
04/01/2022 12:01:18 - INFO - __main__ -     Batch size = 8
04/01/2022 12:01:18 - INFO - __main__ -     Num epoch = 4
loss 0.2569:   2%|▏         | 998/50000 [05:14<4:59:34,  2.73it/s]04/01/2022 12:06:34 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:06:34 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:06:34 - INFO - __main__ -     Batch size = 8
04/01/2022 12:07:01 - INFO - __main__ -     eval_ppl = 3.84961
04/01/2022 12:07:01 - INFO - __main__ -     global_step = 1000
04/01/2022 12:07:01 - INFO - __main__ -     train_loss = 0.2569
04/01/2022 12:07:01 - INFO - __main__ -     ********************
04/01/2022 12:07:02 - INFO - __main__ -     Best ppl:3.84961
04/01/2022 12:07:02 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:07:28 - INFO - __main__ -     bleu-4 = 33.73 
04/01/2022 12:07:28 - INFO - __main__ -     ********************
04/01/2022 12:07:28 - INFO - __main__ -     Best bleu:33.73
04/01/2022 12:07:28 - INFO - __main__ -     ********************
loss 0.2513:   4%|▍         | 1998/50000 [12:21<5:06:09,  2.61it/s]04/01/2022 12:13:39 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:13:39 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:13:39 - INFO - __main__ -     Batch size = 8
04/01/2022 12:14:08 - INFO - __main__ -     eval_ppl = 3.72794
04/01/2022 12:14:08 - INFO - __main__ -     global_step = 2000
04/01/2022 12:14:08 - INFO - __main__ -     train_loss = 0.2513
04/01/2022 12:14:08 - INFO - __main__ -     ********************
04/01/2022 12:14:08 - INFO - __main__ -     Best ppl:3.72794
04/01/2022 12:14:08 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:14:32 - INFO - __main__ -     bleu-4 = 33.89 
04/01/2022 12:14:32 - INFO - __main__ -     ********************
04/01/2022 12:14:32 - INFO - __main__ -     Best bleu:33.89
04/01/2022 12:14:32 - INFO - __main__ -     ********************
loss 0.2339:   6%|▌         | 2998/50000 [19:24<4:51:43,  2.69it/s]04/01/2022 12:20:42 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:20:42 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:20:42 - INFO - __main__ -     Batch size = 8
04/01/2022 12:21:09 - INFO - __main__ -     eval_ppl = 3.60967
04/01/2022 12:21:09 - INFO - __main__ -     global_step = 3000
04/01/2022 12:21:09 - INFO - __main__ -     train_loss = 0.2339
04/01/2022 12:21:09 - INFO - __main__ -     ********************
04/01/2022 12:21:10 - INFO - __main__ -     Best ppl:3.60967
04/01/2022 12:21:10 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:21:33 - INFO - __main__ -     bleu-4 = 33.7 
04/01/2022 12:21:33 - INFO - __main__ -     ********************
loss 0.241:   8%|▊         | 3998/50000 [26:22<4:40:34,  2.73it/s]04/01/2022 12:27:40 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:27:40 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:27:40 - INFO - __main__ -     Batch size = 8
04/01/2022 12:28:07 - INFO - __main__ -     eval_ppl = 3.58024
04/01/2022 12:28:07 - INFO - __main__ -     global_step = 4000
04/01/2022 12:28:07 - INFO - __main__ -     train_loss = 0.241
04/01/2022 12:28:07 - INFO - __main__ -     ********************
04/01/2022 12:28:08 - INFO - __main__ -     Best ppl:3.58024
04/01/2022 12:28:08 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:28:31 - INFO - __main__ -     bleu-4 = 33.94 
04/01/2022 12:28:31 - INFO - __main__ -     ********************
04/01/2022 12:28:31 - INFO - __main__ -     Best bleu:33.94
04/01/2022 12:28:31 - INFO - __main__ -     ********************
loss 0.2401:  10%|▉         | 4998/50000 [33:14<4:39:34,  2.68it/s]04/01/2022 12:34:32 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:34:32 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:34:32 - INFO - __main__ -     Batch size = 8
04/01/2022 12:35:00 - INFO - __main__ -     eval_ppl = 3.58395
04/01/2022 12:35:00 - INFO - __main__ -     global_step = 5000
04/01/2022 12:35:00 - INFO - __main__ -     train_loss = 0.2401
04/01/2022 12:35:00 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:35:23 - INFO - __main__ -     bleu-4 = 34.37 
04/01/2022 12:35:23 - INFO - __main__ -     ********************
04/01/2022 12:35:23 - INFO - __main__ -     Best bleu:34.37
04/01/2022 12:35:23 - INFO - __main__ -     ********************
loss 0.2327:  12%|█▏        | 5998/50000 [40:32<4:41:37,  2.60it/s]04/01/2022 12:41:51 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:41:51 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:41:51 - INFO - __main__ -     Batch size = 8
04/01/2022 12:42:18 - INFO - __main__ -     eval_ppl = 3.56872
04/01/2022 12:42:18 - INFO - __main__ -     global_step = 6000
04/01/2022 12:42:18 - INFO - __main__ -     train_loss = 0.2327
04/01/2022 12:42:18 - INFO - __main__ -     ********************
04/01/2022 12:42:19 - INFO - __main__ -     Best ppl:3.56872
04/01/2022 12:42:19 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:42:43 - INFO - __main__ -     bleu-4 = 34.69 
04/01/2022 12:42:43 - INFO - __main__ -     ********************
04/01/2022 12:42:43 - INFO - __main__ -     Best bleu:34.69
04/01/2022 12:42:43 - INFO - __main__ -     ********************
loss 0.2243:  14%|█▍        | 6998/50000 [47:51<4:36:58,  2.59it/s]04/01/2022 12:49:09 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:49:09 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:49:09 - INFO - __main__ -     Batch size = 8
04/01/2022 12:49:36 - INFO - __main__ -     eval_ppl = 3.474
04/01/2022 12:49:36 - INFO - __main__ -     global_step = 7000
04/01/2022 12:49:36 - INFO - __main__ -     train_loss = 0.2243
04/01/2022 12:49:36 - INFO - __main__ -     ********************
04/01/2022 12:49:37 - INFO - __main__ -     Best ppl:3.474
04/01/2022 12:49:37 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:50:01 - INFO - __main__ -     bleu-4 = 33.85 
04/01/2022 12:50:01 - INFO - __main__ -     ********************
loss 0.2246:  16%|█▌        | 7998/50000 [55:07<4:28:41,  2.61it/s]04/01/2022 12:56:26 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 12:56:26 - INFO - __main__ -     Num examples = 2000
04/01/2022 12:56:26 - INFO - __main__ -     Batch size = 8
04/01/2022 12:56:54 - INFO - __main__ -     eval_ppl = 3.46286
04/01/2022 12:56:54 - INFO - __main__ -     global_step = 8000
04/01/2022 12:56:54 - INFO - __main__ -     train_loss = 0.2246
04/01/2022 12:56:54 - INFO - __main__ -     ********************
04/01/2022 12:56:55 - INFO - __main__ -     Best ppl:3.46286
04/01/2022 12:56:55 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 12:57:19 - INFO - __main__ -     bleu-4 = 33.85 
04/01/2022 12:57:19 - INFO - __main__ -     ********************
loss 0.2215:  18%|█▊        | 8998/50000 [1:02:26<4:15:56,  2.67it/s]04/01/2022 13:03:44 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:03:44 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:03:44 - INFO - __main__ -     Batch size = 8
04/01/2022 13:04:11 - INFO - __main__ -     eval_ppl = 3.45147
04/01/2022 13:04:11 - INFO - __main__ -     global_step = 9000
04/01/2022 13:04:11 - INFO - __main__ -     train_loss = 0.2215
04/01/2022 13:04:11 - INFO - __main__ -     ********************
04/01/2022 13:04:12 - INFO - __main__ -     Best ppl:3.45147
04/01/2022 13:04:12 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:04:36 - INFO - __main__ -     bleu-4 = 34.15 
04/01/2022 13:04:36 - INFO - __main__ -     ********************
loss 0.2236:  20%|█▉        | 9998/50000 [1:08:41<4:09:16,  2.67it/s]04/01/2022 13:09:59 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:09:59 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:09:59 - INFO - __main__ -     Batch size = 8
04/01/2022 13:10:26 - INFO - __main__ -     eval_ppl = 3.3929
04/01/2022 13:10:26 - INFO - __main__ -     global_step = 10000
04/01/2022 13:10:26 - INFO - __main__ -     train_loss = 0.2236
04/01/2022 13:10:26 - INFO - __main__ -     ********************
04/01/2022 13:10:27 - INFO - __main__ -     Best ppl:3.3929
04/01/2022 13:10:27 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:10:50 - INFO - __main__ -     bleu-4 = 34.01 
04/01/2022 13:10:50 - INFO - __main__ -     ********************
loss 0.2212:  22%|██▏       | 10998/50000 [1:15:22<3:09:58,  3.42it/s]04/01/2022 13:16:41 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:16:41 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:16:41 - INFO - __main__ -     Batch size = 8
04/01/2022 13:17:02 - INFO - __main__ -     eval_ppl = 3.38599
04/01/2022 13:17:02 - INFO - __main__ -     global_step = 11000
04/01/2022 13:17:02 - INFO - __main__ -     train_loss = 0.2212
04/01/2022 13:17:02 - INFO - __main__ -     ********************
04/01/2022 13:17:03 - INFO - __main__ -     Best ppl:3.38599
04/01/2022 13:17:03 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:17:25 - INFO - __main__ -     bleu-4 = 34.7 
04/01/2022 13:17:25 - INFO - __main__ -     ********************
04/01/2022 13:17:25 - INFO - __main__ -     Best bleu:34.7
04/01/2022 13:17:25 - INFO - __main__ -     ********************
loss 0.2149:  24%|██▍       | 11998/50000 [1:21:01<3:04:29,  3.43it/s]04/01/2022 13:22:19 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:22:19 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:22:19 - INFO - __main__ -     Batch size = 8
04/01/2022 13:22:40 - INFO - __main__ -     eval_ppl = 3.39732
04/01/2022 13:22:40 - INFO - __main__ -     global_step = 12000
04/01/2022 13:22:40 - INFO - __main__ -     train_loss = 0.2149
04/01/2022 13:22:40 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:23:02 - INFO - __main__ -     bleu-4 = 34.77 
04/01/2022 13:23:02 - INFO - __main__ -     ********************
04/01/2022 13:23:02 - INFO - __main__ -     Best bleu:34.77
04/01/2022 13:23:02 - INFO - __main__ -     ********************
loss 0.1906:  26%|██▌       | 12998/50000 [1:26:39<3:01:53,  3.39it/s]04/01/2022 13:27:57 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:27:57 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:27:57 - INFO - __main__ -     Batch size = 8
04/01/2022 13:28:18 - INFO - __main__ -     eval_ppl = 3.42075
04/01/2022 13:28:18 - INFO - __main__ -     global_step = 13000
04/01/2022 13:28:18 - INFO - __main__ -     train_loss = 0.1906
04/01/2022 13:28:18 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:28:40 - INFO - __main__ -     bleu-4 = 34.51 
04/01/2022 13:28:40 - INFO - __main__ -     ********************
loss 0.1534:  28%|██▊       | 13998/50000 [1:33:21<3:40:36,  2.72it/s]04/01/2022 13:34:39 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:34:39 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:34:39 - INFO - __main__ -     Batch size = 8
04/01/2022 13:35:06 - INFO - __main__ -     eval_ppl = 3.42258
04/01/2022 13:35:06 - INFO - __main__ -     global_step = 14000
04/01/2022 13:35:06 - INFO - __main__ -     train_loss = 0.1534
04/01/2022 13:35:06 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:35:29 - INFO - __main__ -     bleu-4 = 34.51 
04/01/2022 13:35:29 - INFO - __main__ -     ********************
loss 0.149:  30%|██▉       | 14998/50000 [1:40:17<3:30:19,  2.77it/s]04/01/2022 13:41:35 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:41:35 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:41:35 - INFO - __main__ -     Batch size = 8
04/01/2022 13:42:01 - INFO - __main__ -     eval_ppl = 3.52692
04/01/2022 13:42:01 - INFO - __main__ -     global_step = 15000
04/01/2022 13:42:01 - INFO - __main__ -     train_loss = 0.149
04/01/2022 13:42:01 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:42:24 - INFO - __main__ -     bleu-4 = 34.24 
04/01/2022 13:42:24 - INFO - __main__ -     ********************
loss 0.1457:  32%|███▏      | 15998/50000 [1:47:01<2:47:54,  3.38it/s]04/01/2022 13:48:20 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:48:20 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:48:20 - INFO - __main__ -     Batch size = 8
04/01/2022 13:48:41 - INFO - __main__ -     eval_ppl = 3.48604
04/01/2022 13:48:41 - INFO - __main__ -     global_step = 16000
04/01/2022 13:48:41 - INFO - __main__ -     train_loss = 0.1457
04/01/2022 13:48:41 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:49:04 - INFO - __main__ -     bleu-4 = 34.43 
04/01/2022 13:49:04 - INFO - __main__ -     ********************
loss 0.1506:  34%|███▍      | 16998/50000 [1:52:48<2:40:43,  3.42it/s]04/01/2022 13:54:07 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:54:07 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:54:07 - INFO - __main__ -     Batch size = 8
04/01/2022 13:54:28 - INFO - __main__ -     eval_ppl = 3.48581
04/01/2022 13:54:28 - INFO - __main__ -     global_step = 17000
04/01/2022 13:54:28 - INFO - __main__ -     train_loss = 0.1506
04/01/2022 13:54:28 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 13:54:50 - INFO - __main__ -     bleu-4 = 34.65 
04/01/2022 13:54:50 - INFO - __main__ -     ********************
loss 0.1433:  36%|███▌      | 17998/50000 [1:58:24<2:36:38,  3.41it/s]04/01/2022 13:59:42 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 13:59:42 - INFO - __main__ -     Num examples = 2000
04/01/2022 13:59:42 - INFO - __main__ -     Batch size = 8
04/01/2022 14:00:03 - INFO - __main__ -     eval_ppl = 3.45678
04/01/2022 14:00:03 - INFO - __main__ -     global_step = 18000
04/01/2022 14:00:03 - INFO - __main__ -     train_loss = 0.1433
04/01/2022 14:00:03 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:00:25 - INFO - __main__ -     bleu-4 = 35.52 
04/01/2022 14:00:25 - INFO - __main__ -     ********************
04/01/2022 14:00:25 - INFO - __main__ -     Best bleu:35.52
04/01/2022 14:00:25 - INFO - __main__ -     ********************
loss 0.1373:  38%|███▊      | 18998/50000 [2:04:00<2:30:47,  3.43it/s]04/01/2022 14:05:18 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:05:18 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:05:18 - INFO - __main__ -     Batch size = 8
04/01/2022 14:05:39 - INFO - __main__ -     eval_ppl = 3.45022
04/01/2022 14:05:39 - INFO - __main__ -     global_step = 19000
04/01/2022 14:05:39 - INFO - __main__ -     train_loss = 0.1373
04/01/2022 14:05:39 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:06:01 - INFO - __main__ -     bleu-4 = 34.99 
04/01/2022 14:06:01 - INFO - __main__ -     ********************
loss 0.1334:  40%|███▉      | 19998/50000 [2:09:34<2:26:00,  3.42it/s]04/01/2022 14:10:53 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:10:53 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:10:53 - INFO - __main__ -     Batch size = 8
04/01/2022 14:11:14 - INFO - __main__ -     eval_ppl = 3.48709
04/01/2022 14:11:14 - INFO - __main__ -     global_step = 20000
04/01/2022 14:11:14 - INFO - __main__ -     train_loss = 0.1334
04/01/2022 14:11:14 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:11:36 - INFO - __main__ -     bleu-4 = 34.89 
04/01/2022 14:11:36 - INFO - __main__ -     ********************
loss 0.1363:  42%|████▏     | 20998/50000 [2:15:10<2:22:18,  3.40it/s]04/01/2022 14:16:28 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:16:28 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:16:28 - INFO - __main__ -     Batch size = 8
04/01/2022 14:16:49 - INFO - __main__ -     eval_ppl = 3.41693
04/01/2022 14:16:49 - INFO - __main__ -     global_step = 21000
04/01/2022 14:16:49 - INFO - __main__ -     train_loss = 0.1363
04/01/2022 14:16:49 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:17:11 - INFO - __main__ -     bleu-4 = 34.98 
04/01/2022 14:17:11 - INFO - __main__ -     ********************
loss 0.1331:  44%|████▍     | 21998/50000 [2:20:46<2:16:27,  3.42it/s]04/01/2022 14:22:04 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:22:04 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:22:04 - INFO - __main__ -     Batch size = 8
04/01/2022 14:22:25 - INFO - __main__ -     eval_ppl = 3.42538
04/01/2022 14:22:25 - INFO - __main__ -     global_step = 22000
04/01/2022 14:22:25 - INFO - __main__ -     train_loss = 0.1331
04/01/2022 14:22:25 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:22:47 - INFO - __main__ -     bleu-4 = 34.78 
04/01/2022 14:22:47 - INFO - __main__ -     ********************
loss 0.1317:  46%|████▌     | 22998/50000 [2:26:22<2:12:07,  3.41it/s]04/01/2022 14:27:41 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:27:41 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:27:41 - INFO - __main__ -     Batch size = 8
04/01/2022 14:28:02 - INFO - __main__ -     eval_ppl = 3.39921
04/01/2022 14:28:02 - INFO - __main__ -     global_step = 23000
04/01/2022 14:28:02 - INFO - __main__ -     train_loss = 0.1317
04/01/2022 14:28:02 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:28:24 - INFO - __main__ -     bleu-4 = 34.66 
04/01/2022 14:28:24 - INFO - __main__ -     ********************
loss 0.1323:  48%|████▊     | 23998/50000 [2:31:56<2:05:43,  3.45it/s]04/01/2022 14:33:14 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:33:14 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:33:14 - INFO - __main__ -     Batch size = 8
04/01/2022 14:33:36 - INFO - __main__ -     eval_ppl = 3.39789
04/01/2022 14:33:36 - INFO - __main__ -     global_step = 24000
04/01/2022 14:33:36 - INFO - __main__ -     train_loss = 0.1323
04/01/2022 14:33:36 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:33:58 - INFO - __main__ -     bleu-4 = 35.12 
04/01/2022 14:33:58 - INFO - __main__ -     ********************
loss 0.1241:  50%|████▉     | 24998/50000 [2:37:29<2:00:57,  3.45it/s]04/01/2022 14:38:47 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:38:47 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:38:47 - INFO - __main__ -     Batch size = 8
04/01/2022 14:39:08 - INFO - __main__ -     eval_ppl = 3.42016
04/01/2022 14:39:08 - INFO - __main__ -     global_step = 25000
04/01/2022 14:39:08 - INFO - __main__ -     train_loss = 0.1241
04/01/2022 14:39:08 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:39:30 - INFO - __main__ -     bleu-4 = 34.63 
04/01/2022 14:39:30 - INFO - __main__ -     ********************
loss 0.1031:  52%|█████▏    | 25998/50000 [2:43:02<1:55:41,  3.46it/s]04/01/2022 14:44:20 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:44:20 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:44:20 - INFO - __main__ -     Batch size = 8
04/01/2022 14:44:41 - INFO - __main__ -     eval_ppl = 3.51268
04/01/2022 14:44:41 - INFO - __main__ -     global_step = 26000
04/01/2022 14:44:41 - INFO - __main__ -     train_loss = 0.1031
04/01/2022 14:44:41 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:45:03 - INFO - __main__ -     bleu-4 = 34.78 
04/01/2022 14:45:03 - INFO - __main__ -     ********************
loss 0.0933:  54%|█████▍    | 26998/50000 [2:48:35<1:50:44,  3.46it/s]04/01/2022 14:49:53 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:49:53 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:49:53 - INFO - __main__ -     Batch size = 8
04/01/2022 14:50:14 - INFO - __main__ -     eval_ppl = 3.59552
04/01/2022 14:50:14 - INFO - __main__ -     global_step = 27000
04/01/2022 14:50:14 - INFO - __main__ -     train_loss = 0.0933
04/01/2022 14:50:14 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:50:36 - INFO - __main__ -     bleu-4 = 35.4 
04/01/2022 14:50:36 - INFO - __main__ -     ********************
loss 0.0879:  56%|█████▌    | 27998/50000 [2:54:08<1:46:30,  3.44it/s]04/01/2022 14:55:26 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 14:55:26 - INFO - __main__ -     Num examples = 2000
04/01/2022 14:55:26 - INFO - __main__ -     Batch size = 8
04/01/2022 14:55:47 - INFO - __main__ -     eval_ppl = 3.51467
04/01/2022 14:55:47 - INFO - __main__ -     global_step = 28000
04/01/2022 14:55:47 - INFO - __main__ -     train_loss = 0.0879
04/01/2022 14:55:47 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 14:56:09 - INFO - __main__ -     bleu-4 = 35.73 
04/01/2022 14:56:09 - INFO - __main__ -     ********************
04/01/2022 14:56:09 - INFO - __main__ -     Best bleu:35.73
04/01/2022 14:56:09 - INFO - __main__ -     ********************
loss 0.089:  58%|█████▊    | 28998/50000 [2:59:42<1:41:24,  3.45it/s]04/01/2022 15:01:00 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:01:00 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:01:00 - INFO - __main__ -     Batch size = 8
04/01/2022 15:01:21 - INFO - __main__ -     eval_ppl = 3.53685
04/01/2022 15:01:21 - INFO - __main__ -     global_step = 29000
04/01/2022 15:01:21 - INFO - __main__ -     train_loss = 0.089
04/01/2022 15:01:21 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:01:43 - INFO - __main__ -     bleu-4 = 35.23 
04/01/2022 15:01:43 - INFO - __main__ -     ********************
loss 0.0857:  60%|█████▉    | 29998/50000 [3:05:15<1:37:02,  3.44it/s]04/01/2022 15:06:33 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:06:33 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:06:33 - INFO - __main__ -     Batch size = 8
04/01/2022 15:06:54 - INFO - __main__ -     eval_ppl = 3.56434
04/01/2022 15:06:54 - INFO - __main__ -     global_step = 30000
04/01/2022 15:06:54 - INFO - __main__ -     train_loss = 0.0857
04/01/2022 15:06:54 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:07:16 - INFO - __main__ -     bleu-4 = 35.51 
04/01/2022 15:07:16 - INFO - __main__ -     ********************
loss 0.0839:  62%|██████▏   | 30998/50000 [3:10:48<1:31:19,  3.47it/s]04/01/2022 15:12:06 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:12:06 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:12:06 - INFO - __main__ -     Batch size = 8
04/01/2022 15:12:27 - INFO - __main__ -     eval_ppl = 3.59149
04/01/2022 15:12:27 - INFO - __main__ -     global_step = 31000
04/01/2022 15:12:27 - INFO - __main__ -     train_loss = 0.0839
04/01/2022 15:12:27 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:12:49 - INFO - __main__ -     bleu-4 = 35.19 
04/01/2022 15:12:49 - INFO - __main__ -     ********************
loss 0.0795:  64%|██████▍   | 31998/50000 [3:16:20<1:26:44,  3.46it/s]04/01/2022 15:17:39 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:17:39 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:17:39 - INFO - __main__ -     Batch size = 8
04/01/2022 15:18:00 - INFO - __main__ -     eval_ppl = 3.59195
04/01/2022 15:18:00 - INFO - __main__ -     global_step = 32000
04/01/2022 15:18:00 - INFO - __main__ -     train_loss = 0.0795
04/01/2022 15:18:00 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:18:21 - INFO - __main__ -     bleu-4 = 34.48 
04/01/2022 15:18:21 - INFO - __main__ -     ********************
loss 0.0828:  66%|██████▌   | 32998/50000 [3:21:53<1:22:08,  3.45it/s]04/01/2022 15:23:11 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:23:11 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:23:11 - INFO - __main__ -     Batch size = 8
04/01/2022 15:23:32 - INFO - __main__ -     eval_ppl = 3.55294
04/01/2022 15:23:32 - INFO - __main__ -     global_step = 33000
04/01/2022 15:23:32 - INFO - __main__ -     train_loss = 0.0828
04/01/2022 15:23:32 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:23:54 - INFO - __main__ -     bleu-4 = 34.69 
04/01/2022 15:23:54 - INFO - __main__ -     ********************
loss 0.0792:  68%|██████▊   | 33998/50000 [3:27:26<1:17:20,  3.45it/s]04/01/2022 15:28:44 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:28:44 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:28:44 - INFO - __main__ -     Batch size = 8
04/01/2022 15:29:05 - INFO - __main__ -     eval_ppl = 3.55146
04/01/2022 15:29:05 - INFO - __main__ -     global_step = 34000
04/01/2022 15:29:05 - INFO - __main__ -     train_loss = 0.0792
04/01/2022 15:29:05 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:29:27 - INFO - __main__ -     bleu-4 = 35.29 
04/01/2022 15:29:27 - INFO - __main__ -     ********************
loss 0.0783:  70%|██████▉   | 34998/50000 [3:32:58<1:12:44,  3.44it/s]04/01/2022 15:34:17 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:34:17 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:34:17 - INFO - __main__ -     Batch size = 8
04/01/2022 15:34:38 - INFO - __main__ -     eval_ppl = 3.59309
04/01/2022 15:34:38 - INFO - __main__ -     global_step = 35000
04/01/2022 15:34:38 - INFO - __main__ -     train_loss = 0.0783
04/01/2022 15:34:38 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:35:00 - INFO - __main__ -     bleu-4 = 34.64 
04/01/2022 15:35:00 - INFO - __main__ -     ********************
loss 0.076:  72%|███████▏  | 35998/50000 [3:38:31<1:07:22,  3.46it/s]04/01/2022 15:39:50 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:39:50 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:39:50 - INFO - __main__ -     Batch size = 8
04/01/2022 15:40:11 - INFO - __main__ -     eval_ppl = 3.56886
04/01/2022 15:40:11 - INFO - __main__ -     global_step = 36000
04/01/2022 15:40:11 - INFO - __main__ -     train_loss = 0.076
04/01/2022 15:40:11 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:40:33 - INFO - __main__ -     bleu-4 = 35.02 
04/01/2022 15:40:33 - INFO - __main__ -     ********************
loss 0.075:  74%|███████▍  | 36998/50000 [3:44:04<1:02:50,  3.45it/s] 04/01/2022 15:45:23 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:45:23 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:45:23 - INFO - __main__ -     Batch size = 8
04/01/2022 15:45:44 - INFO - __main__ -     eval_ppl = 3.59597
04/01/2022 15:45:44 - INFO - __main__ -     global_step = 37000
04/01/2022 15:45:44 - INFO - __main__ -     train_loss = 0.075
04/01/2022 15:45:44 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:46:06 - INFO - __main__ -     bleu-4 = 35.17 
04/01/2022 15:46:06 - INFO - __main__ -     ********************
loss 0.0705:  76%|███████▌  | 37998/50000 [3:49:39<58:20,  3.43it/s]04/01/2022 15:50:58 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:50:58 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:50:58 - INFO - __main__ -     Batch size = 8
04/01/2022 15:51:19 - INFO - __main__ -     eval_ppl = 3.64216
04/01/2022 15:51:19 - INFO - __main__ -     global_step = 38000
04/01/2022 15:51:19 - INFO - __main__ -     train_loss = 0.0705
04/01/2022 15:51:19 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:51:41 - INFO - __main__ -     bleu-4 = 35.32 
04/01/2022 15:51:41 - INFO - __main__ -     ********************
loss 0.0574:  78%|███████▊  | 38998/50000 [3:55:14<53:32,  3.43it/s]04/01/2022 15:56:32 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 15:56:32 - INFO - __main__ -     Num examples = 2000
04/01/2022 15:56:32 - INFO - __main__ -     Batch size = 8
04/01/2022 15:56:53 - INFO - __main__ -     eval_ppl = 3.68932
04/01/2022 15:56:53 - INFO - __main__ -     global_step = 39000
04/01/2022 15:56:53 - INFO - __main__ -     train_loss = 0.0574
04/01/2022 15:56:53 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 15:57:16 - INFO - __main__ -     bleu-4 = 35.37 
04/01/2022 15:57:16 - INFO - __main__ -     ********************
loss 0.0522:  80%|███████▉  | 39998/50000 [4:00:49<48:24,  3.44it/s]04/01/2022 16:02:08 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:02:08 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:02:08 - INFO - __main__ -     Batch size = 8
04/01/2022 16:02:29 - INFO - __main__ -     eval_ppl = 3.72479
04/01/2022 16:02:29 - INFO - __main__ -     global_step = 40000
04/01/2022 16:02:29 - INFO - __main__ -     train_loss = 0.0522
04/01/2022 16:02:29 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:02:51 - INFO - __main__ -     bleu-4 = 35.4 
04/01/2022 16:02:51 - INFO - __main__ -     ********************
loss 0.0507:  82%|████████▏ | 40998/50000 [4:07:08<43:35,  3.44it/s]04/01/2022 16:08:27 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:08:27 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:08:27 - INFO - __main__ -     Batch size = 8
04/01/2022 16:08:50 - INFO - __main__ -     eval_ppl = 3.73181
04/01/2022 16:08:50 - INFO - __main__ -     global_step = 41000
04/01/2022 16:08:50 - INFO - __main__ -     train_loss = 0.0507
04/01/2022 16:08:50 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:09:13 - INFO - __main__ -     bleu-4 = 35.06 
04/01/2022 16:09:13 - INFO - __main__ -     ********************
loss 0.0531:  84%|████████▍ | 41998/50000 [4:12:48<38:48,  3.44it/s]04/01/2022 16:14:07 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:14:07 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:14:07 - INFO - __main__ -     Batch size = 8
04/01/2022 16:14:28 - INFO - __main__ -     eval_ppl = 3.69342
04/01/2022 16:14:28 - INFO - __main__ -     global_step = 42000
04/01/2022 16:14:28 - INFO - __main__ -     train_loss = 0.0531
04/01/2022 16:14:28 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:14:50 - INFO - __main__ -     bleu-4 = 35.69 
04/01/2022 16:14:50 - INFO - __main__ -     ********************
loss 0.0496:  86%|████████▌ | 42998/50000 [4:18:29<41:40,  2.80it/s]04/01/2022 16:19:48 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:19:48 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:19:48 - INFO - __main__ -     Batch size = 8
04/01/2022 16:20:13 - INFO - __main__ -     eval_ppl = 3.68848
04/01/2022 16:20:13 - INFO - __main__ -     global_step = 43000
04/01/2022 16:20:13 - INFO - __main__ -     train_loss = 0.0496
04/01/2022 16:20:13 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:20:37 - INFO - __main__ -     bleu-4 = 35.29 
04/01/2022 16:20:37 - INFO - __main__ -     ********************
loss 0.0479:  88%|████████▊ | 43998/50000 [4:24:26<32:19,  3.09it/s]04/01/2022 16:25:44 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:25:44 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:25:44 - INFO - __main__ -     Batch size = 8
04/01/2022 16:26:06 - INFO - __main__ -     eval_ppl = 3.70296
04/01/2022 16:26:06 - INFO - __main__ -     global_step = 44000
04/01/2022 16:26:06 - INFO - __main__ -     train_loss = 0.0479
04/01/2022 16:26:06 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:26:28 - INFO - __main__ -     bleu-4 = 35.17 
04/01/2022 16:26:28 - INFO - __main__ -     ********************
loss 0.0459:  90%|████████▉ | 44998/50000 [4:30:03<25:12,  3.31it/s]04/01/2022 16:31:21 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:31:21 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:31:21 - INFO - __main__ -     Batch size = 8
04/01/2022 16:31:43 - INFO - __main__ -     eval_ppl = 3.74691
04/01/2022 16:31:43 - INFO - __main__ -     global_step = 45000
04/01/2022 16:31:43 - INFO - __main__ -     train_loss = 0.0459
04/01/2022 16:31:43 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:32:06 - INFO - __main__ -     bleu-4 = 35.73 
04/01/2022 16:32:06 - INFO - __main__ -     ********************
loss 0.0472:  92%|█████████▏| 45998/50000 [4:35:47<19:38,  3.40it/s]04/01/2022 16:37:05 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:37:05 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:37:05 - INFO - __main__ -     Batch size = 8
04/01/2022 16:37:27 - INFO - __main__ -     eval_ppl = 3.74679
04/01/2022 16:37:27 - INFO - __main__ -     global_step = 46000
04/01/2022 16:37:27 - INFO - __main__ -     train_loss = 0.0472
04/01/2022 16:37:27 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:37:50 - INFO - __main__ -     bleu-4 = 35.46 
04/01/2022 16:37:50 - INFO - __main__ -     ********************
loss 0.0458:  94%|█████████▍| 46998/50000 [4:41:59<19:18,  2.59it/s]04/01/2022 16:43:17 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:43:17 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:43:17 - INFO - __main__ -     Batch size = 8
04/01/2022 16:43:45 - INFO - __main__ -     eval_ppl = 3.76053
04/01/2022 16:43:45 - INFO - __main__ -     global_step = 47000
04/01/2022 16:43:45 - INFO - __main__ -     train_loss = 0.0458
04/01/2022 16:43:45 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:44:09 - INFO - __main__ -     bleu-4 = 35.63 
04/01/2022 16:44:09 - INFO - __main__ -     ********************
loss 0.0455:  96%|█████████▌| 47998/50000 [4:49:00<11:04,  3.01it/s]04/01/2022 16:50:19 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:50:19 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:50:19 - INFO - __main__ -     Batch size = 8
04/01/2022 16:50:45 - INFO - __main__ -     eval_ppl = 3.76136
04/01/2022 16:50:45 - INFO - __main__ -     global_step = 48000
04/01/2022 16:50:45 - INFO - __main__ -     train_loss = 0.0455
04/01/2022 16:50:45 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:51:12 - INFO - __main__ -     bleu-4 = 35.59 
04/01/2022 16:51:12 - INFO - __main__ -     ********************
loss 0.0469:  98%|█████████▊| 48998/50000 [4:56:20<07:13,  2.31it/s]04/01/2022 16:57:39 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 16:57:39 - INFO - __main__ -     Num examples = 2000
04/01/2022 16:57:39 - INFO - __main__ -     Batch size = 8
04/01/2022 16:58:06 - INFO - __main__ -     eval_ppl = 3.75664
04/01/2022 16:58:06 - INFO - __main__ -     global_step = 49000
04/01/2022 16:58:06 - INFO - __main__ -     train_loss = 0.0469
04/01/2022 16:58:06 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 16:58:31 - INFO - __main__ -     bleu-4 = 35.6 
04/01/2022 16:58:31 - INFO - __main__ -     ********************
loss 0.0444: 100%|█████████▉| 49998/50000 [5:03:38<00:00,  2.90it/s]04/01/2022 17:04:57 - INFO - __main__ -   
***** Running evaluation *****
04/01/2022 17:04:57 - INFO - __main__ -     Num examples = 2000
04/01/2022 17:04:57 - INFO - __main__ -     Batch size = 8
04/01/2022 17:05:19 - INFO - __main__ -     eval_ppl = 3.77217
04/01/2022 17:05:19 - INFO - __main__ -     global_step = 50000
04/01/2022 17:05:19 - INFO - __main__ -     train_loss = 0.0444
04/01/2022 17:05:19 - INFO - __main__ -     ********************
Total: 1000
04/01/2022 17:05:41 - INFO - __main__ -     bleu-4 = 35.64 
04/01/2022 17:05:41 - INFO - __main__ -     ********************
loss 0.0083: 100%|██████████| 50000/50000 [5:04:23<00:00,  2.74it/s]

Process finished with exit code 0
