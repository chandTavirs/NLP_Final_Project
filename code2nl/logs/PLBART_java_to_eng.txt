C:\Users\sriva\anaconda3\envs\DLAssignment\python.exe C:/Users/sriva/OneDrive/Documents/Lectures/CE7455/Project/CodeBERT/CodeBERT/code2nl/run.py --do_train --do_eval --model_type=plbart --model_name_or_path=uclanlp/plbart-base --train_filename=data/code2nl/CodeSearchNet/java/train.jsonl --dev_filename=data/code2nl/CodeSearchNet/java/valid.jsonl --output_dir=model/java/plbart --max_source_length=256 --max_target_length=128 --beam_size=10 --train_batch_size=8 --eval_batch_size=8 --learning_rate=5e-5 --train_steps=50000 --eval_steps=1000
03/30/2022 12:28:58 - INFO - __main__ -   Namespace(model_type='plbart', model_name_or_path='uclanlp/plbart-base', output_dir='model/java/plbart', load_model_path=None, train_filename='data/code2nl/CodeSearchNet/java/train.jsonl', dev_filename='data/code2nl/CodeSearchNet/java/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=1000, train_steps=50000, warmup_steps=0, local_rank=-1, seed=42)
03/30/2022 12:28:58 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/30/2022 12:29:22 - INFO - __main__ -   *** Example ***
03/30/2022 12:29:22 - INFO - __main__ -   idx: 0
03/30/2022 12:29:22 - INFO - __main__ -   source_tokens: ['<s>', '▁public', '▁Image', 'Source', '▁apply', '▁(', '▁Image', 'Source', '▁input', '▁)', '▁{', '▁final', '▁int', '▁[', '▁]', '▁[', '▁]', '▁pixel', 'Matrix', '▁=', '▁new', '▁int', '▁[', '▁3', '▁]', '▁[', '▁3', '▁]', '▁;', '▁int', '▁w', '▁=', '▁input', '▁.', '▁getWidth', '▁(', '▁)', '▁;', '▁int', '▁h', '▁=', '▁input', '▁.', '▁getHeight', '▁(', '▁)', '▁;', '▁int', '▁[', '▁]', '▁[', '▁]', '▁output', '▁=', '▁new', '▁int', '▁[', '▁h', '▁]', '▁[', '▁w', '▁]', '▁;', '▁for', '▁(', '▁int', '▁j', '▁=', '▁1', '▁;', '▁j', '▁<', '▁h', '▁-', '▁1', '▁;', '▁j', '▁++', '▁)', '▁{', '▁for', '▁(', '▁int', '▁i', '▁=', '▁1', '▁;', '▁i', '▁<', '▁w', '▁-', '▁1', '▁;', '▁i', '▁++', '▁)', '▁{', '▁pixel', 'Matrix', '▁[', '▁0', '▁]', '▁[', '▁0', '▁]', '▁=', '▁input', '▁.', '▁getR', '▁(', '▁i', '▁-', '▁1', '▁,', '▁j', '▁-', '▁1', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁0', '▁]', '▁[', '▁1', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁-', '▁1', '▁,', '▁j', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁0', '▁]', '▁[', '▁2', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁-', '▁1', '▁,', '▁j', '▁+', '▁1', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁1', '▁]', '▁[', '▁0', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁,', '▁j', '▁-', '▁1', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁1', '▁]', '▁[', '▁2', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁,', '▁j', '▁+', '▁1', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁2', '▁]', '▁[', '▁0', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁+', '▁1', '▁,', '▁j', '▁-', '▁1', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁2', '▁]', '▁[', '▁1', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '▁(', '▁i', '▁+', '▁1', '▁,', '▁j', '▁)', '▁;', '▁pixel', 'Matrix', '▁[', '▁2', '▁]', '▁[', '▁2', '▁]', '▁=', '▁input', '▁.', '▁getRGB', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   source_ids: 0 161 2875 1774 2429 5 2875 1774 641 6 66 405 219 91 99 91 99 4859 4995 24 166 219 91 363 99 91 363 99 43 219 51 24 641 9 7770 5 6 43 219 83 24 641 9 7755 5 6 43 219 91 99 91 99 699 24 166 219 91 83 99 91 51 99 43 126 5 219 191 24 124 43 191 128 83 158 124 43 191 1116 6 66 126 5 219 25 24 124 43 25 128 51 158 124 43 25 1116 6 66 4859 4995 91 142 99 91 142 99 24 641 9 2713 5 25 158 124 16 191 158 124 6 43 4859 4995 91 142 99 91 124 99 24 641 9 28424 5 25 158 124 16 191 6 43 4859 4995 91 142 99 91 217 99 24 641 9 28424 5 25 158 124 16 191 163 124 6 43 4859 4995 91 124 99 91 142 99 24 641 9 28424 5 25 16 191 158 124 6 43 4859 4995 91 124 99 91 217 99 24 641 9 28424 5 25 16 191 163 124 6 43 4859 4995 91 217 99 91 142 99 24 641 9 28424 5 25 163 124 16 191 158 124 6 43 4859 4995 91 217 99 91 124 99 24 641 9 28424 5 25 163 124 16 191 6 43 4859 4995 91 217 99 91 217 99 24 641 9 28424 2
03/30/2022 12:29:22 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_tokens: ['<s>', '▁Expect', 's', '▁a', '▁height', '▁mat', '▁as', '▁input', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   target_ids: 0 12794 33442 14 1636 2870 268 641 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   *** Example ***
03/30/2022 12:29:22 - INFO - __main__ -   idx: 1
03/30/2022 12:29:22 - INFO - __main__ -   source_tokens: ['<s>', '▁public', '▁<', '▁L', '▁extends', '▁Listener', '▁>', '▁void', '▁pop', 'Event', '▁(', '▁Event', '▁<', '▁?', '▁,', '▁L', '▁>', '▁expected', '▁)', '▁{', '▁synchronized', '▁(', '▁this', '▁.', '▁stack', '▁)', '▁{', '▁final', '▁Event', '▁<', '▁?', '▁,', '▁?', '▁>', '▁actual', '▁=', '▁this', '▁.', '▁stack', '▁.', '▁pop', '▁(', '▁)', '▁;', '▁if', '▁(', '▁actual', '▁!=', '▁expected', '▁)', '▁{', '▁throw', '▁new', '▁Illegal', 'StateException', '▁(', '▁String', '▁.', '▁format', '▁(', '▁"', 'Un', 'balanced', '▁pop', ':', '▁expected', "▁'%", 's', "'", '▁but', '▁encountered', "▁'%", 's', '\'"', '▁,', '▁expected', '▁.', '▁get', 'Listener', 'Class', '▁(', '▁)', '▁,', '▁actual', '▁)', '▁)', '▁;', '▁}', '▁}', '▁}', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   source_ids: 0 161 128 282 2305 12848 202 274 1611 950 5 3048 128 593 16 282 202 902 6 66 2997 5 143 9 2268 6 66 405 3048 128 593 16 593 202 2164 24 143 9 2268 9 1611 5 6 43 105 5 2164 472 902 6 66 409 166 2239 5195 5 212 9 753 5 40 1173 29411 1611 33475 902 14693 33442 33473 321 10657 14693 33442 11996 16 902 9 86 1229 679 5 6 16 2164 6 6 43 65 65 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   target_tokens: ['<s>', '▁P', 'ops', '▁the', '▁top', '▁event', '▁off', '▁the', '▁current', '▁event', '▁stack', '▁.', '▁This', '▁action', '▁has', '▁to', '▁be', '▁performed', '▁immediately', '▁after', '▁the', '▁event', '▁has', '▁been', '▁dispatch', 'ed', '▁to', '▁all', '▁listeners', '▁.', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   target_ids: 0 186 2376 57 1482 709 1235 57 759 709 2268 9 670 1144 440 71 229 11919 6999 1081 57 709 440 1740 4874 60 71 515 7400 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   *** Example ***
03/30/2022 12:29:22 - INFO - __main__ -   idx: 2
03/30/2022 12:29:22 - INFO - __main__ -   source_tokens: ['<s>', '▁protected', '▁void', '▁modify', '▁(', '▁Transaction', '▁t', '▁)', '▁{', '▁try', '▁{', '▁this', '▁.', '▁lock', '▁.', '▁writeLock', '▁(', '▁)', '▁.', '▁lock', '▁(', '▁)', '▁;', '▁t', '▁.', '▁perform', '▁(', '▁)', '▁;', '▁}', '▁finally', '▁{', '▁this', '▁.', '▁lock', '▁.', '▁writeLock', '▁(', '▁)', '▁.', '▁unlock', '▁(', '▁)', '▁;', '▁}', '▁}', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   source_ids: 0 1159 274 3612 5 6525 7 6 66 367 66 143 9 2845 9 22474 5 6 9 2845 5 6 43 7 9 2272 5 6 43 65 2240 66 143 9 2845 9 22474 5 6 9 9982 5 6 43 65 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   target_tokens: ['<s>', '▁Exec', 'utes', '▁the', '▁given', '▁transaction', '▁within', '▁the', '▁context', '▁of', '▁a', '▁write', '▁lock', '▁.', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   target_ids: 0 3916 1338 57 2511 3777 2382 57 557 153 14 661 2845 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   *** Example ***
03/30/2022 12:29:22 - INFO - __main__ -   idx: 3
03/30/2022 12:29:22 - INFO - __main__ -   source_tokens: ['<s>', '▁protected', '▁<', '▁E', '▁>', '▁E', '▁read', '▁(', '▁Supplier', '▁<', '▁E', '▁>', '▁sup', '▁)', '▁{', '▁try', '▁{', '▁this', '▁.', '▁lock', '▁.', '▁readLock', '▁(', '▁)', '▁.', '▁lock', '▁(', '▁)', '▁;', '▁return', '▁sup', '▁.', '▁get', '▁(', '▁)', '▁;', '▁}', '▁finally', '▁{', '▁this', '▁.', '▁lock', '▁.', '▁readLock', '▁(', '▁)', '▁.', '▁unlock', '▁(', '▁)', '▁;', '▁}', '▁}', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   source_ids: 0 1159 128 315 202 315 529 5 16392 128 315 202 13626 6 66 367 66 143 9 2845 9 19775 5 6 9 2845 5 6 43 111 13626 9 86 5 6 43 65 2240 66 143 9 2845 9 19775 5 6 9 9982 5 6 43 65 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   target_tokens: ['<s>', '▁Exec', 'utes', '▁the', '▁given', '▁supplier', '▁within', '▁the', '▁context', '▁of', '▁a', '▁read', '▁lock', '▁.', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   target_ids: 0 3916 1338 57 2511 15026 2382 57 557 153 14 529 2845 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   *** Example ***
03/30/2022 12:29:22 - INFO - __main__ -   idx: 4
03/30/2022 12:29:22 - INFO - __main__ -   source_tokens: ['<s>', '▁protected', '▁void', '▁set', 'Offset', 'And', 'Length', '▁(', '▁long', '▁offset', '▁,', '▁int', '▁length', '▁)', '▁throws', '▁IOException', '▁{', '▁this', '▁.', '▁offset', '▁=', '▁offset', '▁;', '▁this', '▁.', '▁length', '▁=', '▁length', '▁;', '▁this', '▁.', '▁position', '▁=', '▁0', '▁;', '▁if', '▁(', '▁sub', 'Stream', '▁.', '▁position', '▁(', '▁)', '▁!=', '▁offset', '▁)', '▁{', '▁sub', 'Stream', '▁.', '▁seek', '▁(', '▁offset', '▁)', '▁;', '▁}', '▁}', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   source_ids: 0 1159 274 193 2395 1501 2249 5 883 1784 16 219 781 6 600 1363 66 143 9 1784 24 1784 43 143 9 781 24 781 43 143 9 1444 24 142 43 105 5 577 949 9 1444 5 6 472 1784 6 66 577 949 9 5639 5 1784 6 43 65 65 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/30/2022 12:29:22 - INFO - __main__ -   target_tokens: ['<s>', '▁This', '▁should', '▁be', '▁called', '▁from', '▁a', '▁subclass', '▁constructor', '▁if', '▁offset', '▁or', '▁length', '▁are', '▁unknown', '▁at', '▁a', '▁time', '▁when', '▁Sub', 'I', 'IM', 'InputStream', '▁constructor', '▁is', '▁called', '▁.', '▁This', '▁method', '▁shouldn', '▁t', '▁be', '▁called', '▁more', '▁than', '▁once', '▁.', '</s>']
03/30/2022 12:29:22 - INFO - __main__ -   target_ids: 0 670 595 229 1664 320 14 6510 2802 105 1784 255 781 395 4840 341 14 565 509 3079 33462 5304 3021 2802 96 1664 9 670 483 6822 7 229 1664 1010 1433 2742 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/30/2022 12:29:22 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
C:\Users\sriva\anaconda3\envs\DLAssignment\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/30/2022 12:31:06 - INFO - __main__ -   ***** Running training *****
03/30/2022 12:31:06 - INFO - __main__ -     Num examples = 164923
03/30/2022 12:31:06 - INFO - __main__ -     Batch size = 8
03/30/2022 12:31:06 - INFO - __main__ -     Num epoch = 2
loss 3.0257:   2%|▏         | 998/50000 [03:43<2:57:04,  4.61it/s]03/30/2022 12:34:53 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:34:53 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:34:53 - INFO - __main__ -     Batch size = 8
03/30/2022 12:35:32 - INFO - __main__ -     eval_ppl = 18.0064
03/30/2022 12:35:32 - INFO - __main__ -     global_step = 1000
03/30/2022 12:35:32 - INFO - __main__ -     train_loss = 3.0257
03/30/2022 12:35:32 - INFO - __main__ -     ********************
03/30/2022 12:35:33 - INFO - __main__ -     Best ppl:18.0064
03/30/2022 12:35:33 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:35:52 - INFO - __main__ -     bleu-4 = 15.93 
03/30/2022 12:35:52 - INFO - __main__ -     ********************
03/30/2022 12:35:52 - INFO - __main__ -     Best bleu:15.93
03/30/2022 12:35:52 - INFO - __main__ -     ********************
loss 2.9415:   4%|▍         | 1998/50000 [08:32<3:01:34,  4.41it/s]03/30/2022 12:39:39 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:39:39 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:39:39 - INFO - __main__ -     Batch size = 8
03/30/2022 12:40:19 - INFO - __main__ -     eval_ppl = 16.69514
03/30/2022 12:40:19 - INFO - __main__ -     global_step = 2000
03/30/2022 12:40:19 - INFO - __main__ -     train_loss = 2.9415
03/30/2022 12:40:19 - INFO - __main__ -     ********************
03/30/2022 12:40:20 - INFO - __main__ -     Best ppl:16.69514
03/30/2022 12:40:20 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:40:39 - INFO - __main__ -     bleu-4 = 16.5 
03/30/2022 12:40:39 - INFO - __main__ -     ********************
03/30/2022 12:40:39 - INFO - __main__ -     Best bleu:16.5
03/30/2022 12:40:39 - INFO - __main__ -     ********************
loss 2.8582:   6%|▌         | 2998/50000 [13:19<2:55:43,  4.46it/s]03/30/2022 12:44:25 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:44:25 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:44:25 - INFO - __main__ -     Batch size = 8
03/30/2022 12:45:05 - INFO - __main__ -     eval_ppl = 16.84162
03/30/2022 12:45:05 - INFO - __main__ -     global_step = 3000
03/30/2022 12:45:05 - INFO - __main__ -     train_loss = 2.8582
03/30/2022 12:45:05 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:45:23 - INFO - __main__ -     bleu-4 = 16.45 
03/30/2022 12:45:23 - INFO - __main__ -     ********************
loss 2.8463:   8%|▊         | 3998/50000 [17:58<2:51:42,  4.47it/s]03/30/2022 12:49:04 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:49:04 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:49:04 - INFO - __main__ -     Batch size = 8
03/30/2022 12:49:44 - INFO - __main__ -     eval_ppl = 16.3201
03/30/2022 12:49:44 - INFO - __main__ -     global_step = 4000
03/30/2022 12:49:44 - INFO - __main__ -     train_loss = 2.8463
03/30/2022 12:49:44 - INFO - __main__ -     ********************
03/30/2022 12:49:45 - INFO - __main__ -     Best ppl:16.3201
03/30/2022 12:49:45 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:50:04 - INFO - __main__ -     bleu-4 = 16.84 
03/30/2022 12:50:04 - INFO - __main__ -     ********************
03/30/2022 12:50:04 - INFO - __main__ -     Best bleu:16.84
03/30/2022 12:50:04 - INFO - __main__ -     ********************
loss 2.8336:  10%|▉         | 4998/50000 [22:43<2:51:24,  4.38it/s]03/30/2022 12:53:50 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:53:50 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:53:50 - INFO - __main__ -     Batch size = 8
03/30/2022 12:54:29 - INFO - __main__ -     eval_ppl = 15.98812
03/30/2022 12:54:29 - INFO - __main__ -     global_step = 5000
03/30/2022 12:54:29 - INFO - __main__ -     train_loss = 2.8336
03/30/2022 12:54:29 - INFO - __main__ -     ********************
03/30/2022 12:54:30 - INFO - __main__ -     Best ppl:15.98812
03/30/2022 12:54:30 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:54:48 - INFO - __main__ -     bleu-4 = 17.92 
03/30/2022 12:54:48 - INFO - __main__ -     ********************
03/30/2022 12:54:48 - INFO - __main__ -     Best bleu:17.92
03/30/2022 12:54:48 - INFO - __main__ -     ********************
loss 2.7916:  12%|█▏        | 5998/50000 [27:23<2:46:39,  4.40it/s]03/30/2022 12:58:30 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 12:58:30 - INFO - __main__ -     Num examples = 5183
03/30/2022 12:58:30 - INFO - __main__ -     Batch size = 8
03/30/2022 12:59:10 - INFO - __main__ -     eval_ppl = 15.96967
03/30/2022 12:59:10 - INFO - __main__ -     global_step = 6000
03/30/2022 12:59:10 - INFO - __main__ -     train_loss = 2.7916
03/30/2022 12:59:10 - INFO - __main__ -     ********************
03/30/2022 12:59:11 - INFO - __main__ -     Best ppl:15.96967
03/30/2022 12:59:11 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 12:59:30 - INFO - __main__ -     bleu-4 = 17.87 
03/30/2022 12:59:30 - INFO - __main__ -     ********************
loss 2.7531:  14%|█▍        | 6998/50000 [32:10<2:42:57,  4.40it/s]03/30/2022 13:03:16 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:03:16 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:03:16 - INFO - __main__ -     Batch size = 8
03/30/2022 13:03:56 - INFO - __main__ -     eval_ppl = 15.78519
03/30/2022 13:03:56 - INFO - __main__ -     global_step = 7000
03/30/2022 13:03:56 - INFO - __main__ -     train_loss = 2.7531
03/30/2022 13:03:56 - INFO - __main__ -     ********************
03/30/2022 13:03:57 - INFO - __main__ -     Best ppl:15.78519
03/30/2022 13:03:57 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:04:15 - INFO - __main__ -     bleu-4 = 18.09 
03/30/2022 13:04:15 - INFO - __main__ -     ********************
03/30/2022 13:04:15 - INFO - __main__ -     Best bleu:18.09
03/30/2022 13:04:15 - INFO - __main__ -     ********************
loss 2.7594:  16%|█▌        | 7998/50000 [36:56<2:37:53,  4.43it/s]03/30/2022 13:08:02 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:08:02 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:08:02 - INFO - __main__ -     Batch size = 8
03/30/2022 13:08:43 - INFO - __main__ -     eval_ppl = 15.63993
03/30/2022 13:08:43 - INFO - __main__ -     global_step = 8000
03/30/2022 13:08:43 - INFO - __main__ -     train_loss = 2.7594
03/30/2022 13:08:43 - INFO - __main__ -     ********************
03/30/2022 13:08:44 - INFO - __main__ -     Best ppl:15.63993
03/30/2022 13:08:44 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:09:01 - INFO - __main__ -     bleu-4 = 18.4 
03/30/2022 13:09:01 - INFO - __main__ -     ********************
03/30/2022 13:09:01 - INFO - __main__ -     Best bleu:18.4
03/30/2022 13:09:01 - INFO - __main__ -     ********************
loss 2.7439:  18%|█▊        | 8998/50000 [41:43<2:35:50,  4.39it/s]03/30/2022 13:12:49 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:12:49 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:12:49 - INFO - __main__ -     Batch size = 8
03/30/2022 13:13:30 - INFO - __main__ -     eval_ppl = 15.30275
03/30/2022 13:13:30 - INFO - __main__ -     global_step = 9000
03/30/2022 13:13:30 - INFO - __main__ -     train_loss = 2.7439
03/30/2022 13:13:30 - INFO - __main__ -     ********************
03/30/2022 13:13:30 - INFO - __main__ -     Best ppl:15.30275
03/30/2022 13:13:30 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:13:48 - INFO - __main__ -     bleu-4 = 18.54 
03/30/2022 13:13:48 - INFO - __main__ -     ********************
03/30/2022 13:13:48 - INFO - __main__ -     Best bleu:18.54
03/30/2022 13:13:48 - INFO - __main__ -     ********************
loss 2.72:  20%|█▉        | 9998/50000 [46:30<2:32:01,  4.39it/s]  03/30/2022 13:17:37 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:17:37 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:17:37 - INFO - __main__ -     Batch size = 8
03/30/2022 13:18:17 - INFO - __main__ -     eval_ppl = 15.42827
03/30/2022 13:18:17 - INFO - __main__ -     global_step = 10000
03/30/2022 13:18:17 - INFO - __main__ -     train_loss = 2.72
03/30/2022 13:18:17 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:18:35 - INFO - __main__ -     bleu-4 = 18.25 
03/30/2022 13:18:35 - INFO - __main__ -     ********************
loss 2.7022:  22%|██▏       | 10998/50000 [51:17<2:29:19,  4.35it/s]03/30/2022 13:22:23 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:22:23 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:22:23 - INFO - __main__ -     Batch size = 8
03/30/2022 13:23:04 - INFO - __main__ -     eval_ppl = 15.23364
03/30/2022 13:23:04 - INFO - __main__ -     global_step = 11000
03/30/2022 13:23:04 - INFO - __main__ -     train_loss = 2.7022
03/30/2022 13:23:04 - INFO - __main__ -     ********************
03/30/2022 13:23:05 - INFO - __main__ -     Best ppl:15.23364
03/30/2022 13:23:05 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:23:22 - INFO - __main__ -     bleu-4 = 18.03 
03/30/2022 13:23:22 - INFO - __main__ -     ********************
loss 2.6945:  24%|██▍       | 11998/50000 [56:04<2:24:20,  4.39it/s]03/30/2022 13:27:11 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:27:11 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:27:11 - INFO - __main__ -     Batch size = 8
03/30/2022 13:27:51 - INFO - __main__ -     eval_ppl = 14.92084
03/30/2022 13:27:51 - INFO - __main__ -     global_step = 12000
03/30/2022 13:27:51 - INFO - __main__ -     train_loss = 2.6945
03/30/2022 13:27:51 - INFO - __main__ -     ********************
03/30/2022 13:27:52 - INFO - __main__ -     Best ppl:14.92084
03/30/2022 13:27:52 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:28:10 - INFO - __main__ -     bleu-4 = 18.92 
03/30/2022 13:28:10 - INFO - __main__ -     ********************
03/30/2022 13:28:10 - INFO - __main__ -     Best bleu:18.92
03/30/2022 13:28:10 - INFO - __main__ -     ********************
loss 2.6336:  26%|██▌       | 12998/50000 [1:00:53<2:21:48,  4.35it/s]03/30/2022 13:32:00 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:32:00 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:32:00 - INFO - __main__ -     Batch size = 8
03/30/2022 13:32:40 - INFO - __main__ -     eval_ppl = 14.87715
03/30/2022 13:32:40 - INFO - __main__ -     global_step = 13000
03/30/2022 13:32:40 - INFO - __main__ -     train_loss = 2.6336
03/30/2022 13:32:40 - INFO - __main__ -     ********************
03/30/2022 13:32:41 - INFO - __main__ -     Best ppl:14.87715
03/30/2022 13:32:41 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:32:58 - INFO - __main__ -     bleu-4 = 18.44 
03/30/2022 13:32:58 - INFO - __main__ -     ********************
loss 2.6821:  28%|██▊       | 13998/50000 [1:05:46<2:35:46,  3.85it/s]03/30/2022 13:36:53 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:36:53 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:36:53 - INFO - __main__ -     Batch size = 8
03/30/2022 13:37:35 - INFO - __main__ -     eval_ppl = 14.92957
03/30/2022 13:37:35 - INFO - __main__ -     global_step = 14000
03/30/2022 13:37:35 - INFO - __main__ -     train_loss = 2.6821
03/30/2022 13:37:35 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:37:52 - INFO - __main__ -     bleu-4 = 18.29 
03/30/2022 13:37:52 - INFO - __main__ -     ********************
loss 2.6212:  30%|██▉       | 14998/50000 [1:10:59<2:07:58,  4.56it/s]03/30/2022 13:42:06 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:42:06 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:42:06 - INFO - __main__ -     Batch size = 8
03/30/2022 13:42:49 - INFO - __main__ -     eval_ppl = 14.67532
03/30/2022 13:42:49 - INFO - __main__ -     global_step = 15000
03/30/2022 13:42:49 - INFO - __main__ -     train_loss = 2.6212
03/30/2022 13:42:49 - INFO - __main__ -     ********************
03/30/2022 13:42:49 - INFO - __main__ -     Best ppl:14.67532
03/30/2022 13:42:49 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:43:08 - INFO - __main__ -     bleu-4 = 18.43 
03/30/2022 13:43:08 - INFO - __main__ -     ********************
loss 2.6198:  32%|███▏      | 15998/50000 [1:16:35<2:33:28,  3.69it/s]03/30/2022 13:47:42 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:47:42 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:47:42 - INFO - __main__ -     Batch size = 8
03/30/2022 13:48:29 - INFO - __main__ -     eval_ppl = 14.63761
03/30/2022 13:48:29 - INFO - __main__ -     global_step = 16000
03/30/2022 13:48:29 - INFO - __main__ -     train_loss = 2.6198
03/30/2022 13:48:29 - INFO - __main__ -     ********************
03/30/2022 13:48:30 - INFO - __main__ -     Best ppl:14.63761
03/30/2022 13:48:30 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:48:50 - INFO - __main__ -     bleu-4 = 18.47 
03/30/2022 13:48:50 - INFO - __main__ -     ********************
loss 2.5875:  34%|███▍      | 16998/50000 [1:22:17<2:31:27,  3.63it/s]03/30/2022 13:53:24 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:53:24 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:53:24 - INFO - __main__ -     Batch size = 8
03/30/2022 13:54:11 - INFO - __main__ -     eval_ppl = 14.47611
03/30/2022 13:54:11 - INFO - __main__ -     global_step = 17000
03/30/2022 13:54:11 - INFO - __main__ -     train_loss = 2.5875
03/30/2022 13:54:11 - INFO - __main__ -     ********************
03/30/2022 13:54:12 - INFO - __main__ -     Best ppl:14.47611
03/30/2022 13:54:12 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:54:31 - INFO - __main__ -     bleu-4 = 19.0 
03/30/2022 13:54:31 - INFO - __main__ -     ********************
03/30/2022 13:54:31 - INFO - __main__ -     Best bleu:19.0
03/30/2022 13:54:31 - INFO - __main__ -     ********************
loss 2.5954:  36%|███▌      | 17998/50000 [1:27:19<2:06:45,  4.21it/s]03/30/2022 13:58:26 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 13:58:26 - INFO - __main__ -     Num examples = 5183
03/30/2022 13:58:26 - INFO - __main__ -     Batch size = 8
03/30/2022 13:59:04 - INFO - __main__ -     eval_ppl = 14.38072
03/30/2022 13:59:04 - INFO - __main__ -     global_step = 18000
03/30/2022 13:59:04 - INFO - __main__ -     train_loss = 2.5954
03/30/2022 13:59:04 - INFO - __main__ -     ********************
03/30/2022 13:59:05 - INFO - __main__ -     Best ppl:14.38072
03/30/2022 13:59:05 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 13:59:22 - INFO - __main__ -     bleu-4 = 18.86 
03/30/2022 13:59:22 - INFO - __main__ -     ********************
loss 2.5906:  38%|███▊      | 18998/50000 [1:31:52<1:51:03,  4.65it/s]03/30/2022 14:02:58 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:02:58 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:02:58 - INFO - __main__ -     Batch size = 8
03/30/2022 14:03:36 - INFO - __main__ -     eval_ppl = 14.35477
03/30/2022 14:03:36 - INFO - __main__ -     global_step = 19000
03/30/2022 14:03:36 - INFO - __main__ -     train_loss = 2.5906
03/30/2022 14:03:36 - INFO - __main__ -     ********************
03/30/2022 14:03:37 - INFO - __main__ -     Best ppl:14.35477
03/30/2022 14:03:37 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:03:55 - INFO - __main__ -     bleu-4 = 18.61 
03/30/2022 14:03:55 - INFO - __main__ -     ********************
loss 2.6026:  40%|███▉      | 19998/50000 [1:36:46<2:16:37,  3.66it/s]03/30/2022 14:07:53 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:07:53 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:07:53 - INFO - __main__ -     Batch size = 8
03/30/2022 14:08:40 - INFO - __main__ -     eval_ppl = 14.22796
03/30/2022 14:08:40 - INFO - __main__ -     global_step = 20000
03/30/2022 14:08:40 - INFO - __main__ -     train_loss = 2.6026
03/30/2022 14:08:40 - INFO - __main__ -     ********************
03/30/2022 14:08:41 - INFO - __main__ -     Best ppl:14.22796
03/30/2022 14:08:41 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:09:00 - INFO - __main__ -     bleu-4 = 18.71 
03/30/2022 14:09:00 - INFO - __main__ -     ********************
loss 2.4939:  42%|████▏     | 20998/50000 [1:42:14<2:05:58,  3.84it/s]03/30/2022 14:13:21 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:13:21 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:13:21 - INFO - __main__ -     Batch size = 8
03/30/2022 14:14:06 - INFO - __main__ -     eval_ppl = 14.65448
03/30/2022 14:14:06 - INFO - __main__ -     global_step = 21000
03/30/2022 14:14:06 - INFO - __main__ -     train_loss = 2.4939
03/30/2022 14:14:06 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:14:24 - INFO - __main__ -     bleu-4 = 18.85 
03/30/2022 14:14:24 - INFO - __main__ -     ********************
loss 2.2963:  44%|████▍     | 21998/50000 [1:47:30<1:40:23,  4.65it/s]03/30/2022 14:18:36 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:18:36 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:18:36 - INFO - __main__ -     Batch size = 8
03/30/2022 14:19:14 - INFO - __main__ -     eval_ppl = 14.53316
03/30/2022 14:19:14 - INFO - __main__ -     global_step = 22000
03/30/2022 14:19:14 - INFO - __main__ -     train_loss = 2.2963
03/30/2022 14:19:14 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:19:32 - INFO - __main__ -     bleu-4 = 18.89 
03/30/2022 14:19:32 - INFO - __main__ -     ********************
loss 2.2884:  46%|████▌     | 22998/50000 [1:52:00<1:37:17,  4.63it/s]03/30/2022 14:23:07 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:23:07 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:23:07 - INFO - __main__ -     Batch size = 8
03/30/2022 14:23:45 - INFO - __main__ -     eval_ppl = 14.68351
03/30/2022 14:23:45 - INFO - __main__ -     global_step = 23000
03/30/2022 14:23:45 - INFO - __main__ -     train_loss = 2.2884
03/30/2022 14:23:45 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:24:03 - INFO - __main__ -     bleu-4 = 18.72 
03/30/2022 14:24:03 - INFO - __main__ -     ********************
loss 2.2315:  48%|████▊     | 23998/50000 [1:56:32<1:33:18,  4.64it/s]03/30/2022 14:27:39 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:27:39 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:27:39 - INFO - __main__ -     Batch size = 8
03/30/2022 14:28:17 - INFO - __main__ -     eval_ppl = 14.64745
03/30/2022 14:28:17 - INFO - __main__ -     global_step = 24000
03/30/2022 14:28:17 - INFO - __main__ -     train_loss = 2.2315
03/30/2022 14:28:17 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:28:34 - INFO - __main__ -     bleu-4 = 18.32 
03/30/2022 14:28:34 - INFO - __main__ -     ********************
loss 2.2375:  50%|████▉     | 24998/50000 [2:01:03<1:29:51,  4.64it/s]03/30/2022 14:32:10 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:32:10 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:32:10 - INFO - __main__ -     Batch size = 8
03/30/2022 14:32:48 - INFO - __main__ -     eval_ppl = 14.79081
03/30/2022 14:32:48 - INFO - __main__ -     global_step = 25000
03/30/2022 14:32:48 - INFO - __main__ -     train_loss = 2.2375
03/30/2022 14:32:48 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:33:06 - INFO - __main__ -     bleu-4 = 18.48 
03/30/2022 14:33:06 - INFO - __main__ -     ********************
loss 2.2475:  52%|█████▏    | 25998/50000 [2:05:35<1:26:07,  4.64it/s]03/30/2022 14:36:41 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:36:41 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:36:41 - INFO - __main__ -     Batch size = 8
03/30/2022 14:37:19 - INFO - __main__ -     eval_ppl = 14.71443
03/30/2022 14:37:19 - INFO - __main__ -     global_step = 26000
03/30/2022 14:37:19 - INFO - __main__ -     train_loss = 2.2475
03/30/2022 14:37:19 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:37:38 - INFO - __main__ -     bleu-4 = 18.28 
03/30/2022 14:37:38 - INFO - __main__ -     ********************
loss 2.1907:  54%|█████▍    | 26998/50000 [2:10:07<1:22:32,  4.64it/s]03/30/2022 14:41:14 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:41:14 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:41:14 - INFO - __main__ -     Batch size = 8
03/30/2022 14:41:52 - INFO - __main__ -     eval_ppl = 14.74069
03/30/2022 14:41:52 - INFO - __main__ -     global_step = 27000
03/30/2022 14:41:52 - INFO - __main__ -     train_loss = 2.1907
03/30/2022 14:41:52 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:42:10 - INFO - __main__ -     bleu-4 = 19.38 
03/30/2022 14:42:10 - INFO - __main__ -     ********************
03/30/2022 14:42:10 - INFO - __main__ -     Best bleu:19.38
03/30/2022 14:42:10 - INFO - __main__ -     ********************
loss 2.2016:  56%|█████▌    | 27998/50000 [2:15:16<1:41:00,  3.63it/s]03/30/2022 14:46:23 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:46:23 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:46:23 - INFO - __main__ -     Batch size = 8
03/30/2022 14:47:10 - INFO - __main__ -     eval_ppl = 14.93968
03/30/2022 14:47:10 - INFO - __main__ -     global_step = 28000
03/30/2022 14:47:10 - INFO - __main__ -     train_loss = 2.2016
03/30/2022 14:47:10 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:47:29 - INFO - __main__ -     bleu-4 = 19.14 
03/30/2022 14:47:29 - INFO - __main__ -     ********************
loss 2.1862:  58%|█████▊    | 28998/50000 [2:20:56<1:36:17,  3.64it/s]03/30/2022 14:52:03 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:52:03 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:52:03 - INFO - __main__ -     Batch size = 8
03/30/2022 14:52:50 - INFO - __main__ -     eval_ppl = 14.64679
03/30/2022 14:52:50 - INFO - __main__ -     global_step = 29000
03/30/2022 14:52:50 - INFO - __main__ -     train_loss = 2.1862
03/30/2022 14:52:50 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:53:10 - INFO - __main__ -     bleu-4 = 19.06 
03/30/2022 14:53:10 - INFO - __main__ -     ********************
loss 2.1965:  60%|█████▉    | 29998/50000 [2:26:05<1:27:23,  3.81it/s]03/30/2022 14:57:11 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 14:57:11 - INFO - __main__ -     Num examples = 5183
03/30/2022 14:57:11 - INFO - __main__ -     Batch size = 8
03/30/2022 14:57:56 - INFO - __main__ -     eval_ppl = 14.63047
03/30/2022 14:57:56 - INFO - __main__ -     global_step = 30000
03/30/2022 14:57:56 - INFO - __main__ -     train_loss = 2.1965
03/30/2022 14:57:56 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 14:58:15 - INFO - __main__ -     bleu-4 = 19.32 
03/30/2022 14:58:15 - INFO - __main__ -     ********************
loss 2.1704:  62%|██████▏   | 30998/50000 [2:31:27<1:21:55,  3.87it/s]03/30/2022 15:02:34 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:02:34 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:02:34 - INFO - __main__ -     Batch size = 8
03/30/2022 15:03:19 - INFO - __main__ -     eval_ppl = 14.60676
03/30/2022 15:03:19 - INFO - __main__ -     global_step = 31000
03/30/2022 15:03:19 - INFO - __main__ -     train_loss = 2.1704
03/30/2022 15:03:19 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:03:38 - INFO - __main__ -     bleu-4 = 18.61 
03/30/2022 15:03:38 - INFO - __main__ -     ********************
loss 2.1752:  64%|██████▍   | 31998/50000 [2:36:52<1:21:57,  3.66it/s]03/30/2022 15:07:58 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:07:58 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:07:58 - INFO - __main__ -     Batch size = 8
03/30/2022 15:08:46 - INFO - __main__ -     eval_ppl = 14.31808
03/30/2022 15:08:46 - INFO - __main__ -     global_step = 32000
03/30/2022 15:08:46 - INFO - __main__ -     train_loss = 2.1752
03/30/2022 15:08:46 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:09:05 - INFO - __main__ -     bleu-4 = 18.81 
03/30/2022 15:09:05 - INFO - __main__ -     ********************
loss 2.1397:  66%|██████▌   | 32998/50000 [2:42:26<1:00:46,  4.66it/s]03/30/2022 15:13:32 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:13:32 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:13:32 - INFO - __main__ -     Batch size = 8
03/30/2022 15:14:10 - INFO - __main__ -     eval_ppl = 14.46759
03/30/2022 15:14:10 - INFO - __main__ -     global_step = 33000
03/30/2022 15:14:10 - INFO - __main__ -     train_loss = 2.1397
03/30/2022 15:14:10 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:14:28 - INFO - __main__ -     bleu-4 = 19.13 
03/30/2022 15:14:28 - INFO - __main__ -     ********************
loss 2.1344:  68%|██████▊   | 33998/50000 [2:47:21<59:03,  4.52it/s]03/30/2022 15:18:27 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:18:27 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:18:27 - INFO - __main__ -     Batch size = 8
03/30/2022 15:19:07 - INFO - __main__ -     eval_ppl = 14.30045
03/30/2022 15:19:07 - INFO - __main__ -     global_step = 34000
03/30/2022 15:19:07 - INFO - __main__ -     train_loss = 2.1344
03/30/2022 15:19:07 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:19:25 - INFO - __main__ -     bleu-4 = 19.37 
03/30/2022 15:19:25 - INFO - __main__ -     ********************
loss 2.164:  70%|██████▉   | 34998/50000 [2:52:00<57:39,  4.34it/s] 03/30/2022 15:23:07 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:23:07 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:23:07 - INFO - __main__ -     Batch size = 8
03/30/2022 15:23:53 - INFO - __main__ -     eval_ppl = 14.41356
03/30/2022 15:23:53 - INFO - __main__ -     global_step = 35000
03/30/2022 15:23:53 - INFO - __main__ -     train_loss = 2.164
03/30/2022 15:23:53 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:24:12 - INFO - __main__ -     bleu-4 = 19.26 
03/30/2022 15:24:12 - INFO - __main__ -     ********************
loss 2.1194:  72%|███████▏  | 35998/50000 [2:57:37<1:03:16,  3.69it/s]03/30/2022 15:28:44 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:28:44 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:28:44 - INFO - __main__ -     Batch size = 8
03/30/2022 15:29:30 - INFO - __main__ -     eval_ppl = 14.20361
03/30/2022 15:29:30 - INFO - __main__ -     global_step = 36000
03/30/2022 15:29:30 - INFO - __main__ -     train_loss = 2.1194
03/30/2022 15:29:30 - INFO - __main__ -     ********************
03/30/2022 15:29:31 - INFO - __main__ -     Best ppl:14.20361
03/30/2022 15:29:31 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:29:50 - INFO - __main__ -     bleu-4 = 18.71 
03/30/2022 15:29:50 - INFO - __main__ -     ********************
loss 2.1165:  74%|███████▍  | 36998/50000 [3:03:16<58:43,  3.69it/s]03/30/2022 15:34:22 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:34:22 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:34:22 - INFO - __main__ -     Batch size = 8
03/30/2022 15:35:09 - INFO - __main__ -     eval_ppl = 14.3251
03/30/2022 15:35:09 - INFO - __main__ -     global_step = 37000
03/30/2022 15:35:09 - INFO - __main__ -     train_loss = 2.1165
03/30/2022 15:35:09 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:35:28 - INFO - __main__ -     bleu-4 = 19.17 
03/30/2022 15:35:28 - INFO - __main__ -     ********************
loss 2.0944:  76%|███████▌  | 37998/50000 [3:08:40<52:43,  3.79it/s]03/30/2022 15:39:46 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:39:46 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:39:46 - INFO - __main__ -     Batch size = 8
03/30/2022 15:40:32 - INFO - __main__ -     eval_ppl = 14.10858
03/30/2022 15:40:32 - INFO - __main__ -     global_step = 38000
03/30/2022 15:40:32 - INFO - __main__ -     train_loss = 2.0944
03/30/2022 15:40:32 - INFO - __main__ -     ********************
03/30/2022 15:40:33 - INFO - __main__ -     Best ppl:14.10858
03/30/2022 15:40:33 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:40:51 - INFO - __main__ -     bleu-4 = 19.7 
03/30/2022 15:40:51 - INFO - __main__ -     ********************
03/30/2022 15:40:51 - INFO - __main__ -     Best bleu:19.7
03/30/2022 15:40:51 - INFO - __main__ -     ********************
loss 2.1254:  78%|███████▊  | 38998/50000 [3:14:08<49:47,  3.68it/s]03/30/2022 15:45:15 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:45:15 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:45:15 - INFO - __main__ -     Batch size = 8
03/30/2022 15:46:02 - INFO - __main__ -     eval_ppl = 14.0637
03/30/2022 15:46:02 - INFO - __main__ -     global_step = 39000
03/30/2022 15:46:02 - INFO - __main__ -     train_loss = 2.1254
03/30/2022 15:46:02 - INFO - __main__ -     ********************
03/30/2022 15:46:03 - INFO - __main__ -     Best ppl:14.0637
03/30/2022 15:46:03 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:46:22 - INFO - __main__ -     bleu-4 = 19.29 
03/30/2022 15:46:22 - INFO - __main__ -     ********************
loss 2.1146:  80%|███████▉  | 39998/50000 [3:19:19<36:01,  4.63it/s]03/30/2022 15:50:25 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:50:25 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:50:25 - INFO - __main__ -     Batch size = 8
03/30/2022 15:51:04 - INFO - __main__ -     eval_ppl = 14.17343
03/30/2022 15:51:04 - INFO - __main__ -     global_step = 40000
03/30/2022 15:51:04 - INFO - __main__ -     train_loss = 2.1146
03/30/2022 15:51:04 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:51:22 - INFO - __main__ -     bleu-4 = 19.69 
03/30/2022 15:51:22 - INFO - __main__ -     ********************
loss 2.1342:  82%|████████▏ | 40998/50000 [3:24:23<41:24,  3.62it/s]03/30/2022 15:55:30 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 15:55:30 - INFO - __main__ -     Num examples = 5183
03/30/2022 15:55:30 - INFO - __main__ -     Batch size = 8
03/30/2022 15:56:17 - INFO - __main__ -     eval_ppl = 14.00395
03/30/2022 15:56:17 - INFO - __main__ -     global_step = 41000
03/30/2022 15:56:17 - INFO - __main__ -     train_loss = 2.1342
03/30/2022 15:56:17 - INFO - __main__ -     ********************
03/30/2022 15:56:18 - INFO - __main__ -     Best ppl:14.00395
03/30/2022 15:56:18 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 15:56:38 - INFO - __main__ -     bleu-4 = 19.18 
03/30/2022 15:56:38 - INFO - __main__ -     ********************
loss 1.9422:  84%|████████▍ | 41998/50000 [3:30:05<37:23,  3.57it/s]03/30/2022 16:01:12 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:01:12 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:01:12 - INFO - __main__ -     Batch size = 8
03/30/2022 16:01:59 - INFO - __main__ -     eval_ppl = 14.86323
03/30/2022 16:01:59 - INFO - __main__ -     global_step = 42000
03/30/2022 16:01:59 - INFO - __main__ -     train_loss = 1.9422
03/30/2022 16:01:59 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:02:19 - INFO - __main__ -     bleu-4 = 19.11 
03/30/2022 16:02:19 - INFO - __main__ -     ********************
loss 1.8605:  86%|████████▌ | 42998/50000 [3:35:16<26:55,  4.33it/s]03/30/2022 16:06:23 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:06:23 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:06:23 - INFO - __main__ -     Batch size = 8
03/30/2022 16:07:09 - INFO - __main__ -     eval_ppl = 15.06856
03/30/2022 16:07:09 - INFO - __main__ -     global_step = 43000
03/30/2022 16:07:09 - INFO - __main__ -     train_loss = 1.8605
03/30/2022 16:07:09 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:07:28 - INFO - __main__ -     bleu-4 = 19.14 
03/30/2022 16:07:28 - INFO - __main__ -     ********************
loss 1.8458:  88%|████████▊ | 43998/50000 [3:40:52<26:48,  3.73it/s]03/30/2022 16:11:59 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:11:59 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:11:59 - INFO - __main__ -     Batch size = 8
03/30/2022 16:12:45 - INFO - __main__ -     eval_ppl = 14.87196
03/30/2022 16:12:45 - INFO - __main__ -     global_step = 44000
03/30/2022 16:12:45 - INFO - __main__ -     train_loss = 1.8458
03/30/2022 16:12:45 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:13:05 - INFO - __main__ -     bleu-4 = 18.98 
03/30/2022 16:13:05 - INFO - __main__ -     ********************
loss 1.8247:  90%|████████▉ | 44998/50000 [3:46:04<18:04,  4.61it/s]03/30/2022 16:17:11 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:17:11 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:17:11 - INFO - __main__ -     Batch size = 8
03/30/2022 16:17:49 - INFO - __main__ -     eval_ppl = 15.02186
03/30/2022 16:17:49 - INFO - __main__ -     global_step = 45000
03/30/2022 16:17:49 - INFO - __main__ -     train_loss = 1.8247
03/30/2022 16:17:49 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:18:07 - INFO - __main__ -     bleu-4 = 18.65 
03/30/2022 16:18:07 - INFO - __main__ -     ********************
loss 1.8395:  92%|█████████▏| 45998/50000 [3:50:36<14:27,  4.61it/s]03/30/2022 16:21:43 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:21:43 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:21:43 - INFO - __main__ -     Batch size = 8
03/30/2022 16:22:23 - INFO - __main__ -     eval_ppl = 14.85293
03/30/2022 16:22:23 - INFO - __main__ -     global_step = 46000
03/30/2022 16:22:23 - INFO - __main__ -     train_loss = 1.8395
03/30/2022 16:22:23 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:22:43 - INFO - __main__ -     bleu-4 = 19.12 
03/30/2022 16:22:43 - INFO - __main__ -     ********************
loss 1.8266:  94%|█████████▍| 46998/50000 [3:55:55<12:55,  3.87it/s]03/30/2022 16:27:02 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:27:02 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:27:02 - INFO - __main__ -     Batch size = 8
03/30/2022 16:27:46 - INFO - __main__ -     eval_ppl = 15.17527
03/30/2022 16:27:46 - INFO - __main__ -     global_step = 47000
03/30/2022 16:27:46 - INFO - __main__ -     train_loss = 1.8266
03/30/2022 16:27:46 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:28:05 - INFO - __main__ -     bleu-4 = 19.2 
03/30/2022 16:28:05 - INFO - __main__ -     ********************
loss 1.8137:  96%|█████████▌| 47998/50000 [4:01:17<08:39,  3.85it/s]03/30/2022 16:32:23 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:32:23 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:32:23 - INFO - __main__ -     Batch size = 8
03/30/2022 16:33:08 - INFO - __main__ -     eval_ppl = 15.00834
03/30/2022 16:33:08 - INFO - __main__ -     global_step = 48000
03/30/2022 16:33:08 - INFO - __main__ -     train_loss = 1.8137
03/30/2022 16:33:08 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:33:27 - INFO - __main__ -     bleu-4 = 19.26 
03/30/2022 16:33:27 - INFO - __main__ -     ********************
loss 1.8274:  98%|█████████▊| 48998/50000 [4:06:38<04:17,  3.89it/s]03/30/2022 16:37:45 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:37:45 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:37:45 - INFO - __main__ -     Batch size = 8
03/30/2022 16:38:30 - INFO - __main__ -     eval_ppl = 14.77103
03/30/2022 16:38:30 - INFO - __main__ -     global_step = 49000
03/30/2022 16:38:30 - INFO - __main__ -     train_loss = 1.8274
03/30/2022 16:38:30 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:38:49 - INFO - __main__ -     bleu-4 = 19.35 
03/30/2022 16:38:49 - INFO - __main__ -     ********************
loss 1.8398: 100%|█████████▉| 49998/50000 [4:12:00<00:00,  3.87it/s]03/30/2022 16:43:07 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 16:43:07 - INFO - __main__ -     Num examples = 5183
03/30/2022 16:43:07 - INFO - __main__ -     Batch size = 8
03/30/2022 16:43:51 - INFO - __main__ -     eval_ppl = 14.81027
03/30/2022 16:43:51 - INFO - __main__ -     global_step = 50000
03/30/2022 16:43:51 - INFO - __main__ -     train_loss = 1.8398
03/30/2022 16:43:51 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 16:44:11 - INFO - __main__ -     bleu-4 = 19.43 
03/30/2022 16:44:11 - INFO - __main__ -     ********************
loss 2.1593: 100%|██████████| 50000/50000 [4:13:04<00:00,  3.29it/s]

Process finished with exit code 0