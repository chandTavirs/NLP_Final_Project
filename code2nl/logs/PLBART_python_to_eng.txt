C:\Users\sriva\anaconda3\envs\DLAssignment\python.exe C:/Users/sriva/OneDrive/Documents/Lectures/CE7455/Project/CodeBERT/CodeBERT/code2nl/run.py --do_train --do_eval --model_type=plbart --model_name_or_path=uclanlp/plbart-python-en_XX --train_filename=data/code2nl/CodeSearchNet/python/train.jsonl --dev_filename=data/code2nl/CodeSearchNet/python/valid.jsonl --output_dir=model/python/plbart --max_source_length=256 --max_target_length=128 --beam_size=10 --train_batch_size=8 --eval_batch_size=8 --learning_rate=5e-5 --train_steps=50000 --eval_steps=1000
03/29/2022 20:51:46 - INFO - __main__ -   Namespace(model_type='plbart', model_name_or_path='uclanlp/plbart-python-en_XX', output_dir='model/python/plbart', load_model_path=None, train_filename='data/code2nl/CodeSearchNet/python/train.jsonl', dev_filename='data/code2nl/CodeSearchNet/python/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=1000, train_steps=50000, warmup_steps=0, local_rank=-1, seed=42)
03/29/2022 20:51:46 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/29/2022 20:52:13 - INFO - __main__ -   *** Example ***
03/29/2022 20:52:13 - INFO - __main__ -   idx: 0
03/29/2022 20:52:13 - INFO - __main__ -   source_tokens: ['<s>', '▁def', '▁split', '_', 'ph', 'y', 'log', 'en', 'y', '▁(', '▁p', '▁,', '▁level', '▁=', '▁"', 's', '"', '▁)', '▁:', '▁level', '▁=', '▁level', '▁+', '▁"__', '"', '▁result', '▁=', '▁p', '▁.', '▁split', '▁(', '▁level', '▁)', '▁return', '▁result', '▁[', '▁0', '▁]', '▁+', '▁level', '▁+', '▁result', '▁[', '▁1', '▁]', '▁.', '▁split', '▁(', '▁"', ';"', '▁)', '▁[', '▁0', '▁]', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   source_ids: 0 134 1265 33456 637 33464 916 23 33464 5 31 16 1912 24 40 33442 33474 6 54 1912 24 1912 163 18892 33474 372 24 31 9 1265 5 1912 6 111 372 91 142 99 163 1912 163 372 91 124 99 9 1265 5 40 11173 6 91 142 99 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   target_tokens: ['<s>', '▁Return', '▁either', '▁the', '▁full', '▁or', '▁truncated', '▁version', '▁of', '▁a', '▁Q', 'I', 'IME', '▁-', '▁formatted', '▁tax', 'onomy', '▁string', '▁.', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   target_ids: 0 6379 2734 57 2111 255 17442 867 153 14 1402 33462 3210 158 7766 7117 20662 625 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   *** Example ***
03/29/2022 20:52:13 - INFO - __main__ -   idx: 1
03/29/2022 20:52:13 - INFO - __main__ -   source_tokens: ['<s>', '▁def', '▁ensure', '_', 'dir', '▁(', '▁d', '▁)', '▁:', '▁if', '▁not', '▁os', '▁.', '▁path', '▁.', '▁exists', '▁(', '▁d', '▁)', '▁:', '▁try', '▁:', '▁os', '▁.', '▁makedirs', '▁(', '▁d', '▁)', '▁except', '▁OSError', '▁as', '▁o', 'e', '▁:', '▁if', '▁os', '▁.', '▁errno', '▁==', '▁errno', '▁.', '▁ENOENT', '▁:', '▁msg', '▁=', '▁tw', 'dd', '▁(', '▁)', '▁return', '▁msg', '▁.', '▁format', '▁(', '▁d', '▁)', '▁else', '▁:', '▁msg', '▁=', '▁tw', 'dd', '▁(', '▁)', '▁return', '▁msg', '▁.', '▁format', '▁(', '▁d', '▁,', '▁o', 'e', '▁.', '▁strerror', '▁)', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   source_ids: 0 134 3803 33456 1013 5 36 6 54 105 188 763 9 470 9 2189 5 36 6 54 367 54 763 9 12489 5 36 6 1004 7994 268 75 33439 54 105 763 9 9040 258 9040 9 28117 54 1006 24 977 205 5 6 111 1006 9 753 5 36 6 345 54 1006 24 977 205 5 6 111 1006 9 753 5 36 16 75 33439 9 32922 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   target_tokens: ['<s>', '▁Check', '▁to', '▁make', '▁sure', '▁the', '▁supplied', '▁directory', '▁path', '▁does', '▁not', '▁exist', '▁if', '▁so', '▁create', '▁it', '▁.', '▁The', '▁method', '▁catches', '▁OSError', '▁exceptions', '▁and', '▁returns', '▁a', '▁des', 'criptive', '▁message', '▁instead', '▁of', '▁re', '▁-', '▁raising', '▁the', '▁error', '▁.', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   target_ids: 0 2960 71 797 1619 57 13279 2139 470 657 188 1227 105 558 451 141 9 418 483 31125 7994 4715 135 2039 14 839 27191 782 1432 153 46 158 26914 57 476 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   *** Example ***
03/29/2022 20:52:13 - INFO - __main__ -   idx: 2
03/29/2022 20:52:13 - INFO - __main__ -   source_tokens: ['<s>', '▁def', '▁file', '_', 'handle', '▁(', '▁fn', 'h', '▁,', '▁mode', '▁=', '▁"', 'r', 'U', '"', '▁)', '▁:', '▁handle', '▁=', '▁None', '▁if', '▁isinstance', '▁(', '▁fn', 'h', '▁,', '▁file', '▁)', '▁:', '▁if', '▁fn', 'h', '▁.', '▁closed', '▁:', '▁raise', '▁ValueError', '▁(', '▁"', 'Input', '▁file', '▁is', '▁closed', '."', '▁)', '▁handle', '▁=', '▁fn', 'h', '▁elif', '▁isinstance', '▁(', '▁fn', 'h', '▁,', '▁str', '▁)', '▁:', '▁handle', '▁=', '▁open', '▁(', '▁fn', 'h', '▁,', '▁mode', '▁)', '▁return', '▁handle', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   source_ids: 0 134 375 33456 4264 5 3619 33454 16 1985 24 40 33446 33501 33474 6 54 1656 24 307 105 1398 5 3619 33454 16 375 6 54 105 3619 33454 9 4510 54 841 1825 5 40 1434 375 96 4510 5921 6 1656 24 3619 33454 1091 1398 5 3619 33454 16 524 6 54 1656 24 1009 5 3619 33454 16 1985 6 111 1656 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   target_tokens: ['<s>', '▁T', 'akes', '▁either', '▁a', '▁file', '▁path', '▁or', '▁an', '▁open', '▁file', '▁handle', '▁checks', '▁validity', '▁and', '▁returns', '▁an', '▁open', '▁file', '▁handle', '▁or', '▁raises', '▁an', '▁appropriate', '▁Exception', '▁.', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   target_ids: 0 108 8000 2734 14 375 470 255 197 1009 375 1656 5881 24550 135 2039 197 1009 375 1656 255 7405 197 6296 773 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   *** Example ***
03/29/2022 20:52:13 - INFO - __main__ -   idx: 3
03/29/2022 20:52:13 - INFO - __main__ -   source_tokens: ['<s>', '▁def', '▁gather', '_', 'categories', '▁(', '▁imap', '▁,', '▁header', '▁,', '▁categories', '▁=', '▁None', '▁)', '▁:', '▁if', '▁categories', '▁is', '▁None', '▁:', '▁return', '▁{', '▁"', 'default', '"', '▁:', '▁Data', 'Category', '▁(', '▁set', '▁(', '▁imap', '▁.', '▁keys', '▁(', '▁)', '▁)', '▁,', '▁{', '▁}', '▁)', '▁}', '▁cat', '_', 'ids', '▁=', '▁[', '▁header', '▁.', '▁index', '▁(', '▁cat', '▁)', '▁for', '▁cat', '▁in', '▁categories', '▁if', '▁cat', '▁in', '▁header', '▁and', '▁"', '="', '▁not', '▁in', '▁cat', '▁]', '▁table', '▁=', '▁OrderedDict', '▁(', '▁)', '▁conditions', '▁=', '▁defaultdict', '▁(', '▁set', '▁)', '▁for', '▁i', '▁,', '▁cat', '▁in', '▁enumerate', '▁(', '▁categories', '▁)', '▁:', '▁if', '▁"', '="', '▁in', '▁cat', '▁and', '▁cat', '▁.', '▁split', '▁(', '▁"', '="', '▁)', '▁[', '▁0', '▁]', '▁in', '▁header', '▁:', '▁cat', '_', 'name', '▁=', '▁header', '▁[', '▁header', '▁.', '▁index', '▁(', '▁cat', '▁.', '▁split', '▁(', '▁"', '="', '▁)', '▁[', '▁0', '▁]', '▁)', '▁]', '▁conditions', '▁[', '▁cat', '_', 'name', '▁]', '▁.', '▁add', '▁(', '▁cat', '▁.', '▁split', '▁(', '▁"', '="', '▁)', '▁[', '▁1', '▁]', '▁)', '▁if', '▁not', '▁cat', '_', 'ids', '▁and', '▁not', '▁conditions', '▁:', '▁return', '▁{', '▁"', 'default', '"', '▁:', '▁Data', 'Category', '▁(', '▁set', '▁(', '▁imap', '▁.', '▁keys', '▁(', '▁)', '▁)', '▁,', '▁{', '▁}', '▁)', '▁}', '▁if', '▁cat', '_', 'ids', '▁and', '▁not', '▁conditions', '▁:', '▁for', '▁sid', '▁,', '▁row', '▁in', '▁imap', '▁.', '▁items', '▁(', '▁)', '▁:', '▁cat', '_', 'name', '▁=', '▁"_', '"', '▁.', '▁join', '▁(', '▁[', '▁row', '▁[', '▁cid', '▁]', '▁for', '▁cid', '▁in', '▁cat', '_', 'ids', '▁]', '▁)', '▁if', '▁cat', '_', 'name', '▁not', '▁in', '▁table', '▁:', '▁table', '▁[', '▁cat', '_', 'name', '▁]', '▁=', '▁Data', 'Category', '▁(', '▁set', '▁(', '▁)', '▁,', '▁{', '▁}', '▁)', '▁table', '▁[', '▁cat', '_', 'name', '▁]', '▁.', '▁s', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   source_ids: 0 134 10676 33456 13086 5 21988 16 1805 16 7660 24 307 6 54 105 7660 96 307 54 111 66 40 2123 33474 54 1472 5590 5 193 5 21988 9 1839 5 6 6 16 66 65 6 65 5905 33456 2357 24 91 1805 9 638 5 5905 6 126 5905 55 7660 105 5905 55 1805 135 40 286 188 55 5905 99 1036 24 11987 5 6 6620 24 11383 5 193 6 126 25 16 5905 55 4677 5 7660 6 54 105 40 286 55 5905 135 5905 9 1265 5 40 286 6 91 142 99 55 1805 54 5905 33456 308 24 1805 91 1805 9 638 5 5905 9 1265 5 40 286 6 91 142 99 6 99 6620 91 5905 33456 308 99 9 236 5 5905 9 1265 5 40 286 6 91 124 99 6 105 188 5905 33456 2357 135 188 6620 54 111 66 40 2123 33474 54 1472 5590 5 193 5 21988 9 1839 5 6 6 16 66 65 6 65 105 5905 33456 2357 135 188 6620 54 126 10055 16 879 55 21988 9 1503 5 6 54 5905 33456 308 24 12759 33474 9 1112 5 91 879 91 9382 99 126 9382 55 5905 33456 2357 99 6 105 5905 33456 308 188 55 1036 54 1036 91 5905 33456 308 99 24 1472 5590 5 193 5 6 16 66 65 6 1036 91 5905 33456 308 99 9 11 2
03/29/2022 20:52:13 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_tokens: ['<s>', '▁Find', '▁the', '▁user', '▁specified', '▁categories', '▁in', '▁the', '▁map', '▁and', '▁create', '▁a', '▁dictionary', '▁to', '▁contain', '▁the', '▁relevant', '▁data', '▁for', '▁each', '▁type', '▁within', '▁the', '▁categories', '▁.', '▁Multiple', '▁categories', '▁will', '▁have', '▁their', '▁types', '▁combined', '▁such', '▁that', '▁each', '▁possible', '▁combination', '▁will', '▁have', '▁its', '▁own', '▁entry', '▁in', '▁the', '▁dictionary', '▁.', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   target_ids: 0 7208 57 419 4017 7660 55 57 1065 135 451 14 3202 71 816 57 6493 272 126 1022 415 2382 57 7660 9 9372 7660 481 295 2614 2536 9599 2089 208 1022 1678 8821 481 295 1477 2577 1440 55 57 3202 9 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   *** Example ***
03/29/2022 20:52:13 - INFO - __main__ -   idx: 4
03/29/2022 20:52:13 - INFO - __main__ -   source_tokens: ['<s>', '▁def', '▁parse', '_', 'un', 'if', 'rac', '▁(', '▁un', 'if', 'rac', 'FN', '▁)', '▁:', '▁with', '▁open', '▁(', '▁un', 'if', 'rac', 'FN', '▁,', '▁"', 'r', 'U', '"', '▁)', '▁as', '▁u', 'F', '▁:', '▁first', '▁=', '▁u', 'F', '▁.', '▁next', '▁(', '▁)', '▁.', '▁split', '▁(', '▁"\\', 't', '"', '▁)', '▁lines', '▁=', '▁[', '▁line', '▁.', '▁strip', '▁(', '▁)', '▁for', '▁line', '▁in', '▁u', 'F', '▁]', '▁un', 'if', 'rac', '▁=', '▁{', '▁"', 'pc', 'd', '"', '▁:', '▁OrderedDict', '▁(', '▁)', '▁,', '▁"', 'e', 'ig', 'vals', '"', '▁:', '▁[', '▁]', '▁,', '▁"', 'v', 'are', 'xp', '"', '▁:', '▁[', '▁]', '▁}', '▁if', '▁first', '▁[', '▁0', '▁]', '▁==', '▁"', 'pc', '▁vector', '▁number', '"', '▁:', '▁return', '▁parse', '_', 'un', 'if', 'rac', '_', 'v', '1_', '8', '▁(', '▁un', 'if', 'rac', '▁,', '▁lines', '▁)', '▁elif', '▁first', '▁[', '▁0', '▁]', '▁==', '▁"', 'E', 'ig', 'vals', '"', '▁:', '▁return', '▁parse', '_', 'un', 'if', 'rac', '_', 'v', '1_', '9', '▁(', '▁un', 'if', 'rac', '▁,', '▁lines', '▁)', '▁else', '▁:', '▁raise', '▁ValueError', '▁(', '▁"', 'File', '▁format', '▁not', '▁supported', '/', 'recognized', '.', '▁Please', '▁check', '▁input', '▁"', '▁"', 'un', 'if', 'rac', '▁file', '."', '▁)', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   source_ids: 0 134 1142 33456 164 209 12019 5 511 209 12019 10909 6 54 215 1009 5 511 209 12019 10909 16 40 33446 33501 33474 6 268 98 33495 54 723 24 98 33495 9 919 5 6 9 1265 5 9147 33440 33474 6 1783 24 91 571 9 2912 5 6 126 571 55 98 33495 99 511 209 12019 24 66 40 2590 33448 33474 54 11987 5 6 16 40 33439 139 6298 33474 54 91 99 16 40 33472 361 19939 33474 54 91 99 65 105 723 91 142 99 258 40 2590 4419 1019 33474 54 111 1142 33456 164 209 12019 33456 33472 3955 33515 5 511 209 12019 16 1783 6 1091 723 91 142 99 258 40 33450 139 6298 33474 54 111 1142 33456 164 209 12019 33456 33472 3955 33518 5 511 209 12019 16 1783 6 345 54 841 1825 5 40 664 753 188 4045 33488 15671 33455 2646 553 641 40 40 164 209 12019 375 5921 6 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/29/2022 20:52:13 - INFO - __main__ -   target_tokens: ['<s>', '▁Pars', 'es', '▁the', '▁un', 'if', 'rac', '▁results', '▁file', '▁into', '▁a', '▁dictionary', '</s>']
03/29/2022 20:52:13 - INFO - __main__ -   target_ids: 0 17211 29 57 511 209 12019 1487 375 910 14 3202 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/29/2022 20:52:13 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
C:\Users\sriva\anaconda3\envs\DLAssignment\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/29/2022 20:54:46 - INFO - __main__ -   ***** Running training *****
03/29/2022 20:54:46 - INFO - __main__ -     Num examples = 251820
03/29/2022 20:54:46 - INFO - __main__ -     Batch size = 8
03/29/2022 20:54:46 - INFO - __main__ -     Num epoch = 1
loss 2.2184:   2%|▏         | 998/50000 [03:49<3:03:43,  4.45it/s]03/29/2022 20:58:46 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 20:58:46 - INFO - __main__ -     Num examples = 13914
03/29/2022 20:58:46 - INFO - __main__ -     Batch size = 8
03/29/2022 21:00:32 - INFO - __main__ -     eval_ppl = 37.58554
03/29/2022 21:00:32 - INFO - __main__ -     global_step = 1000
03/29/2022 21:00:32 - INFO - __main__ -     train_loss = 2.2184
03/29/2022 21:00:32 - INFO - __main__ -     ********************
03/29/2022 21:00:33 - INFO - __main__ -     Best ppl:37.58554
03/29/2022 21:00:33 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:00:52 - INFO - __main__ -     bleu-4 = 16.82 
03/29/2022 21:00:52 - INFO - __main__ -     ********************
03/29/2022 21:00:52 - INFO - __main__ -     Best bleu:16.82
03/29/2022 21:00:52 - INFO - __main__ -     ********************
loss 2.2646:   4%|▍         | 1998/50000 [09:50<2:58:39,  4.48it/s]03/29/2022 21:04:37 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:04:37 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:04:37 - INFO - __main__ -     Batch size = 8
03/29/2022 21:06:24 - INFO - __main__ -     eval_ppl = 36.71091
03/29/2022 21:06:24 - INFO - __main__ -     global_step = 2000
03/29/2022 21:06:24 - INFO - __main__ -     train_loss = 2.2646
03/29/2022 21:06:24 - INFO - __main__ -     ********************
03/29/2022 21:06:25 - INFO - __main__ -     Best ppl:36.71091
03/29/2022 21:06:25 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:06:43 - INFO - __main__ -     bleu-4 = 17.12 
03/29/2022 21:06:43 - INFO - __main__ -     ********************
03/29/2022 21:06:43 - INFO - __main__ -     Best bleu:17.12
03/29/2022 21:06:43 - INFO - __main__ -     ********************
loss 2.2915:   6%|▌         | 2998/50000 [15:43<2:55:48,  4.46it/s]03/29/2022 21:10:29 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:10:29 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:10:29 - INFO - __main__ -     Batch size = 8
03/29/2022 21:12:16 - INFO - __main__ -     eval_ppl = 36.26474
03/29/2022 21:12:16 - INFO - __main__ -     global_step = 3000
03/29/2022 21:12:16 - INFO - __main__ -     train_loss = 2.2915
03/29/2022 21:12:16 - INFO - __main__ -     ********************
03/29/2022 21:12:17 - INFO - __main__ -     Best ppl:36.26474
03/29/2022 21:12:17 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:12:34 - INFO - __main__ -     bleu-4 = 17.32 
03/29/2022 21:12:34 - INFO - __main__ -     ********************
03/29/2022 21:12:34 - INFO - __main__ -     Best bleu:17.32
03/29/2022 21:12:34 - INFO - __main__ -     ********************
loss 2.2621:   8%|▊         | 3998/50000 [21:35<2:52:34,  4.44it/s]03/29/2022 21:16:22 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:16:22 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:16:22 - INFO - __main__ -     Batch size = 8
03/29/2022 21:18:08 - INFO - __main__ -     eval_ppl = 34.86706
03/29/2022 21:18:08 - INFO - __main__ -     global_step = 4000
03/29/2022 21:18:08 - INFO - __main__ -     train_loss = 2.2621
03/29/2022 21:18:08 - INFO - __main__ -     ********************
03/29/2022 21:18:09 - INFO - __main__ -     Best ppl:34.86706
03/29/2022 21:18:09 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:18:28 - INFO - __main__ -     bleu-4 = 17.3 
03/29/2022 21:18:28 - INFO - __main__ -     ********************
loss 2.2989:  10%|▉         | 4998/50000 [27:42<3:14:32,  3.86it/s]03/29/2022 21:22:29 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:22:29 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:22:29 - INFO - __main__ -     Batch size = 8
03/29/2022 21:24:23 - INFO - __main__ -     eval_ppl = 34.59744
03/29/2022 21:24:23 - INFO - __main__ -     global_step = 5000
03/29/2022 21:24:23 - INFO - __main__ -     train_loss = 2.2989
03/29/2022 21:24:23 - INFO - __main__ -     ********************
03/29/2022 21:24:24 - INFO - __main__ -     Best ppl:34.59744
03/29/2022 21:24:24 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:24:43 - INFO - __main__ -     bleu-4 = 17.34 
03/29/2022 21:24:43 - INFO - __main__ -     ********************
03/29/2022 21:24:43 - INFO - __main__ -     Best bleu:17.34
03/29/2022 21:24:43 - INFO - __main__ -     ********************
loss 2.2968:  12%|█▏        | 5998/50000 [34:20<3:22:59,  3.61it/s]03/29/2022 21:29:06 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:29:06 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:29:06 - INFO - __main__ -     Batch size = 8
03/29/2022 21:31:16 - INFO - __main__ -     eval_ppl = 35.55808
03/29/2022 21:31:16 - INFO - __main__ -     global_step = 6000
03/29/2022 21:31:16 - INFO - __main__ -     train_loss = 2.2968
03/29/2022 21:31:16 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:31:35 - INFO - __main__ -     bleu-4 = 17.44 
03/29/2022 21:31:35 - INFO - __main__ -     ********************
03/29/2022 21:31:35 - INFO - __main__ -     Best bleu:17.44
03/29/2022 21:31:35 - INFO - __main__ -     ********************
loss 2.2833:  14%|█▍        | 6998/50000 [40:39<2:36:01,  4.59it/s]03/29/2022 21:35:26 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:35:26 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:35:26 - INFO - __main__ -     Batch size = 8
03/29/2022 21:37:10 - INFO - __main__ -     eval_ppl = 34.17235
03/29/2022 21:37:10 - INFO - __main__ -     global_step = 7000
03/29/2022 21:37:10 - INFO - __main__ -     train_loss = 2.2833
03/29/2022 21:37:10 - INFO - __main__ -     ********************
03/29/2022 21:37:11 - INFO - __main__ -     Best ppl:34.17235
03/29/2022 21:37:11 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:37:29 - INFO - __main__ -     bleu-4 = 17.51 
03/29/2022 21:37:29 - INFO - __main__ -     ********************
03/29/2022 21:37:29 - INFO - __main__ -     Best bleu:17.51
03/29/2022 21:37:29 - INFO - __main__ -     ********************
loss 2.2664:  16%|█▌        | 7998/50000 [46:21<2:31:42,  4.61it/s]03/29/2022 21:41:07 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:41:07 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:41:07 - INFO - __main__ -     Batch size = 8
03/29/2022 21:42:51 - INFO - __main__ -     eval_ppl = 33.44989
03/29/2022 21:42:51 - INFO - __main__ -     global_step = 8000
03/29/2022 21:42:51 - INFO - __main__ -     train_loss = 2.2664
03/29/2022 21:42:51 - INFO - __main__ -     ********************
03/29/2022 21:42:52 - INFO - __main__ -     Best ppl:33.44989
03/29/2022 21:42:52 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:43:10 - INFO - __main__ -     bleu-4 = 17.37 
03/29/2022 21:43:10 - INFO - __main__ -     ********************
loss 2.3002:  18%|█▊        | 8998/50000 [52:01<2:28:16,  4.61it/s]03/29/2022 21:46:47 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:46:47 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:46:47 - INFO - __main__ -     Batch size = 8
03/29/2022 21:48:31 - INFO - __main__ -     eval_ppl = 32.11295
03/29/2022 21:48:31 - INFO - __main__ -     global_step = 9000
03/29/2022 21:48:31 - INFO - __main__ -     train_loss = 2.3002
03/29/2022 21:48:31 - INFO - __main__ -     ********************
03/29/2022 21:48:32 - INFO - __main__ -     Best ppl:32.11295
03/29/2022 21:48:32 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:48:51 - INFO - __main__ -     bleu-4 = 16.88 
03/29/2022 21:48:51 - INFO - __main__ -     ********************
loss 2.2802:  20%|█▉        | 9998/50000 [57:42<2:25:36,  4.58it/s]03/29/2022 21:52:29 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:52:29 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:52:29 - INFO - __main__ -     Batch size = 8
03/29/2022 21:54:12 - INFO - __main__ -     eval_ppl = 32.25165
03/29/2022 21:54:12 - INFO - __main__ -     global_step = 10000
03/29/2022 21:54:12 - INFO - __main__ -     train_loss = 2.2802
03/29/2022 21:54:12 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 21:54:31 - INFO - __main__ -     bleu-4 = 17.4 
03/29/2022 21:54:31 - INFO - __main__ -     ********************
loss 2.2608:  22%|██▏       | 10998/50000 [1:03:22<2:23:53,  4.52it/s]03/29/2022 21:58:09 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 21:58:09 - INFO - __main__ -     Num examples = 13914
03/29/2022 21:58:09 - INFO - __main__ -     Batch size = 8
03/29/2022 21:59:53 - INFO - __main__ -     eval_ppl = 32.07987
03/29/2022 21:59:53 - INFO - __main__ -     global_step = 11000
03/29/2022 21:59:53 - INFO - __main__ -     train_loss = 2.2608
03/29/2022 21:59:53 - INFO - __main__ -     ********************
03/29/2022 21:59:54 - INFO - __main__ -     Best ppl:32.07987
03/29/2022 21:59:54 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:00:12 - INFO - __main__ -     bleu-4 = 17.35 
03/29/2022 22:00:12 - INFO - __main__ -     ********************
loss 2.2635:  24%|██▍       | 11998/50000 [1:09:04<2:18:52,  4.56it/s]03/29/2022 22:03:50 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:03:50 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:03:50 - INFO - __main__ -     Batch size = 8
03/29/2022 22:05:34 - INFO - __main__ -     eval_ppl = 31.68224
03/29/2022 22:05:34 - INFO - __main__ -     global_step = 12000
03/29/2022 22:05:34 - INFO - __main__ -     train_loss = 2.2635
03/29/2022 22:05:34 - INFO - __main__ -     ********************
03/29/2022 22:05:35 - INFO - __main__ -     Best ppl:31.68224
03/29/2022 22:05:35 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:05:54 - INFO - __main__ -     bleu-4 = 17.3 
03/29/2022 22:05:54 - INFO - __main__ -     ********************
loss 2.2958:  26%|██▌       | 12998/50000 [1:14:45<2:13:45,  4.61it/s]03/29/2022 22:09:32 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:09:32 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:09:32 - INFO - __main__ -     Batch size = 8
03/29/2022 22:11:15 - INFO - __main__ -     eval_ppl = 31.55247
03/29/2022 22:11:15 - INFO - __main__ -     global_step = 13000
03/29/2022 22:11:15 - INFO - __main__ -     train_loss = 2.2958
03/29/2022 22:11:15 - INFO - __main__ -     ********************
03/29/2022 22:11:16 - INFO - __main__ -     Best ppl:31.55247
03/29/2022 22:11:16 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:11:34 - INFO - __main__ -     bleu-4 = 17.35 
03/29/2022 22:11:34 - INFO - __main__ -     ********************
loss 2.262:  28%|██▊       | 13998/50000 [1:20:26<2:11:02,  4.58it/s] 03/29/2022 22:15:12 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:15:12 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:15:12 - INFO - __main__ -     Batch size = 8
03/29/2022 22:16:56 - INFO - __main__ -     eval_ppl = 31.40146
03/29/2022 22:16:56 - INFO - __main__ -     global_step = 14000
03/29/2022 22:16:56 - INFO - __main__ -     train_loss = 2.262
03/29/2022 22:16:56 - INFO - __main__ -     ********************
03/29/2022 22:16:57 - INFO - __main__ -     Best ppl:31.40146
03/29/2022 22:16:57 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:17:15 - INFO - __main__ -     bleu-4 = 17.33 
03/29/2022 22:17:15 - INFO - __main__ -     ********************
loss 2.2675:  30%|██▉       | 14998/50000 [1:26:07<2:07:38,  4.57it/s]03/29/2022 22:20:53 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:20:53 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:20:53 - INFO - __main__ -     Batch size = 8
03/29/2022 22:22:37 - INFO - __main__ -     eval_ppl = 30.51692
03/29/2022 22:22:37 - INFO - __main__ -     global_step = 15000
03/29/2022 22:22:37 - INFO - __main__ -     train_loss = 2.2675
03/29/2022 22:22:37 - INFO - __main__ -     ********************
03/29/2022 22:22:38 - INFO - __main__ -     Best ppl:30.51692
03/29/2022 22:22:38 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:22:56 - INFO - __main__ -     bleu-4 = 17.53 
03/29/2022 22:22:56 - INFO - __main__ -     ********************
03/29/2022 22:22:56 - INFO - __main__ -     Best bleu:17.53
03/29/2022 22:22:56 - INFO - __main__ -     ********************
loss 2.2347:  32%|███▏      | 15998/50000 [1:31:48<2:04:16,  4.56it/s]03/29/2022 22:26:35 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:26:35 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:26:35 - INFO - __main__ -     Batch size = 8
03/29/2022 22:28:18 - INFO - __main__ -     eval_ppl = 30.66817
03/29/2022 22:28:18 - INFO - __main__ -     global_step = 16000
03/29/2022 22:28:18 - INFO - __main__ -     train_loss = 2.2347
03/29/2022 22:28:18 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:28:37 - INFO - __main__ -     bleu-4 = 17.73 
03/29/2022 22:28:37 - INFO - __main__ -     ********************
03/29/2022 22:28:37 - INFO - __main__ -     Best bleu:17.73
03/29/2022 22:28:37 - INFO - __main__ -     ********************
loss 2.2358:  34%|███▍      | 16998/50000 [1:37:30<1:59:32,  4.60it/s]03/29/2022 22:32:16 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:32:16 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:32:16 - INFO - __main__ -     Batch size = 8
03/29/2022 22:34:00 - INFO - __main__ -     eval_ppl = 30.45395
03/29/2022 22:34:00 - INFO - __main__ -     global_step = 17000
03/29/2022 22:34:00 - INFO - __main__ -     train_loss = 2.2358
03/29/2022 22:34:00 - INFO - __main__ -     ********************
03/29/2022 22:34:01 - INFO - __main__ -     Best ppl:30.45395
03/29/2022 22:34:01 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:34:19 - INFO - __main__ -     bleu-4 = 17.9 
03/29/2022 22:34:19 - INFO - __main__ -     ********************
03/29/2022 22:34:19 - INFO - __main__ -     Best bleu:17.9
03/29/2022 22:34:19 - INFO - __main__ -     ********************
loss 2.2476:  36%|███▌      | 17998/50000 [1:43:14<1:56:13,  4.59it/s]03/29/2022 22:38:01 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:38:01 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:38:01 - INFO - __main__ -     Batch size = 8
03/29/2022 22:39:44 - INFO - __main__ -     eval_ppl = 30.29945
03/29/2022 22:39:44 - INFO - __main__ -     global_step = 18000
03/29/2022 22:39:44 - INFO - __main__ -     train_loss = 2.2476
03/29/2022 22:39:44 - INFO - __main__ -     ********************
03/29/2022 22:39:45 - INFO - __main__ -     Best ppl:30.29945
03/29/2022 22:39:45 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:40:04 - INFO - __main__ -     bleu-4 = 17.5 
03/29/2022 22:40:04 - INFO - __main__ -     ********************
loss 2.23:  38%|███▊      | 18998/50000 [1:48:54<1:51:26,  4.64it/s]03/29/2022 22:43:41 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:43:41 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:43:41 - INFO - __main__ -     Batch size = 8
03/29/2022 22:45:25 - INFO - __main__ -     eval_ppl = 29.69683
03/29/2022 22:45:25 - INFO - __main__ -     global_step = 19000
03/29/2022 22:45:25 - INFO - __main__ -     train_loss = 2.23
03/29/2022 22:45:25 - INFO - __main__ -     ********************
03/29/2022 22:45:26 - INFO - __main__ -     Best ppl:29.69683
03/29/2022 22:45:26 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:45:44 - INFO - __main__ -     bleu-4 = 17.45 
03/29/2022 22:45:44 - INFO - __main__ -     ********************
loss 2.2128:  40%|███▉      | 19998/50000 [1:54:35<1:47:50,  4.64it/s]03/29/2022 22:49:21 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:49:21 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:49:21 - INFO - __main__ -     Batch size = 8
03/29/2022 22:51:05 - INFO - __main__ -     eval_ppl = 29.69478
03/29/2022 22:51:05 - INFO - __main__ -     global_step = 20000
03/29/2022 22:51:05 - INFO - __main__ -     train_loss = 2.2128
03/29/2022 22:51:05 - INFO - __main__ -     ********************
03/29/2022 22:51:06 - INFO - __main__ -     Best ppl:29.69478
03/29/2022 22:51:06 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:51:24 - INFO - __main__ -     bleu-4 = 17.53 
03/29/2022 22:51:24 - INFO - __main__ -     ********************
loss 2.2123:  42%|████▏     | 20998/50000 [2:00:15<1:44:58,  4.60it/s]03/29/2022 22:55:01 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 22:55:01 - INFO - __main__ -     Num examples = 13914
03/29/2022 22:55:01 - INFO - __main__ -     Batch size = 8
03/29/2022 22:56:45 - INFO - __main__ -     eval_ppl = 29.42364
03/29/2022 22:56:45 - INFO - __main__ -     global_step = 21000
03/29/2022 22:56:45 - INFO - __main__ -     train_loss = 2.2123
03/29/2022 22:56:45 - INFO - __main__ -     ********************
03/29/2022 22:56:46 - INFO - __main__ -     Best ppl:29.42364
03/29/2022 22:56:46 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 22:57:04 - INFO - __main__ -     bleu-4 = 17.83 
03/29/2022 22:57:04 - INFO - __main__ -     ********************
loss 2.1856:  44%|████▍     | 21998/50000 [2:05:54<1:41:07,  4.61it/s]03/29/2022 23:00:41 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:00:41 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:00:41 - INFO - __main__ -     Batch size = 8
03/29/2022 23:02:24 - INFO - __main__ -     eval_ppl = 29.27238
03/29/2022 23:02:24 - INFO - __main__ -     global_step = 22000
03/29/2022 23:02:24 - INFO - __main__ -     train_loss = 2.1856
03/29/2022 23:02:24 - INFO - __main__ -     ********************
03/29/2022 23:02:25 - INFO - __main__ -     Best ppl:29.27238
03/29/2022 23:02:25 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:02:44 - INFO - __main__ -     bleu-4 = 17.81 
03/29/2022 23:02:44 - INFO - __main__ -     ********************
loss 2.1958:  46%|████▌     | 22998/50000 [2:11:49<1:59:37,  3.76it/s]03/29/2022 23:06:36 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:06:36 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:06:36 - INFO - __main__ -     Batch size = 8
03/29/2022 23:08:31 - INFO - __main__ -     eval_ppl = 29.37139
03/29/2022 23:08:31 - INFO - __main__ -     global_step = 23000
03/29/2022 23:08:31 - INFO - __main__ -     train_loss = 2.1958
03/29/2022 23:08:31 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:08:48 - INFO - __main__ -     bleu-4 = 17.66 
03/29/2022 23:08:48 - INFO - __main__ -     ********************
loss 2.19:  48%|████▊     | 23998/50000 [2:18:11<1:52:35,  3.85it/s]  03/29/2022 23:12:57 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:12:57 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:12:57 - INFO - __main__ -     Batch size = 8
03/29/2022 23:14:58 - INFO - __main__ -     eval_ppl = 28.87004
03/29/2022 23:14:58 - INFO - __main__ -     global_step = 24000
03/29/2022 23:14:58 - INFO - __main__ -     train_loss = 2.19
03/29/2022 23:14:58 - INFO - __main__ -     ********************
03/29/2022 23:14:59 - INFO - __main__ -     Best ppl:28.87004
03/29/2022 23:14:59 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:15:19 - INFO - __main__ -     bleu-4 = 17.02 
03/29/2022 23:15:19 - INFO - __main__ -     ********************
loss 2.1744:  50%|████▉     | 24998/50000 [2:24:45<1:43:40,  4.02it/s]03/29/2022 23:19:32 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:19:32 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:19:32 - INFO - __main__ -     Batch size = 8
03/29/2022 23:21:29 - INFO - __main__ -     eval_ppl = 28.66492
03/29/2022 23:21:29 - INFO - __main__ -     global_step = 25000
03/29/2022 23:21:29 - INFO - __main__ -     train_loss = 2.1744
03/29/2022 23:21:29 - INFO - __main__ -     ********************
03/29/2022 23:21:30 - INFO - __main__ -     Best ppl:28.66492
03/29/2022 23:21:30 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:21:49 - INFO - __main__ -     bleu-4 = 17.52 
03/29/2022 23:21:49 - INFO - __main__ -     ********************
loss 2.1578:  52%|█████▏    | 25998/50000 [2:31:13<1:40:38,  3.97it/s]03/29/2022 23:26:00 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:26:00 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:26:00 - INFO - __main__ -     Batch size = 8
03/29/2022 23:27:56 - INFO - __main__ -     eval_ppl = 28.24881
03/29/2022 23:27:56 - INFO - __main__ -     global_step = 26000
03/29/2022 23:27:56 - INFO - __main__ -     train_loss = 2.1578
03/29/2022 23:27:56 - INFO - __main__ -     ********************
03/29/2022 23:27:57 - INFO - __main__ -     Best ppl:28.24881
03/29/2022 23:27:57 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:28:16 - INFO - __main__ -     bleu-4 = 17.19 
03/29/2022 23:28:16 - INFO - __main__ -     ********************
loss 2.1605:  54%|█████▍    | 26998/50000 [2:37:40<1:36:17,  3.98it/s]03/29/2022 23:32:27 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:32:27 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:32:27 - INFO - __main__ -     Batch size = 8
03/29/2022 23:34:23 - INFO - __main__ -     eval_ppl = 28.57166
03/29/2022 23:34:23 - INFO - __main__ -     global_step = 27000
03/29/2022 23:34:23 - INFO - __main__ -     train_loss = 2.1605
03/29/2022 23:34:23 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:34:41 - INFO - __main__ -     bleu-4 = 17.56 
03/29/2022 23:34:41 - INFO - __main__ -     ********************
loss 2.1539:  56%|█████▌    | 27998/50000 [2:44:04<1:31:40,  4.00it/s]03/29/2022 23:38:51 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:38:51 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:38:51 - INFO - __main__ -     Batch size = 8
03/29/2022 23:40:46 - INFO - __main__ -     eval_ppl = 28.658
03/29/2022 23:40:46 - INFO - __main__ -     global_step = 28000
03/29/2022 23:40:46 - INFO - __main__ -     train_loss = 2.1539
03/29/2022 23:40:46 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:41:05 - INFO - __main__ -     bleu-4 = 17.5 
03/29/2022 23:41:05 - INFO - __main__ -     ********************
loss 2.152:  58%|█████▊    | 28998/50000 [2:50:27<1:27:00,  4.02it/s] 03/29/2022 23:45:14 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:45:14 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:45:14 - INFO - __main__ -     Batch size = 8
03/29/2022 23:47:10 - INFO - __main__ -     eval_ppl = 28.20342
03/29/2022 23:47:10 - INFO - __main__ -     global_step = 29000
03/29/2022 23:47:10 - INFO - __main__ -     train_loss = 2.152
03/29/2022 23:47:10 - INFO - __main__ -     ********************
03/29/2022 23:47:10 - INFO - __main__ -     Best ppl:28.20342
03/29/2022 23:47:10 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:47:29 - INFO - __main__ -     bleu-4 = 17.03 
03/29/2022 23:47:29 - INFO - __main__ -     ********************
loss 2.1373:  60%|█████▉    | 29998/50000 [2:57:02<1:12:09,  4.62it/s]03/29/2022 23:51:48 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:51:48 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:51:48 - INFO - __main__ -     Batch size = 8
03/29/2022 23:53:38 - INFO - __main__ -     eval_ppl = 28.29185
03/29/2022 23:53:38 - INFO - __main__ -     global_step = 30000
03/29/2022 23:53:38 - INFO - __main__ -     train_loss = 2.1373
03/29/2022 23:53:38 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:53:57 - INFO - __main__ -     bleu-4 = 17.38 
03/29/2022 23:53:57 - INFO - __main__ -     ********************
loss 2.1313:  62%|██████▏   | 30998/50000 [3:02:57<1:14:24,  4.26it/s]03/29/2022 23:57:43 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 23:57:43 - INFO - __main__ -     Num examples = 13914
03/29/2022 23:57:43 - INFO - __main__ -     Batch size = 8
03/29/2022 23:59:32 - INFO - __main__ -     eval_ppl = 27.69048
03/29/2022 23:59:32 - INFO - __main__ -     global_step = 31000
03/29/2022 23:59:32 - INFO - __main__ -     train_loss = 2.1313
03/29/2022 23:59:32 - INFO - __main__ -     ********************
03/29/2022 23:59:33 - INFO - __main__ -     Best ppl:27.69048
03/29/2022 23:59:33 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 23:59:52 - INFO - __main__ -     bleu-4 = 17.84 
03/29/2022 23:59:52 - INFO - __main__ -     ********************
loss 1.9193:  64%|██████▍   | 31998/50000 [3:08:57<1:09:33,  4.31it/s]03/30/2022 00:03:44 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:03:44 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:03:44 - INFO - __main__ -     Batch size = 8
03/30/2022 00:05:33 - INFO - __main__ -     eval_ppl = 30.18573
03/30/2022 00:05:33 - INFO - __main__ -     global_step = 32000
03/30/2022 00:05:33 - INFO - __main__ -     train_loss = 1.9193
03/30/2022 00:05:33 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:05:52 - INFO - __main__ -     bleu-4 = 17.16 
03/30/2022 00:05:52 - INFO - __main__ -     ********************
loss 1.7075:  66%|██████▌   | 32998/50000 [3:14:57<1:05:11,  4.35it/s]03/30/2022 00:09:43 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:09:43 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:09:43 - INFO - __main__ -     Batch size = 8
03/30/2022 00:11:33 - INFO - __main__ -     eval_ppl = 30.57618
03/30/2022 00:11:33 - INFO - __main__ -     global_step = 33000
03/30/2022 00:11:33 - INFO - __main__ -     train_loss = 1.7075
03/30/2022 00:11:33 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:11:51 - INFO - __main__ -     bleu-4 = 16.97 
03/30/2022 00:11:51 - INFO - __main__ -     ********************
loss 1.6951:  68%|██████▊   | 33998/50000 [3:20:54<1:01:30,  4.34it/s]03/30/2022 00:15:40 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:15:40 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:15:40 - INFO - __main__ -     Batch size = 8
03/30/2022 00:17:29 - INFO - __main__ -     eval_ppl = 30.98886
03/30/2022 00:17:29 - INFO - __main__ -     global_step = 34000
03/30/2022 00:17:29 - INFO - __main__ -     train_loss = 1.6951
03/30/2022 00:17:29 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:17:48 - INFO - __main__ -     bleu-4 = 17.27 
03/30/2022 00:17:48 - INFO - __main__ -     ********************
loss 1.6839:  70%|██████▉   | 34998/50000 [3:27:08<1:06:33,  3.76it/s]03/30/2022 00:21:55 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:21:55 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:21:55 - INFO - __main__ -     Batch size = 8
03/30/2022 00:24:02 - INFO - __main__ -     eval_ppl = 30.88977
03/30/2022 00:24:02 - INFO - __main__ -     global_step = 35000
03/30/2022 00:24:02 - INFO - __main__ -     train_loss = 1.6839
03/30/2022 00:24:02 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:24:21 - INFO - __main__ -     bleu-4 = 17.4 
03/30/2022 00:24:21 - INFO - __main__ -     ********************
loss 1.6806:  72%|███████▏  | 35998/50000 [3:34:17<1:05:20,  3.57it/s]03/30/2022 00:29:03 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:29:03 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:29:03 - INFO - __main__ -     Batch size = 8
03/30/2022 00:31:13 - INFO - __main__ -     eval_ppl = 30.84305
03/30/2022 00:31:13 - INFO - __main__ -     global_step = 36000
03/30/2022 00:31:13 - INFO - __main__ -     train_loss = 1.6806
03/30/2022 00:31:13 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:31:33 - INFO - __main__ -     bleu-4 = 17.46 
03/30/2022 00:31:33 - INFO - __main__ -     ********************
loss 1.6637:  74%|███████▍  | 36998/50000 [3:40:43<52:56,  4.09it/s]03/30/2022 00:35:30 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:35:30 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:35:30 - INFO - __main__ -     Batch size = 8
03/30/2022 00:37:20 - INFO - __main__ -     eval_ppl = 30.83475
03/30/2022 00:37:20 - INFO - __main__ -     global_step = 37000
03/30/2022 00:37:20 - INFO - __main__ -     train_loss = 1.6637
03/30/2022 00:37:20 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:37:39 - INFO - __main__ -     bleu-4 = 17.23 
03/30/2022 00:37:39 - INFO - __main__ -     ********************
loss 1.6343:  76%|███████▌  | 37998/50000 [3:46:42<46:19,  4.32it/s]03/30/2022 00:41:29 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:41:29 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:41:29 - INFO - __main__ -     Batch size = 8
03/30/2022 00:43:18 - INFO - __main__ -     eval_ppl = 31.44998
03/30/2022 00:43:18 - INFO - __main__ -     global_step = 38000
03/30/2022 00:43:18 - INFO - __main__ -     train_loss = 1.6343
03/30/2022 00:43:18 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:43:38 - INFO - __main__ -     bleu-4 = 17.3 
03/30/2022 00:43:38 - INFO - __main__ -     ********************
loss 1.6245:  78%|███████▊  | 38998/50000 [3:52:42<42:20,  4.33it/s]03/30/2022 00:47:28 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:47:28 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:47:28 - INFO - __main__ -     Batch size = 8
03/30/2022 00:49:17 - INFO - __main__ -     eval_ppl = 30.86922
03/30/2022 00:49:17 - INFO - __main__ -     global_step = 39000
03/30/2022 00:49:17 - INFO - __main__ -     train_loss = 1.6245
03/30/2022 00:49:17 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:49:37 - INFO - __main__ -     bleu-4 = 17.23 
03/30/2022 00:49:37 - INFO - __main__ -     ********************
loss 1.6327:  80%|███████▉  | 39998/50000 [3:58:40<39:38,  4.20it/s]03/30/2022 00:53:26 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:53:26 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:53:26 - INFO - __main__ -     Batch size = 8
03/30/2022 00:55:16 - INFO - __main__ -     eval_ppl = 30.71895
03/30/2022 00:55:16 - INFO - __main__ -     global_step = 40000
03/30/2022 00:55:16 - INFO - __main__ -     train_loss = 1.6327
03/30/2022 00:55:16 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 00:55:35 - INFO - __main__ -     bleu-4 = 17.34 
03/30/2022 00:55:35 - INFO - __main__ -     ********************
loss 1.6483:  82%|████████▏ | 40998/50000 [4:04:41<34:40,  4.33it/s]03/30/2022 00:59:27 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 00:59:27 - INFO - __main__ -     Num examples = 13914
03/30/2022 00:59:27 - INFO - __main__ -     Batch size = 8
03/30/2022 01:01:17 - INFO - __main__ -     eval_ppl = 30.71321
03/30/2022 01:01:17 - INFO - __main__ -     global_step = 41000
03/30/2022 01:01:17 - INFO - __main__ -     train_loss = 1.6483
03/30/2022 01:01:17 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:01:35 - INFO - __main__ -     bleu-4 = 17.08 
03/30/2022 01:01:35 - INFO - __main__ -     ********************
loss 1.6099:  84%|████████▍ | 41998/50000 [4:10:39<29:27,  4.53it/s]03/30/2022 01:05:26 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:05:26 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:05:26 - INFO - __main__ -     Batch size = 8
03/30/2022 01:07:23 - INFO - __main__ -     eval_ppl = 30.87856
03/30/2022 01:07:23 - INFO - __main__ -     global_step = 42000
03/30/2022 01:07:23 - INFO - __main__ -     train_loss = 1.6099
03/30/2022 01:07:23 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:07:43 - INFO - __main__ -     bleu-4 = 17.21 
03/30/2022 01:07:43 - INFO - __main__ -     ********************
loss 1.6107:  86%|████████▌ | 42998/50000 [4:16:47<27:56,  4.18it/s]03/30/2022 01:11:33 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:11:33 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:11:33 - INFO - __main__ -     Batch size = 8
03/30/2022 01:13:20 - INFO - __main__ -     eval_ppl = 30.68126
03/30/2022 01:13:20 - INFO - __main__ -     global_step = 43000
03/30/2022 01:13:20 - INFO - __main__ -     train_loss = 1.6107
03/30/2022 01:13:20 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:13:39 - INFO - __main__ -     bleu-4 = 17.01 
03/30/2022 01:13:39 - INFO - __main__ -     ********************
loss 1.624:  88%|████████▊ | 43998/50000 [4:22:37<21:51,  4.58it/s] 03/30/2022 01:17:23 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:17:23 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:17:23 - INFO - __main__ -     Batch size = 8
03/30/2022 01:19:07 - INFO - __main__ -     eval_ppl = 30.64522
03/30/2022 01:19:07 - INFO - __main__ -     global_step = 44000
03/30/2022 01:19:07 - INFO - __main__ -     train_loss = 1.624
03/30/2022 01:19:07 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:19:25 - INFO - __main__ -     bleu-4 = 17.26 
03/30/2022 01:19:25 - INFO - __main__ -     ********************
loss 1.6211:  90%|████████▉ | 44998/50000 [4:28:16<18:10,  4.59it/s]03/30/2022 01:23:03 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:23:03 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:23:03 - INFO - __main__ -     Batch size = 8
03/30/2022 01:24:47 - INFO - __main__ -     eval_ppl = 30.70427
03/30/2022 01:24:47 - INFO - __main__ -     global_step = 45000
03/30/2022 01:24:47 - INFO - __main__ -     train_loss = 1.6211
03/30/2022 01:24:47 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:25:05 - INFO - __main__ -     bleu-4 = 17.25 
03/30/2022 01:25:05 - INFO - __main__ -     ********************
loss 1.6126:  92%|█████████▏| 45998/50000 [4:33:59<14:49,  4.50it/s]03/30/2022 01:28:46 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:28:46 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:28:46 - INFO - __main__ -     Batch size = 8
03/30/2022 01:30:31 - INFO - __main__ -     eval_ppl = 30.44522
03/30/2022 01:30:31 - INFO - __main__ -     global_step = 46000
03/30/2022 01:30:31 - INFO - __main__ -     train_loss = 1.6126
03/30/2022 01:30:31 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:30:49 - INFO - __main__ -     bleu-4 = 17.38 
03/30/2022 01:30:49 - INFO - __main__ -     ********************
loss 1.5961:  94%|█████████▍| 46998/50000 [4:39:43<11:00,  4.54it/s]03/30/2022 01:34:30 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:34:30 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:34:30 - INFO - __main__ -     Batch size = 8
03/30/2022 01:36:15 - INFO - __main__ -     eval_ppl = 30.59197
03/30/2022 01:36:15 - INFO - __main__ -     global_step = 47000
03/30/2022 01:36:15 - INFO - __main__ -     train_loss = 1.5961
03/30/2022 01:36:15 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:36:33 - INFO - __main__ -     bleu-4 = 17.69 
03/30/2022 01:36:33 - INFO - __main__ -     ********************
loss 1.5796:  96%|█████████▌| 47998/50000 [4:45:27<07:23,  4.51it/s]03/30/2022 01:40:14 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:40:14 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:40:14 - INFO - __main__ -     Batch size = 8
03/30/2022 01:41:59 - INFO - __main__ -     eval_ppl = 30.53676
03/30/2022 01:41:59 - INFO - __main__ -     global_step = 48000
03/30/2022 01:41:59 - INFO - __main__ -     train_loss = 1.5796
03/30/2022 01:41:59 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:42:16 - INFO - __main__ -     bleu-4 = 17.4 
03/30/2022 01:42:16 - INFO - __main__ -     ********************
loss 1.6224:  98%|█████████▊| 48998/50000 [4:51:11<03:40,  4.53it/s]03/30/2022 01:45:57 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:45:57 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:45:57 - INFO - __main__ -     Batch size = 8
03/30/2022 01:47:42 - INFO - __main__ -     eval_ppl = 30.29656
03/30/2022 01:47:42 - INFO - __main__ -     global_step = 49000
03/30/2022 01:47:42 - INFO - __main__ -     train_loss = 1.6224
03/30/2022 01:47:42 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:48:00 - INFO - __main__ -     bleu-4 = 17.51 
03/30/2022 01:48:00 - INFO - __main__ -     ********************
loss 1.6019: 100%|█████████▉| 49998/50000 [4:56:54<00:00,  4.49it/s]03/30/2022 01:51:41 - INFO - __main__ -   
***** Running evaluation *****
03/30/2022 01:51:41 - INFO - __main__ -     Num examples = 13914
03/30/2022 01:51:41 - INFO - __main__ -     Batch size = 8
03/30/2022 01:53:26 - INFO - __main__ -     eval_ppl = 30.36843
03/30/2022 01:53:26 - INFO - __main__ -     global_step = 50000
03/30/2022 01:53:26 - INFO - __main__ -     train_loss = 1.6019
03/30/2022 01:53:26 - INFO - __main__ -     ********************
Total: 1000
03/30/2022 01:53:43 - INFO - __main__ -     bleu-4 = 17.44 
03/30/2022 01:53:43 - INFO - __main__ -     ********************
loss 1.4083: 100%|██████████| 50000/50000 [4:58:57<00:00,  2.79it/s]

Process finished with exit code 0
