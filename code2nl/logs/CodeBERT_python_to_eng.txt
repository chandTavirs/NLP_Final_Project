C:\Users\sriva\anaconda3\envs\DLAssignment\python.exe C:/Users/sriva/OneDrive/Documents/Lectures/CE7455/Project/CodeBERT/CodeBERT/code2nl/run.py --do_train --do_eval --model_type=roberta --model_name_or_path=microsoft/codebert-base --train_filename=data/code2nl/CodeSearchNet/python/train.jsonl --dev_filename=data/code2nl/CodeSearchNet/python/valid.jsonl --output_dir=model/python --max_source_length=256 --max_target_length=128 --beam_size=10 --train_batch_size=8 --eval_batch_size=8 --learning_rate=5e-5 --train_steps=50000 --eval_steps=1000
03/28/2022 15:02:45 - INFO - __main__ -   Namespace(model_type='roberta', model_name_or_path='microsoft/codebert-base', output_dir='model/python', load_model_path=None, train_filename='data/code2nl/CodeSearchNet/python/train.jsonl', dev_filename='data/code2nl/CodeSearchNet/python/valid.jsonl', test_filename=None, config_name='', tokenizer_name='', max_source_length=256, max_target_length=128, do_train=True, do_eval=True, do_test=False, do_lower_case=False, no_cuda=False, train_batch_size=8, eval_batch_size=8, gradient_accumulation_steps=1, learning_rate=5e-05, beam_size=10, weight_decay=0.0, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3.0, max_steps=-1, eval_steps=1000, train_steps=50000, warmup_steps=0, local_rank=-1, seed=42)
03/28/2022 15:02:45 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False
03/28/2022 15:03:03 - INFO - __main__ -   *** Example ***
03/28/2022 15:03:03 - INFO - __main__ -   idx: 0
03/28/2022 15:03:03 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_split', '_', 'ph', 'yl', 'ogen', 'y', '_(', '_p', '_,', '_level', '_=', '_"', 's', '"', '_)', '_:', '_level', '_=', '_level', '_+', '_"', '__', '"', '_result', '_=', '_p', '_.', '_split', '_(', '_level', '_)', '_return', '_result', '_[', '_0', '_]', '_+', '_level', '_+', '_result', '_[', '_1', '_]', '_.', '_split', '_(', '_"', ';"', '_)', '_[', '_0', '_]', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   source_ids: 0 9232 3462 1215 3792 4360 11575 219 36 181 2156 672 5457 22 29 113 4839 4832 672 5457 672 2055 22 30529 113 898 5457 181 479 3462 36 672 4839 671 898 646 321 27779 2055 672 2055 898 646 112 27779 479 3462 36 22 42777 4839 646 321 27779 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   target_tokens: ['<s>', 'Return', '_either', '_the', '_full', '_or', '_trunc', 'ated', '_version', '_of', '_a', '_Q', 'I', 'IME', '_-', '_formatted', '_tax', 'onomy', '_string', '_.', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   target_ids: 0 42555 1169 5 455 50 43064 1070 1732 9 10 1209 100 28417 111 46625 629 38217 6755 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   *** Example ***
03/28/2022 15:03:03 - INFO - __main__ -   idx: 1
03/28/2022 15:03:03 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_ensure', '_', 'dir', '_(', '_d', '_)', '_:', '_if', '_not', '_os', '_.', '_path', '_.', '_exists', '_(', '_d', '_)', '_:', '_try', '_:', '_os', '_.', '_m', 'aked', 'irs', '_(', '_d', '_)', '_except', '_O', 'SE', 'r', 'ror', '_as', '_o', 'e', '_:', '_if', '_os', '_.', '_err', 'no', '_==', '_err', 'no', '_.', '_EN', 'O', 'ENT', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_)', '_else', '_:', '_msg', '_=', '_tw', 'dd', '_(', '_)', '_return', '_msg', '_.', '_format', '_(', '_d', '_,', '_o', 'e', '_.', '_stre', 'r', 'ror', '_)', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   source_ids: 0 9232 1306 1215 41292 36 385 4839 4832 114 45 11988 479 2718 479 8785 36 385 4839 4832 860 4832 11988 479 475 8435 21098 36 385 4839 4682 384 3388 338 21929 25 1021 242 4832 114 11988 479 22379 2362 45994 22379 2362 479 13245 673 5382 4832 49049 5457 11901 16134 36 4839 671 49049 479 7390 36 385 4839 1493 4832 49049 5457 11901 16134 36 4839 671 49049 479 7390 36 385 2156 1021 242 479 22246 338 21929 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   target_tokens: ['<s>', 'Check', '_to', '_make', '_sure', '_the', '_supplied', '_directory', '_path', '_does', '_not', '_exist', '_if', '_so', '_create', '_it', '_.', '_The', '_method', '_catches', '_O', 'SE', 'r', 'ror', '_exceptions', '_and', '_returns', '_a', '_descriptive', '_message', '_instead', '_of', '_re', '_-', '_raising', '_the', '_error', '_.', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   target_ids: 0 26615 7 146 686 5 12359 31826 2718 473 45 5152 114 98 1045 24 479 20 5448 8758 384 3388 338 21929 18286 8 2886 10 42690 1579 1386 9 769 111 3282 5 5849 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   *** Example ***
03/28/2022 15:03:03 - INFO - __main__ -   idx: 2
03/28/2022 15:03:03 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_file', '_', 'handle', '_(', '_fn', 'h', '_,', '_mode', '_=', '_"', 'r', 'U', '"', '_)', '_:', '_handle', '_=', '_None', '_if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_file', '_)', '_:', '_if', '_fn', 'h', '_.', '_closed', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'Input', '_file', '_is', '_closed', '."', '_)', '_handle', '_=', '_fn', 'h', '_el', 'if', '_is', 'instance', '_(', '_fn', 'h', '_,', '_str', '_)', '_:', '_handle', '_=', '_open', '_(', '_fn', 'h', '_,', '_mode', '_)', '_return', '_handle', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   source_ids: 0 9232 2870 1215 26628 36 48930 298 2156 5745 5457 22 338 791 113 4839 4832 3679 5457 9291 114 16 48768 36 48930 298 2156 2870 4839 4832 114 48930 298 479 1367 4832 1693 11714 30192 36 22 48214 2870 16 1367 72 4839 3679 5457 48930 298 1615 1594 16 48768 36 48930 298 2156 7031 4839 4832 3679 5457 490 36 48930 298 2156 5745 4839 671 3679 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   target_tokens: ['<s>', 'T', 'akes', '_either', '_a', '_file', '_path', '_or', '_an', '_open', '_file', '_handle', '_checks', '_validity', '_and', '_returns', '_an', '_open', '_file', '_handle', '_or', '_raises', '_an', '_appropriate', '_Exception', '_.', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   target_ids: 0 565 5556 1169 10 2870 2718 50 41 490 2870 3679 6240 25295 8 2886 41 490 2870 3679 50 7700 41 3901 47617 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   *** Example ***
03/28/2022 15:03:03 - INFO - __main__ -   idx: 3
03/28/2022 15:03:03 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_gather', '_', 'c', 'ategories', '_(', '_im', 'ap', '_,', '_header', '_,', '_categories', '_=', '_None', '_)', '_:', '_if', '_categories', '_is', '_None', '_:', '_return', '_{', '_"', 'default', '"', '_:', '_Data', 'Category', '_(', '_set', '_(', '_im', 'ap', '_.', '_keys', '_(', '_)', '_)', '_,', '_{', '_}', '_)', '_}', '_cat', '_', 'ids', '_=', '_[', '_header', '_.', '_index', '_(', '_cat', '_)', '_for', '_cat', '_in', '_categories', '_if', '_cat', '_in', '_header', '_and', '_"', '="', '_not', '_in', '_cat', '_]', '_table', '_=', '_Ord', 'ered', 'D', 'ict', '_(', '_)', '_conditions', '_=', '_default', 'dict', '_(', '_set', '_)', '_for', '_i', '_,', '_cat', '_in', '_enumer', 'ate', '_(', '_categories', '_)', '_:', '_if', '_"', '="', '_in', '_cat', '_and', '_cat', '_.', '_split', '_(', '_"', '="', '_)', '_[', '_0', '_]', '_in', '_header', '_:', '_cat', '_', 'name', '_=', '_header', '_[', '_header', '_.', '_index', '_(', '_cat', '_.', '_split', '_(', '_"', '="', '_)', '_[', '_0', '_]', '_)', '_]', '_conditions', '_[', '_cat', '_', 'name', '_]', '_.', '_add', '_(', '_cat', '_.', '_split', '_(', '_"', '="', '_)', '_[', '_1', '_]', '_)', '_if', '_not', '_cat', '_', 'ids', '_and', '_not', '_conditions', '_:', '_return', '_{', '_"', 'default', '"', '_:', '_Data', 'Category', '_(', '_set', '_(', '_im', 'ap', '_.', '_keys', '_(', '_)', '_)', '_,', '_{', '_}', '_)', '_}', '_if', '_cat', '_', 'ids', '_and', '_not', '_conditions', '_:', '_for', '_sid', '_,', '_row', '_in', '_im', 'ap', '_.', '_items', '_(', '_)', '_:', '_cat', '_', 'name', '_=', '_"_', '"', '_.', '_join', '_(', '_[', '_row', '_[', '_c', 'id', '_]', '_for', '_c', 'id', '_in', '_cat', '_', 'ids', '_]', '_)', '_if', '_cat', '_', 'name', '_not', '_in', '_table', '_:', '_table', '_[', '_cat', '_', 'name', '_]', '_=', '_Data', 'Category', '_(', '_set', '_(', '_)', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   source_ids: 0 9232 7365 1215 438 45885 36 4356 1115 2156 12734 2156 6363 5457 9291 4839 4832 114 6363 16 9291 4832 671 25522 22 43234 113 4832 5423 46308 36 278 36 4356 1115 479 10654 36 4839 4839 2156 25522 35524 4839 35524 4758 1215 7823 5457 646 12734 479 1965 36 4758 4839 13 4758 11 6363 114 4758 11 12734 8 22 40635 45 11 4758 27779 2103 5457 16702 3215 495 11726 36 4839 1274 5457 6814 25867 36 278 4839 13 939 2156 4758 11 41949 877 36 6363 4839 4832 114 22 40635 11 4758 8 4758 479 3462 36 22 40635 4839 646 321 27779 11 12734 4832 4758 1215 13650 5457 12734 646 12734 479 1965 36 4758 479 3462 36 22 40635 4839 646 321 27779 4839 27779 1274 646 4758 1215 13650 27779 479 1606 36 4758 479 3462 36 22 40635 4839 646 112 27779 4839 114 45 4758 1215 7823 8 45 1274 4832 671 25522 22 43234 113 4832 5423 46308 36 278 36 4356 1115 479 10654 36 4839 4839 2156 25522 35524 4839 35524 114 4758 1215 7823 8 45 1274 4832 13 16742 2156 3236 11 4356 1115 479 1964 36 4839 4832 4758 1215 13650 5457 49713 113 479 1962 36 646 3236 646 740 808 27779 13 740 808 11 4758 1215 7823 27779 4839 114 4758 1215 13650 45 11 2103 4832 2103 646 4758 1215 13650 27779 5457 5423 46308 36 278 36 4839 2
03/28/2022 15:03:03 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_tokens: ['<s>', 'Find', '_the', '_user', '_specified', '_categories', '_in', '_the', '_map', '_and', '_create', '_a', '_dictionary', '_to', '_contain', '_the', '_relevant', '_data', '_for', '_each', '_type', '_within', '_the', '_categories', '_.', '_Multiple', '_categories', '_will', '_have', '_their', '_types', '_combined', '_such', '_that', '_each', '_possible', '_combination', '_will', '_have', '_its', '_own', '_entry', '_in', '_the', '_dictionary', '_.', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   target_ids: 0 38195 5 3018 17966 6363 11 5 5456 8 1045 10 36451 7 5585 5 4249 414 13 349 1907 624 5 6363 479 16210 6363 40 33 49 3505 2771 215 14 349 678 4069 40 33 63 308 3555 11 5 36451 479 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   *** Example ***
03/28/2022 15:03:03 - INFO - __main__ -   idx: 4
03/28/2022 15:03:03 - INFO - __main__ -   source_tokens: ['<s>', 'def', '_parse', '_', 'un', 'if', 'rac', '_(', '_un', 'if', 'rac', 'FN', '_)', '_:', '_with', '_open', '_(', '_un', 'if', 'rac', 'FN', '_,', '_"', 'r', 'U', '"', '_)', '_as', '_u', 'F', '_:', '_first', '_=', '_u', 'F', '_.', '_next', '_(', '_)', '_.', '_split', '_(', '_"\\', 't', '"', '_)', '_lines', '_=', '_[', '_line', '_.', '_strip', '_(', '_)', '_for', '_line', '_in', '_u', 'F', '_]', '_un', 'if', 'rac', '_=', '_{', '_"', 'p', 'cd', '"', '_:', '_Ord', 'ered', 'D', 'ict', '_(', '_)', '_,', '_"', 'e', 'ig', 'vals', '"', '_:', '_[', '_]', '_,', '_"', 'v', 'are', 'xp', '"', '_:', '_[', '_]', '_}', '_if', '_first', '_[', '_0', '_]', '_==', '_"', 'pc', '_vector', '_number', '"', '_:', '_return', '_parse', '_', 'un', 'if', 'rac', '_', 'v', '1', '_', '8', '_(', '_un', 'if', 'rac', '_,', '_lines', '_)', '_el', 'if', '_first', '_[', '_0', '_]', '_==', '_"', 'E', 'ig', 'vals', '"', '_:', '_return', '_parse', '_', 'un', 'if', 'rac', '_', 'v', '1', '_', '9', '_(', '_un', 'if', 'rac', '_,', '_lines', '_)', '_else', '_:', '_raise', '_Value', 'Error', '_(', '_"', 'File', '_format', '_not', '_supported', '/', 'recogn', 'ized', '.', '_Please', '_check', '_input', '_"', '_"', 'un', 'if', 'rac', '_file', '."', '_)', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   source_ids: 0 9232 43756 1215 879 1594 13249 36 542 1594 13249 38350 4839 4832 19 490 36 542 1594 13249 38350 2156 22 338 791 113 4839 25 1717 597 4832 78 5457 1717 597 479 220 36 4839 479 3462 36 49761 90 113 4839 2301 5457 646 516 479 9572 36 4839 13 516 11 1717 597 27779 542 1594 13249 5457 25522 22 642 28690 113 4832 16702 3215 495 11726 36 4839 2156 22 242 1023 21049 113 4832 646 27779 2156 22 705 1322 44813 113 4832 646 27779 35524 114 78 646 321 27779 45994 22 17426 37681 346 113 4832 671 43756 1215 879 1594 13249 1215 705 134 1215 398 36 542 1594 13249 2156 2301 4839 1615 1594 78 646 321 27779 45994 22 717 1023 21049 113 4832 671 43756 1215 879 1594 13249 1215 705 134 1215 466 36 542 1594 13249 2156 2301 4839 1493 4832 1693 11714 30192 36 22 9966 7390 45 2800 73 28039 1538 4 3401 1649 8135 22 22 879 1594 13249 2870 72 4839 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   source_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
03/28/2022 15:03:03 - INFO - __main__ -   target_tokens: ['<s>', 'P', 'ars', 'es', '_the', '_un', 'if', 'rac', '_results', '_file', '_into', '_a', '_dictionary', '</s>']
03/28/2022 15:03:03 - INFO - __main__ -   target_ids: 0 510 2726 293 5 542 1594 13249 775 2870 88 10 36451 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
03/28/2022 15:03:03 - INFO - __main__ -   target_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
C:\Users\sriva\anaconda3\envs\DLAssignment\lib\site-packages\transformers\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
03/28/2022 15:06:05 - INFO - __main__ -   ***** Running training *****
03/28/2022 15:06:05 - INFO - __main__ -     Num examples = 251820
03/28/2022 15:06:05 - INFO - __main__ -     Batch size = 8
03/28/2022 15:06:05 - INFO - __main__ -     Num epoch = 1
loss 5.5346:   2%|▏         | 998/50000 [05:57<4:03:36,  3.35it/s]03/28/2022 15:12:13 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 15:12:13 - INFO - __main__ -     Num examples = 13914
03/28/2022 15:12:13 - INFO - __main__ -     Batch size = 8
03/28/2022 15:14:56 - INFO - __main__ -     eval_ppl = 173.22565
03/28/2022 15:14:56 - INFO - __main__ -     global_step = 1000
03/28/2022 15:14:56 - INFO - __main__ -     train_loss = 5.5346
03/28/2022 15:14:56 - INFO - __main__ -     ********************
03/28/2022 15:14:58 - INFO - __main__ -     Best ppl:173.22565
03/28/2022 15:14:58 - INFO - __main__ -     ********************
C:\Users\sriva\OneDrive\Documents\Lectures\CE7455\Project\CodeBERT\CodeBERT\code2nl\model.py:165: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').
  prevK = bestScoresId // numWords
Total: 1000
03/28/2022 15:21:07 - INFO - __main__ -     bleu-4 = 10.82 
03/28/2022 15:21:07 - INFO - __main__ -     ********************
03/28/2022 15:21:07 - INFO - __main__ -     Best bleu:10.82
03/28/2022 15:21:07 - INFO - __main__ -     ********************
loss 4.7285:   4%|▍         | 1998/50000 [20:23<3:56:16,  3.39it/s]03/28/2022 15:26:29 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 15:26:29 - INFO - __main__ -     Num examples = 13914
03/28/2022 15:26:29 - INFO - __main__ -     Batch size = 8
03/28/2022 15:28:46 - INFO - __main__ -     eval_ppl = 119.23383
03/28/2022 15:28:46 - INFO - __main__ -     global_step = 2000
03/28/2022 15:28:46 - INFO - __main__ -     train_loss = 4.7285
03/28/2022 15:28:46 - INFO - __main__ -     ********************
03/28/2022 15:28:47 - INFO - __main__ -     Best ppl:119.23383
03/28/2022 15:28:47 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 15:31:55 - INFO - __main__ -     bleu-4 = 12.14 
03/28/2022 15:31:55 - INFO - __main__ -     ********************
03/28/2022 15:31:55 - INFO - __main__ -     Best bleu:12.14
03/28/2022 15:31:55 - INFO - __main__ -     ********************
loss 4.4319:   6%|▌         | 2998/50000 [30:44<3:50:14,  3.40it/s]03/28/2022 15:36:49 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 15:36:49 - INFO - __main__ -     Num examples = 13914
03/28/2022 15:36:49 - INFO - __main__ -     Batch size = 8
03/28/2022 15:39:07 - INFO - __main__ -     eval_ppl = 97.93949
03/28/2022 15:39:07 - INFO - __main__ -     global_step = 3000
03/28/2022 15:39:07 - INFO - __main__ -     train_loss = 4.4319
03/28/2022 15:39:07 - INFO - __main__ -     ********************
03/28/2022 15:39:08 - INFO - __main__ -     Best ppl:97.93949
03/28/2022 15:39:08 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 15:42:19 - INFO - __main__ -     bleu-4 = 12.21 
03/28/2022 15:42:19 - INFO - __main__ -     ********************
03/28/2022 15:42:19 - INFO - __main__ -     Best bleu:12.21
03/28/2022 15:42:19 - INFO - __main__ -     ********************
loss 4.2593:   8%|▊         | 3998/50000 [41:10<3:46:26,  3.39it/s]03/28/2022 15:47:16 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 15:47:16 - INFO - __main__ -     Num examples = 13914
03/28/2022 15:47:16 - INFO - __main__ -     Batch size = 8
03/28/2022 15:49:37 - INFO - __main__ -     eval_ppl = 78.84867
03/28/2022 15:49:37 - INFO - __main__ -     global_step = 4000
03/28/2022 15:49:37 - INFO - __main__ -     train_loss = 4.2593
03/28/2022 15:49:37 - INFO - __main__ -     ********************
03/28/2022 15:49:38 - INFO - __main__ -     Best ppl:78.84867
03/28/2022 15:49:38 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 15:53:40 - INFO - __main__ -     bleu-4 = 13.65 
03/28/2022 15:53:40 - INFO - __main__ -     ********************
03/28/2022 15:53:40 - INFO - __main__ -     Best bleu:13.65
03/28/2022 15:53:40 - INFO - __main__ -     ********************
loss 4.1404:  10%|▉         | 4998/50000 [52:38<3:41:50,  3.38it/s]03/28/2022 15:58:44 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 15:58:44 - INFO - __main__ -     Num examples = 13914
03/28/2022 15:58:44 - INFO - __main__ -     Batch size = 8
03/28/2022 16:01:05 - INFO - __main__ -     eval_ppl = 73.45707
03/28/2022 16:01:05 - INFO - __main__ -     global_step = 5000
03/28/2022 16:01:05 - INFO - __main__ -     train_loss = 4.1404
03/28/2022 16:01:05 - INFO - __main__ -     ********************
03/28/2022 16:01:06 - INFO - __main__ -     Best ppl:73.45707
03/28/2022 16:01:06 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 16:04:18 - INFO - __main__ -     bleu-4 = 13.61 
03/28/2022 16:04:18 - INFO - __main__ -     ********************
loss 4.0243:  12%|█▏        | 5998/50000 [1:03:27<4:41:47,  2.60it/s]03/28/2022 16:09:32 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 16:09:32 - INFO - __main__ -     Num examples = 13914
03/28/2022 16:09:32 - INFO - __main__ -     Batch size = 8
03/28/2022 16:11:50 - INFO - __main__ -     eval_ppl = 63.14082
03/28/2022 16:11:50 - INFO - __main__ -     global_step = 6000
03/28/2022 16:11:50 - INFO - __main__ -     train_loss = 4.0243
03/28/2022 16:11:50 - INFO - __main__ -     ********************
03/28/2022 16:11:51 - INFO - __main__ -     Best ppl:63.14082
03/28/2022 16:11:51 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 16:15:08 - INFO - __main__ -     bleu-4 = 14.72 
03/28/2022 16:15:08 - INFO - __main__ -     ********************
03/28/2022 16:15:08 - INFO - __main__ -     Best bleu:14.72
03/28/2022 16:15:08 - INFO - __main__ -     ********************
loss 3.9623:  14%|█▍        | 6998/50000 [1:14:01<3:33:27,  3.36it/s]03/28/2022 16:20:06 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 16:20:06 - INFO - __main__ -     Num examples = 13914
03/28/2022 16:20:06 - INFO - __main__ -     Batch size = 8
03/28/2022 16:22:24 - INFO - __main__ -     eval_ppl = 58.42869
03/28/2022 16:22:24 - INFO - __main__ -     global_step = 7000
03/28/2022 16:22:24 - INFO - __main__ -     train_loss = 3.9623
03/28/2022 16:22:24 - INFO - __main__ -     ********************
03/28/2022 16:22:25 - INFO - __main__ -     Best ppl:58.42869
03/28/2022 16:22:25 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 16:26:17 - INFO - __main__ -     bleu-4 = 14.66 
03/28/2022 16:26:17 - INFO - __main__ -     ********************
loss 3.8812:  16%|█▌        | 7998/50000 [1:25:10<3:27:41,  3.37it/s]03/28/2022 16:31:16 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 16:31:16 - INFO - __main__ -     Num examples = 13914
03/28/2022 16:31:16 - INFO - __main__ -     Batch size = 8
03/28/2022 16:33:39 - INFO - __main__ -     eval_ppl = 53.51301
03/28/2022 16:33:39 - INFO - __main__ -     global_step = 8000
03/28/2022 16:33:39 - INFO - __main__ -     train_loss = 3.8812
03/28/2022 16:33:39 - INFO - __main__ -     ********************
03/28/2022 16:33:40 - INFO - __main__ -     Best ppl:53.51301
03/28/2022 16:33:40 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 16:37:03 - INFO - __main__ -     bleu-4 = 15.41 
03/28/2022 16:37:03 - INFO - __main__ -     ********************
03/28/2022 16:37:03 - INFO - __main__ -     Best bleu:15.41
03/28/2022 16:37:03 - INFO - __main__ -     ********************
loss 3.7998:  18%|█▊        | 8998/50000 [1:36:05<3:29:03,  3.27it/s]03/28/2022 16:42:10 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 16:42:10 - INFO - __main__ -     Num examples = 13914
03/28/2022 16:42:10 - INFO - __main__ -     Batch size = 8
03/28/2022 16:44:34 - INFO - __main__ -     eval_ppl = 51.27983
03/28/2022 16:44:34 - INFO - __main__ -     global_step = 9000
03/28/2022 16:44:34 - INFO - __main__ -     train_loss = 3.7998
03/28/2022 16:44:34 - INFO - __main__ -     ********************
03/28/2022 16:44:35 - INFO - __main__ -     Best ppl:51.27983
03/28/2022 16:44:35 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 16:47:55 - INFO - __main__ -     bleu-4 = 15.84 
03/28/2022 16:47:55 - INFO - __main__ -     ********************
03/28/2022 16:47:55 - INFO - __main__ -     Best bleu:15.84
03/28/2022 16:47:55 - INFO - __main__ -     ********************
loss 3.7549:  20%|█▉        | 9998/50000 [1:48:11<4:21:34,  2.55it/s]03/28/2022 16:54:17 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 16:54:17 - INFO - __main__ -     Num examples = 13914
03/28/2022 16:54:17 - INFO - __main__ -     Batch size = 8
03/28/2022 16:57:01 - INFO - __main__ -     eval_ppl = 49.93831
03/28/2022 16:57:01 - INFO - __main__ -     global_step = 10000
03/28/2022 16:57:01 - INFO - __main__ -     train_loss = 3.7549
03/28/2022 16:57:01 - INFO - __main__ -     ********************
03/28/2022 16:57:02 - INFO - __main__ -     Best ppl:49.93831
03/28/2022 16:57:02 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:01:32 - INFO - __main__ -     bleu-4 = 16.23 
03/28/2022 17:01:32 - INFO - __main__ -     ********************
03/28/2022 17:01:32 - INFO - __main__ -     Best bleu:16.23
03/28/2022 17:01:32 - INFO - __main__ -     ********************
loss 3.6899:  22%|██▏       | 10998/50000 [2:00:50<4:02:13,  2.68it/s]03/28/2022 17:06:55 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 17:06:55 - INFO - __main__ -     Num examples = 13914
03/28/2022 17:06:55 - INFO - __main__ -     Batch size = 8
03/28/2022 17:09:29 - INFO - __main__ -     eval_ppl = 47.14324
03/28/2022 17:09:29 - INFO - __main__ -     global_step = 11000
03/28/2022 17:09:29 - INFO - __main__ -     train_loss = 3.6899
03/28/2022 17:09:29 - INFO - __main__ -     ********************
03/28/2022 17:09:30 - INFO - __main__ -     Best ppl:47.14324
03/28/2022 17:09:30 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:13:47 - INFO - __main__ -     bleu-4 = 16.26 
03/28/2022 17:13:47 - INFO - __main__ -     ********************
03/28/2022 17:13:47 - INFO - __main__ -     Best bleu:16.26
03/28/2022 17:13:47 - INFO - __main__ -     ********************
loss 3.6515:  24%|██▍       | 11998/50000 [2:13:07<3:50:38,  2.75it/s]03/28/2022 17:19:13 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 17:19:13 - INFO - __main__ -     Num examples = 13914
03/28/2022 17:19:13 - INFO - __main__ -     Batch size = 8
03/28/2022 17:21:45 - INFO - __main__ -     eval_ppl = 45.47747
03/28/2022 17:21:45 - INFO - __main__ -     global_step = 12000
03/28/2022 17:21:45 - INFO - __main__ -     train_loss = 3.6515
03/28/2022 17:21:45 - INFO - __main__ -     ********************
03/28/2022 17:21:46 - INFO - __main__ -     Best ppl:45.47747
03/28/2022 17:21:46 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:25:07 - INFO - __main__ -     bleu-4 = 16.2 
03/28/2022 17:25:07 - INFO - __main__ -     ********************
loss 3.6254:  26%|██▌       | 12998/50000 [2:24:12<3:27:40,  2.97it/s]03/28/2022 17:30:17 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 17:30:17 - INFO - __main__ -     Num examples = 13914
03/28/2022 17:30:17 - INFO - __main__ -     Batch size = 8
03/28/2022 17:32:46 - INFO - __main__ -     eval_ppl = 43.95498
03/28/2022 17:32:46 - INFO - __main__ -     global_step = 13000
03/28/2022 17:32:46 - INFO - __main__ -     train_loss = 3.6254
03/28/2022 17:32:46 - INFO - __main__ -     ********************
03/28/2022 17:32:47 - INFO - __main__ -     Best ppl:43.95498
03/28/2022 17:32:47 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:36:31 - INFO - __main__ -     bleu-4 = 16.2 
03/28/2022 17:36:31 - INFO - __main__ -     ********************
loss 3.5795:  28%|██▊       | 13998/50000 [2:35:31<2:56:30,  3.40it/s]03/28/2022 17:41:37 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 17:41:37 - INFO - __main__ -     Num examples = 13914
03/28/2022 17:41:37 - INFO - __main__ -     Batch size = 8
03/28/2022 17:43:58 - INFO - __main__ -     eval_ppl = 42.70641
03/28/2022 17:43:58 - INFO - __main__ -     global_step = 14000
03/28/2022 17:43:58 - INFO - __main__ -     train_loss = 3.5795
03/28/2022 17:43:58 - INFO - __main__ -     ********************
03/28/2022 17:43:59 - INFO - __main__ -     Best ppl:42.70641
03/28/2022 17:43:59 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:47:19 - INFO - __main__ -     bleu-4 = 16.23 
03/28/2022 17:47:19 - INFO - __main__ -     ********************
loss 3.5792:  30%|██▉       | 14998/50000 [2:46:19<3:04:37,  3.16it/s]03/28/2022 17:52:25 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 17:52:25 - INFO - __main__ -     Num examples = 13914
03/28/2022 17:52:25 - INFO - __main__ -     Batch size = 8
03/28/2022 17:54:47 - INFO - __main__ -     eval_ppl = 41.44045
03/28/2022 17:54:47 - INFO - __main__ -     global_step = 15000
03/28/2022 17:54:47 - INFO - __main__ -     train_loss = 3.5792
03/28/2022 17:54:47 - INFO - __main__ -     ********************
03/28/2022 17:54:49 - INFO - __main__ -     Best ppl:41.44045
03/28/2022 17:54:49 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 17:57:54 - INFO - __main__ -     bleu-4 = 16.71 
03/28/2022 17:57:54 - INFO - __main__ -     ********************
03/28/2022 17:57:54 - INFO - __main__ -     Best bleu:16.71
03/28/2022 17:57:54 - INFO - __main__ -     ********************
loss 3.5398:  32%|███▏      | 15998/50000 [2:56:50<2:46:54,  3.40it/s]03/28/2022 18:02:55 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:02:55 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:02:55 - INFO - __main__ -     Batch size = 8
03/28/2022 18:05:15 - INFO - __main__ -     eval_ppl = 40.4564
03/28/2022 18:05:15 - INFO - __main__ -     global_step = 16000
03/28/2022 18:05:15 - INFO - __main__ -     train_loss = 3.5398
03/28/2022 18:05:15 - INFO - __main__ -     ********************
03/28/2022 18:05:16 - INFO - __main__ -     Best ppl:40.4564
03/28/2022 18:05:16 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 18:08:20 - INFO - __main__ -     bleu-4 = 16.83 
03/28/2022 18:08:20 - INFO - __main__ -     ********************
03/28/2022 18:08:20 - INFO - __main__ -     Best bleu:16.83
03/28/2022 18:08:20 - INFO - __main__ -     ********************
loss 3.5368:  34%|███▍      | 16998/50000 [3:07:13<2:42:38,  3.38it/s]03/28/2022 18:13:18 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:13:18 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:13:18 - INFO - __main__ -     Batch size = 8
03/28/2022 18:15:37 - INFO - __main__ -     eval_ppl = 39.06411
03/28/2022 18:15:37 - INFO - __main__ -     global_step = 17000
03/28/2022 18:15:37 - INFO - __main__ -     train_loss = 3.5368
03/28/2022 18:15:37 - INFO - __main__ -     ********************
03/28/2022 18:15:38 - INFO - __main__ -     Best ppl:39.06411
03/28/2022 18:15:38 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 18:18:45 - INFO - __main__ -     bleu-4 = 16.4 
03/28/2022 18:18:45 - INFO - __main__ -     ********************
loss 3.4586:  36%|███▌      | 17998/50000 [3:17:35<2:37:37,  3.38it/s]03/28/2022 18:23:40 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:23:40 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:23:40 - INFO - __main__ -     Batch size = 8
03/28/2022 18:25:58 - INFO - __main__ -     eval_ppl = 38.53534
03/28/2022 18:25:58 - INFO - __main__ -     global_step = 18000
03/28/2022 18:25:58 - INFO - __main__ -     train_loss = 3.4586
03/28/2022 18:25:58 - INFO - __main__ -     ********************
03/28/2022 18:25:59 - INFO - __main__ -     Best ppl:38.53534
03/28/2022 18:25:59 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 18:29:06 - INFO - __main__ -     bleu-4 = 16.67 
03/28/2022 18:29:06 - INFO - __main__ -     ********************
loss 3.4569:  38%|███▊      | 18998/50000 [3:27:57<2:32:49,  3.38it/s]03/28/2022 18:34:02 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:34:02 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:34:02 - INFO - __main__ -     Batch size = 8
03/28/2022 18:36:19 - INFO - __main__ -     eval_ppl = 37.21568
03/28/2022 18:36:19 - INFO - __main__ -     global_step = 19000
03/28/2022 18:36:19 - INFO - __main__ -     train_loss = 3.4569
03/28/2022 18:36:19 - INFO - __main__ -     ********************
03/28/2022 18:36:21 - INFO - __main__ -     Best ppl:37.21568
03/28/2022 18:36:21 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 18:39:45 - INFO - __main__ -     bleu-4 = 16.64 
03/28/2022 18:39:45 - INFO - __main__ -     ********************
loss 3.4599:  40%|███▉      | 19998/50000 [3:38:35<2:28:26,  3.37it/s]03/28/2022 18:44:40 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:44:40 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:44:40 - INFO - __main__ -     Batch size = 8
03/28/2022 18:46:58 - INFO - __main__ -     eval_ppl = 36.68263
03/28/2022 18:46:58 - INFO - __main__ -     global_step = 20000
03/28/2022 18:46:58 - INFO - __main__ -     train_loss = 3.4599
03/28/2022 18:46:58 - INFO - __main__ -     ********************
03/28/2022 18:46:59 - INFO - __main__ -     Best ppl:36.68263
03/28/2022 18:46:59 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 18:50:23 - INFO - __main__ -     bleu-4 = 16.8 
03/28/2022 18:50:23 - INFO - __main__ -     ********************
loss 3.4319:  42%|████▏     | 20998/50000 [3:49:13<2:22:56,  3.38it/s]03/28/2022 18:55:18 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 18:55:18 - INFO - __main__ -     Num examples = 13914
03/28/2022 18:55:18 - INFO - __main__ -     Batch size = 8
03/28/2022 18:57:36 - INFO - __main__ -     eval_ppl = 36.27034
03/28/2022 18:57:36 - INFO - __main__ -     global_step = 21000
03/28/2022 18:57:36 - INFO - __main__ -     train_loss = 3.4319
03/28/2022 18:57:36 - INFO - __main__ -     ********************
03/28/2022 18:57:37 - INFO - __main__ -     Best ppl:36.27034
03/28/2022 18:57:37 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:00:57 - INFO - __main__ -     bleu-4 = 16.21 
03/28/2022 19:00:57 - INFO - __main__ -     ********************
loss 3.3995:  44%|████▍     | 21998/50000 [3:59:47<2:17:34,  3.39it/s]03/28/2022 19:05:52 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:05:52 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:05:52 - INFO - __main__ -     Batch size = 8
03/28/2022 19:08:10 - INFO - __main__ -     eval_ppl = 35.32662
03/28/2022 19:08:10 - INFO - __main__ -     global_step = 22000
03/28/2022 19:08:10 - INFO - __main__ -     train_loss = 3.3995
03/28/2022 19:08:10 - INFO - __main__ -     ********************
03/28/2022 19:08:11 - INFO - __main__ -     Best ppl:35.32662
03/28/2022 19:08:11 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:11:45 - INFO - __main__ -     bleu-4 = 16.83 
03/28/2022 19:11:45 - INFO - __main__ -     ********************
loss 3.3668:  46%|████▌     | 22998/50000 [4:10:36<2:13:15,  3.38it/s]03/28/2022 19:16:41 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:16:41 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:16:41 - INFO - __main__ -     Batch size = 8
03/28/2022 19:18:58 - INFO - __main__ -     eval_ppl = 34.86279
03/28/2022 19:18:58 - INFO - __main__ -     global_step = 23000
03/28/2022 19:18:58 - INFO - __main__ -     train_loss = 3.3668
03/28/2022 19:18:58 - INFO - __main__ -     ********************
03/28/2022 19:18:59 - INFO - __main__ -     Best ppl:34.86279
03/28/2022 19:18:59 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:22:02 - INFO - __main__ -     bleu-4 = 16.98 
03/28/2022 19:22:02 - INFO - __main__ -     ********************
03/28/2022 19:22:02 - INFO - __main__ -     Best bleu:16.98
03/28/2022 19:22:02 - INFO - __main__ -     ********************
loss 3.3535:  48%|████▊     | 23998/50000 [4:20:55<2:08:20,  3.38it/s]03/28/2022 19:27:01 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:27:01 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:27:01 - INFO - __main__ -     Batch size = 8
03/28/2022 19:29:18 - INFO - __main__ -     eval_ppl = 34.56607
03/28/2022 19:29:18 - INFO - __main__ -     global_step = 24000
03/28/2022 19:29:18 - INFO - __main__ -     train_loss = 3.3535
03/28/2022 19:29:18 - INFO - __main__ -     ********************
03/28/2022 19:29:19 - INFO - __main__ -     Best ppl:34.56607
03/28/2022 19:29:19 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:32:16 - INFO - __main__ -     bleu-4 = 17.19 
03/28/2022 19:32:16 - INFO - __main__ -     ********************
03/28/2022 19:32:16 - INFO - __main__ -     Best bleu:17.19
03/28/2022 19:32:16 - INFO - __main__ -     ********************
loss 3.3282:  50%|████▉     | 24998/50000 [4:31:07<2:02:49,  3.39it/s]03/28/2022 19:37:13 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:37:13 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:37:13 - INFO - __main__ -     Batch size = 8
03/28/2022 19:39:31 - INFO - __main__ -     eval_ppl = 33.9613
03/28/2022 19:39:31 - INFO - __main__ -     global_step = 25000
03/28/2022 19:39:31 - INFO - __main__ -     train_loss = 3.3282
03/28/2022 19:39:31 - INFO - __main__ -     ********************
03/28/2022 19:39:32 - INFO - __main__ -     Best ppl:33.9613
03/28/2022 19:39:32 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:43:03 - INFO - __main__ -     bleu-4 = 17.02 
03/28/2022 19:43:03 - INFO - __main__ -     ********************
loss 3.3107:  52%|█████▏    | 25998/50000 [4:41:54<1:57:58,  3.39it/s]03/28/2022 19:47:59 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:47:59 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:47:59 - INFO - __main__ -     Batch size = 8
03/28/2022 19:50:17 - INFO - __main__ -     eval_ppl = 33.47226
03/28/2022 19:50:17 - INFO - __main__ -     global_step = 26000
03/28/2022 19:50:17 - INFO - __main__ -     train_loss = 3.3107
03/28/2022 19:50:17 - INFO - __main__ -     ********************
03/28/2022 19:50:18 - INFO - __main__ -     Best ppl:33.47226
03/28/2022 19:50:18 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 19:53:33 - INFO - __main__ -     bleu-4 = 17.29 
03/28/2022 19:53:33 - INFO - __main__ -     ********************
03/28/2022 19:53:33 - INFO - __main__ -     Best bleu:17.29
03/28/2022 19:53:33 - INFO - __main__ -     ********************
loss 3.3059:  54%|█████▍    | 26998/50000 [4:52:24<1:52:45,  3.40it/s]03/28/2022 19:58:29 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 19:58:29 - INFO - __main__ -     Num examples = 13914
03/28/2022 19:58:29 - INFO - __main__ -     Batch size = 8
03/28/2022 20:00:46 - INFO - __main__ -     eval_ppl = 33.10132
03/28/2022 20:00:46 - INFO - __main__ -     global_step = 27000
03/28/2022 20:00:46 - INFO - __main__ -     train_loss = 3.3059
03/28/2022 20:00:46 - INFO - __main__ -     ********************
03/28/2022 20:00:47 - INFO - __main__ -     Best ppl:33.10132
03/28/2022 20:00:47 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:03:43 - INFO - __main__ -     bleu-4 = 17.06 
03/28/2022 20:03:43 - INFO - __main__ -     ********************
loss 3.3061:  56%|█████▌    | 27998/50000 [5:02:33<1:47:42,  3.40it/s]03/28/2022 20:08:38 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 20:08:38 - INFO - __main__ -     Num examples = 13914
03/28/2022 20:08:38 - INFO - __main__ -     Batch size = 8
03/28/2022 20:10:56 - INFO - __main__ -     eval_ppl = 32.44292
03/28/2022 20:10:56 - INFO - __main__ -     global_step = 28000
03/28/2022 20:10:56 - INFO - __main__ -     train_loss = 3.3061
03/28/2022 20:10:56 - INFO - __main__ -     ********************
03/28/2022 20:10:57 - INFO - __main__ -     Best ppl:32.44292
03/28/2022 20:10:57 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:13:55 - INFO - __main__ -     bleu-4 = 16.82 
03/28/2022 20:13:55 - INFO - __main__ -     ********************
loss 3.2788:  58%|█████▊    | 28998/50000 [5:12:51<1:44:01,  3.37it/s]03/28/2022 20:18:56 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 20:18:56 - INFO - __main__ -     Num examples = 13914
03/28/2022 20:18:56 - INFO - __main__ -     Batch size = 8
03/28/2022 20:21:15 - INFO - __main__ -     eval_ppl = 32.11522
03/28/2022 20:21:15 - INFO - __main__ -     global_step = 29000
03/28/2022 20:21:15 - INFO - __main__ -     train_loss = 3.2788
03/28/2022 20:21:15 - INFO - __main__ -     ********************
03/28/2022 20:21:16 - INFO - __main__ -     Best ppl:32.11522
03/28/2022 20:21:16 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:24:29 - INFO - __main__ -     bleu-4 = 17.72 
03/28/2022 20:24:29 - INFO - __main__ -     ********************
03/28/2022 20:24:29 - INFO - __main__ -     Best bleu:17.72
03/28/2022 20:24:29 - INFO - __main__ -     ********************
loss 3.2676:  60%|█████▉    | 29998/50000 [5:23:24<1:38:46,  3.37it/s]03/28/2022 20:29:29 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 20:29:29 - INFO - __main__ -     Num examples = 13914
03/28/2022 20:29:29 - INFO - __main__ -     Batch size = 8
03/28/2022 20:31:47 - INFO - __main__ -     eval_ppl = 31.8052
03/28/2022 20:31:47 - INFO - __main__ -     global_step = 30000
03/28/2022 20:31:47 - INFO - __main__ -     train_loss = 3.2676
03/28/2022 20:31:47 - INFO - __main__ -     ********************
03/28/2022 20:31:48 - INFO - __main__ -     Best ppl:31.8052
03/28/2022 20:31:48 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:35:05 - INFO - __main__ -     bleu-4 = 17.25 
03/28/2022 20:35:05 - INFO - __main__ -     ********************
loss 3.2743:  62%|██████▏   | 30998/50000 [5:33:55<1:34:55,  3.34it/s]03/28/2022 20:40:00 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 20:40:00 - INFO - __main__ -     Num examples = 13914
03/28/2022 20:40:00 - INFO - __main__ -     Batch size = 8
03/28/2022 20:42:19 - INFO - __main__ -     eval_ppl = 31.21525
03/28/2022 20:42:19 - INFO - __main__ -     global_step = 31000
03/28/2022 20:42:19 - INFO - __main__ -     train_loss = 3.2743
03/28/2022 20:42:19 - INFO - __main__ -     ********************
03/28/2022 20:42:20 - INFO - __main__ -     Best ppl:31.21525
03/28/2022 20:42:20 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:45:25 - INFO - __main__ -     bleu-4 = 17.48 
03/28/2022 20:45:25 - INFO - __main__ -     ********************
loss 3.2136:  64%|██████▍   | 31998/50000 [5:44:32<1:30:14,  3.32it/s]03/28/2022 20:50:38 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 20:50:38 - INFO - __main__ -     Num examples = 13914
03/28/2022 20:50:38 - INFO - __main__ -     Batch size = 8
03/28/2022 20:53:00 - INFO - __main__ -     eval_ppl = 31.11532
03/28/2022 20:53:00 - INFO - __main__ -     global_step = 32000
03/28/2022 20:53:00 - INFO - __main__ -     train_loss = 3.2136
03/28/2022 20:53:00 - INFO - __main__ -     ********************
03/28/2022 20:53:01 - INFO - __main__ -     Best ppl:31.11532
03/28/2022 20:53:01 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 20:56:07 - INFO - __main__ -     bleu-4 = 17.18 
03/28/2022 20:56:07 - INFO - __main__ -     ********************
loss 3.1785:  66%|██████▌   | 32998/50000 [5:55:06<1:24:07,  3.37it/s]03/28/2022 21:01:12 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 21:01:12 - INFO - __main__ -     Num examples = 13914
03/28/2022 21:01:12 - INFO - __main__ -     Batch size = 8
03/28/2022 21:03:29 - INFO - __main__ -     eval_ppl = 30.58741
03/28/2022 21:03:29 - INFO - __main__ -     global_step = 33000
03/28/2022 21:03:29 - INFO - __main__ -     train_loss = 3.1785
03/28/2022 21:03:29 - INFO - __main__ -     ********************
03/28/2022 21:03:30 - INFO - __main__ -     Best ppl:30.58741
03/28/2022 21:03:30 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 21:06:36 - INFO - __main__ -     bleu-4 = 17.12 
03/28/2022 21:06:36 - INFO - __main__ -     ********************
loss 3.1403:  68%|██████▊   | 33998/50000 [6:05:59<1:45:22,  2.53it/s]03/28/2022 21:12:04 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 21:12:04 - INFO - __main__ -     Num examples = 13914
03/28/2022 21:12:04 - INFO - __main__ -     Batch size = 8
03/28/2022 21:14:27 - INFO - __main__ -     eval_ppl = 30.18842
03/28/2022 21:14:27 - INFO - __main__ -     global_step = 34000
03/28/2022 21:14:27 - INFO - __main__ -     train_loss = 3.1403
03/28/2022 21:14:27 - INFO - __main__ -     ********************
03/28/2022 21:14:28 - INFO - __main__ -     Best ppl:30.18842
03/28/2022 21:14:28 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 21:17:47 - INFO - __main__ -     bleu-4 = 17.66 
03/28/2022 21:17:47 - INFO - __main__ -     ********************
loss 3.0938:  70%|██████▉   | 34998/50000 [6:17:10<1:28:48,  2.82it/s]03/28/2022 21:23:15 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 21:23:15 - INFO - __main__ -     Num examples = 13914
03/28/2022 21:23:15 - INFO - __main__ -     Batch size = 8
03/28/2022 21:25:59 - INFO - __main__ -     eval_ppl = 30.07329
03/28/2022 21:25:59 - INFO - __main__ -     global_step = 35000
03/28/2022 21:25:59 - INFO - __main__ -     train_loss = 3.0938
03/28/2022 21:25:59 - INFO - __main__ -     ********************
03/28/2022 21:26:00 - INFO - __main__ -     Best ppl:30.07329
03/28/2022 21:26:00 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 21:29:37 - INFO - __main__ -     bleu-4 = 17.62 
03/28/2022 21:29:37 - INFO - __main__ -     ********************
loss 3.0891:  72%|███████▏  | 35998/50000 [6:29:37<1:25:42,  2.72it/s]03/28/2022 21:35:42 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 21:35:42 - INFO - __main__ -     Num examples = 13914
03/28/2022 21:35:42 - INFO - __main__ -     Batch size = 8
03/28/2022 21:38:32 - INFO - __main__ -     eval_ppl = 29.94962
03/28/2022 21:38:32 - INFO - __main__ -     global_step = 36000
03/28/2022 21:38:32 - INFO - __main__ -     train_loss = 3.0891
03/28/2022 21:38:32 - INFO - __main__ -     ********************
03/28/2022 21:38:33 - INFO - __main__ -     Best ppl:29.94962
03/28/2022 21:38:33 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 21:42:09 - INFO - __main__ -     bleu-4 = 17.79 
03/28/2022 21:42:09 - INFO - __main__ -     ********************
03/28/2022 21:42:09 - INFO - __main__ -     Best bleu:17.79
03/28/2022 21:42:09 - INFO - __main__ -     ********************
loss 3.0739:  74%|███████▍  | 36998/50000 [6:42:41<1:27:01,  2.49it/s]03/28/2022 21:48:46 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 21:48:46 - INFO - __main__ -     Num examples = 13914
03/28/2022 21:48:46 - INFO - __main__ -     Batch size = 8
03/28/2022 21:51:53 - INFO - __main__ -     eval_ppl = 29.857
03/28/2022 21:51:53 - INFO - __main__ -     global_step = 37000
03/28/2022 21:51:53 - INFO - __main__ -     train_loss = 3.0739
03/28/2022 21:51:53 - INFO - __main__ -     ********************
03/28/2022 21:51:54 - INFO - __main__ -     Best ppl:29.857
03/28/2022 21:51:54 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 21:56:00 - INFO - __main__ -     bleu-4 = 17.93 
03/28/2022 21:56:00 - INFO - __main__ -     ********************
03/28/2022 21:56:00 - INFO - __main__ -     Best bleu:17.93
03/28/2022 21:56:00 - INFO - __main__ -     ********************
loss 3.0395:  76%|███████▌  | 37998/50000 [6:56:26<1:01:15,  3.27it/s]03/28/2022 22:02:31 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 22:02:31 - INFO - __main__ -     Num examples = 13914
03/28/2022 22:02:31 - INFO - __main__ -     Batch size = 8
03/28/2022 22:05:17 - INFO - __main__ -     eval_ppl = 29.4499
03/28/2022 22:05:17 - INFO - __main__ -     global_step = 38000
03/28/2022 22:05:17 - INFO - __main__ -     train_loss = 3.0395
03/28/2022 22:05:17 - INFO - __main__ -     ********************
03/28/2022 22:05:18 - INFO - __main__ -     Best ppl:29.4499
03/28/2022 22:05:18 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 22:08:41 - INFO - __main__ -     bleu-4 = 17.84 
03/28/2022 22:08:41 - INFO - __main__ -     ********************
loss 3.0358:  78%|███████▊  | 38998/50000 [7:08:46<1:09:04,  2.65it/s]03/28/2022 22:14:51 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 22:14:51 - INFO - __main__ -     Num examples = 13914
03/28/2022 22:14:51 - INFO - __main__ -     Batch size = 8
03/28/2022 22:17:42 - INFO - __main__ -     eval_ppl = 29.38213
03/28/2022 22:17:42 - INFO - __main__ -     global_step = 39000
03/28/2022 22:17:42 - INFO - __main__ -     train_loss = 3.0358
03/28/2022 22:17:42 - INFO - __main__ -     ********************
03/28/2022 22:17:43 - INFO - __main__ -     Best ppl:29.38213
03/28/2022 22:17:43 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 22:21:19 - INFO - __main__ -     bleu-4 = 18.03 
03/28/2022 22:21:19 - INFO - __main__ -     ********************
03/28/2022 22:21:19 - INFO - __main__ -     Best bleu:18.03
03/28/2022 22:21:19 - INFO - __main__ -     ********************
loss 3.0141:  80%|███████▉  | 39998/50000 [7:21:33<1:01:40,  2.70it/s]03/28/2022 22:27:39 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 22:27:39 - INFO - __main__ -     Num examples = 13914
03/28/2022 22:27:39 - INFO - __main__ -     Batch size = 8
03/28/2022 22:30:31 - INFO - __main__ -     eval_ppl = 29.02858
03/28/2022 22:30:31 - INFO - __main__ -     global_step = 40000
03/28/2022 22:30:31 - INFO - __main__ -     train_loss = 3.0141
03/28/2022 22:30:31 - INFO - __main__ -     ********************
03/28/2022 22:30:32 - INFO - __main__ -     Best ppl:29.02858
03/28/2022 22:30:32 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 22:34:02 - INFO - __main__ -     bleu-4 = 18.09 
03/28/2022 22:34:02 - INFO - __main__ -     ********************
03/28/2022 22:34:02 - INFO - __main__ -     Best bleu:18.09
03/28/2022 22:34:02 - INFO - __main__ -     ********************
loss 2.9721:  82%|████████▏ | 40998/50000 [7:34:10<59:50,  2.51it/s]03/28/2022 22:40:16 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 22:40:16 - INFO - __main__ -     Num examples = 13914
03/28/2022 22:40:16 - INFO - __main__ -     Batch size = 8
03/28/2022 22:43:09 - INFO - __main__ -     eval_ppl = 28.82112
03/28/2022 22:43:09 - INFO - __main__ -     global_step = 41000
03/28/2022 22:43:09 - INFO - __main__ -     train_loss = 2.9721
03/28/2022 22:43:09 - INFO - __main__ -     ********************
03/28/2022 22:43:10 - INFO - __main__ -     Best ppl:28.82112
03/28/2022 22:43:10 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 22:46:30 - INFO - __main__ -     bleu-4 = 18.34 
03/28/2022 22:46:30 - INFO - __main__ -     ********************
03/28/2022 22:46:30 - INFO - __main__ -     Best bleu:18.34
03/28/2022 22:46:30 - INFO - __main__ -     ********************
loss 2.9443:  84%|████████▍ | 41998/50000 [7:46:36<49:37,  2.69it/s]03/28/2022 22:52:41 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 22:52:41 - INFO - __main__ -     Num examples = 13914
03/28/2022 22:52:41 - INFO - __main__ -     Batch size = 8
03/28/2022 22:55:33 - INFO - __main__ -     eval_ppl = 28.68261
03/28/2022 22:55:33 - INFO - __main__ -     global_step = 42000
03/28/2022 22:55:33 - INFO - __main__ -     train_loss = 2.9443
03/28/2022 22:55:33 - INFO - __main__ -     ********************
03/28/2022 22:55:34 - INFO - __main__ -     Best ppl:28.68261
03/28/2022 22:55:34 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 22:59:21 - INFO - __main__ -     bleu-4 = 18.08 
03/28/2022 22:59:21 - INFO - __main__ -     ********************
loss 2.9496:  86%|████████▌ | 42998/50000 [7:59:24<42:45,  2.73it/s]03/28/2022 23:05:30 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 23:05:30 - INFO - __main__ -     Num examples = 13914
03/28/2022 23:05:30 - INFO - __main__ -     Batch size = 8
03/28/2022 23:08:19 - INFO - __main__ -     eval_ppl = 28.56756
03/28/2022 23:08:19 - INFO - __main__ -     global_step = 43000
03/28/2022 23:08:19 - INFO - __main__ -     train_loss = 2.9496
03/28/2022 23:08:19 - INFO - __main__ -     ********************
03/28/2022 23:08:20 - INFO - __main__ -     Best ppl:28.56756
03/28/2022 23:08:20 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 23:11:51 - INFO - __main__ -     bleu-4 = 18.28 
03/28/2022 23:11:51 - INFO - __main__ -     ********************
loss 2.9265:  88%|████████▊ | 43998/50000 [8:11:53<36:41,  2.73it/s]03/28/2022 23:17:58 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 23:17:58 - INFO - __main__ -     Num examples = 13914
03/28/2022 23:17:58 - INFO - __main__ -     Batch size = 8
03/28/2022 23:20:47 - INFO - __main__ -     eval_ppl = 28.29548
03/28/2022 23:20:47 - INFO - __main__ -     global_step = 44000
03/28/2022 23:20:47 - INFO - __main__ -     train_loss = 2.9265
03/28/2022 23:20:47 - INFO - __main__ -     ********************
03/28/2022 23:20:48 - INFO - __main__ -     Best ppl:28.29548
03/28/2022 23:20:48 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 23:24:05 - INFO - __main__ -     bleu-4 = 18.22 
03/28/2022 23:24:05 - INFO - __main__ -     ********************
loss 2.9156:  90%|████████▉ | 44998/50000 [8:23:56<33:43,  2.47it/s]03/28/2022 23:30:01 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 23:30:01 - INFO - __main__ -     Num examples = 13914
03/28/2022 23:30:01 - INFO - __main__ -     Batch size = 8
03/28/2022 23:32:31 - INFO - __main__ -     eval_ppl = 28.2027
03/28/2022 23:32:31 - INFO - __main__ -     global_step = 45000
03/28/2022 23:32:31 - INFO - __main__ -     train_loss = 2.9156
03/28/2022 23:32:31 - INFO - __main__ -     ********************
03/28/2022 23:32:32 - INFO - __main__ -     Best ppl:28.2027
03/28/2022 23:32:32 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 23:36:34 - INFO - __main__ -     bleu-4 = 18.06 
03/28/2022 23:36:34 - INFO - __main__ -     ********************
loss 2.9183:  92%|█████████▏| 45998/50000 [8:37:09<26:12,  2.55it/s]03/28/2022 23:43:14 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 23:43:14 - INFO - __main__ -     Num examples = 13914
03/28/2022 23:43:14 - INFO - __main__ -     Batch size = 8
03/28/2022 23:46:15 - INFO - __main__ -     eval_ppl = 28.11759
03/28/2022 23:46:15 - INFO - __main__ -     global_step = 46000
03/28/2022 23:46:15 - INFO - __main__ -     train_loss = 2.9183
03/28/2022 23:46:15 - INFO - __main__ -     ********************
03/28/2022 23:46:16 - INFO - __main__ -     Best ppl:28.11759
03/28/2022 23:46:16 - INFO - __main__ -     ********************
Total: 1000
03/28/2022 23:49:58 - INFO - __main__ -     bleu-4 = 18.47 
03/28/2022 23:49:58 - INFO - __main__ -     ********************
03/28/2022 23:49:58 - INFO - __main__ -     Best bleu:18.47
03/28/2022 23:49:58 - INFO - __main__ -     ********************
loss 2.9235:  94%|█████████▍| 46998/50000 [8:50:16<19:36,  2.55it/s]03/28/2022 23:56:22 - INFO - __main__ -   
***** Running evaluation *****
03/28/2022 23:56:22 - INFO - __main__ -     Num examples = 13914
03/28/2022 23:56:22 - INFO - __main__ -     Batch size = 8
03/28/2022 23:59:15 - INFO - __main__ -     eval_ppl = 27.99354
03/28/2022 23:59:15 - INFO - __main__ -     global_step = 47000
03/28/2022 23:59:15 - INFO - __main__ -     train_loss = 2.9235
03/28/2022 23:59:15 - INFO - __main__ -     ********************
03/28/2022 23:59:16 - INFO - __main__ -     Best ppl:27.99354
03/28/2022 23:59:16 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 00:02:50 - INFO - __main__ -     bleu-4 = 18.04 
03/29/2022 00:02:50 - INFO - __main__ -     ********************
loss 2.9281:  96%|█████████▌| 47998/50000 [9:03:05<12:37,  2.64it/s]03/29/2022 00:09:10 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 00:09:10 - INFO - __main__ -     Num examples = 13914
03/29/2022 00:09:10 - INFO - __main__ -     Batch size = 8
03/29/2022 00:12:12 - INFO - __main__ -     eval_ppl = 27.85624
03/29/2022 00:12:12 - INFO - __main__ -     global_step = 48000
03/29/2022 00:12:12 - INFO - __main__ -     train_loss = 2.9281
03/29/2022 00:12:12 - INFO - __main__ -     ********************
03/29/2022 00:12:13 - INFO - __main__ -     Best ppl:27.85624
03/29/2022 00:12:13 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 00:15:53 - INFO - __main__ -     bleu-4 = 18.12 
03/29/2022 00:15:53 - INFO - __main__ -     ********************
loss 2.8742:  98%|█████████▊| 48998/50000 [9:16:01<07:10,  2.33it/s]03/29/2022 00:22:06 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 00:22:06 - INFO - __main__ -     Num examples = 13914
03/29/2022 00:22:06 - INFO - __main__ -     Batch size = 8
03/29/2022 00:24:44 - INFO - __main__ -     eval_ppl = 27.8392
03/29/2022 00:24:44 - INFO - __main__ -     global_step = 49000
03/29/2022 00:24:44 - INFO - __main__ -     train_loss = 2.8742
03/29/2022 00:24:44 - INFO - __main__ -     ********************
03/29/2022 00:24:45 - INFO - __main__ -     Best ppl:27.8392
03/29/2022 00:24:45 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 00:28:24 - INFO - __main__ -     bleu-4 = 18.26 
03/29/2022 00:28:24 - INFO - __main__ -     ********************
loss 2.8955: 100%|█████████▉| 49998/50000 [9:28:46<00:00,  2.53it/s]03/29/2022 00:34:52 - INFO - __main__ -   
***** Running evaluation *****
03/29/2022 00:34:52 - INFO - __main__ -     Num examples = 13914
03/29/2022 00:34:52 - INFO - __main__ -     Batch size = 8
03/29/2022 00:37:53 - INFO - __main__ -     eval_ppl = 27.77313
03/29/2022 00:37:53 - INFO - __main__ -     global_step = 50000
03/29/2022 00:37:53 - INFO - __main__ -     train_loss = 2.8955
03/29/2022 00:37:53 - INFO - __main__ -     ********************
03/29/2022 00:37:54 - INFO - __main__ -     Best ppl:27.77313
03/29/2022 00:37:54 - INFO - __main__ -     ********************
Total: 1000
03/29/2022 00:41:06 - INFO - __main__ -     bleu-4 = 18.41 
03/29/2022 00:41:06 - INFO - __main__ -     ********************
loss 2.9821: 100%|██████████| 50000/50000 [9:35:01<00:00,  1.45it/s]

Process finished with exit code 0
